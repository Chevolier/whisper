{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a473fe8-ef6b-49a4-b7d2-d96600d9163d",
   "metadata": {},
   "source": [
    "## 1. Upload data to S3\n",
    "Here I use pokeman dataset as an example, which is composed of 833 image-text pairs. To scale up, you can just process your data into the same format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60a3ee2c-be39-46cf-ae76-1ecfc52e0e24",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f972fb3-9c30-4c5c-adea-36ed78e38d4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import datetime\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d4023f7-0ad4-460d-96f1-db5710f05d87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44e6697e-5363-4614-9371-284ec1b65fd4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-west-2-452145973879/datasets/midea_data/custom_data_v8\n"
     ]
    }
   ],
   "source": [
    "prefix_data = 'datasets/midea_data/custom_data_v0'\n",
    "\n",
    "local_data_path = \"../data/custom_data_v0\"\n",
    "input_data = sagemaker_session.upload_data(path=local_data_path, key_prefix=prefix_data)\n",
    "print(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc31ccb1-e849-43e0-85eb-9dd8b8984fa5",
   "metadata": {},
   "source": [
    "## 2. Upload pretrained models to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35dcff89-e473-497b-bc7a-4e333fbcc706",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3\n"
     ]
    }
   ],
   "source": [
    "prefix_model = 'models/whisper-large-v3'\n",
    "\n",
    "local_model_path = \"/home/ec2-user/SageMaker/efs/Models/whisper-large-v3\"\n",
    "input_model = sagemaker_session.upload_data(path=local_model_path, key_prefix=prefix_model)\n",
    "print(input_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417bb61d-6527-4707-9cbb-185c89b51008",
   "metadata": {},
   "source": [
    "## 3. Start a training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8a06ebc-ab38-48b6-9e9e-9c3f0145440e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: whisper-launch-2024-06-20-07-42-29-331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-20 07:42:31 Starting - Starting the training job...\n",
      "2024-06-20 07:42:50 Pending - Training job waiting for capacity...\n",
      "2024-06-20 07:43:14 Pending - Preparing the instances for training...........................\n",
      "2024-06-20 07:47:51 Downloading - Downloading input data...............\n",
      "2024-06-20 07:50:11 Downloading - Downloading the training image......\n",
      "2024-06-20 07:51:27 Training - Training image download completed. Training in progress....\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2024-06-20 07:51:54,946 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-06-20 07:51:55,039 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-06-20 07:51:55,048 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-06-20 07:51:55,049 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-06-20 07:51:56,655 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.11 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numba in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (0.59.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (1.26.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (2.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (4.66.4)\u001b[0m\n",
      "\u001b[34mCollecting more-itertools (from -r requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34mDownloading more_itertools-10.3.0-py3-none-any.whl.metadata (36 kB)\u001b[0m\n",
      "\u001b[34mCollecting tiktoken (from -r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: triton<3,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (2.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (2.2.2)\u001b[0m\n",
      "\u001b[34mCollecting jiwer (from -r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading jiwer-3.0.4-py3-none-any.whl.metadata (2.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting evaluate (from -r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\u001b[0m\n",
      "\u001b[34mCollecting tensorboardX (from -r requirements.txt (line 11))\u001b[0m\n",
      "\u001b[34mDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting bitsandbytes (from -r requirements.txt (line 12))\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /opt/conda/lib/python3.11/site-packages (from numba->-r requirements.txt (line 1)) (0.42.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 3)) (3.14.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 3)) (4.11.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 3)) (1.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 3)) (3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 3)) (3.1.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 3)) (2024.5.0)\u001b[0m\n",
      "\u001b[34mCollecting regex>=2022.1.18 (from tiktoken->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading regex-2024.5.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.9/40.9 kB 6.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.11/site-packages (from tiktoken->-r requirements.txt (line 6)) (2.32.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 8)) (2.9.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 8)) (2024.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 8)) (2024.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click<9.0.0,>=8.1.3 in /opt/conda/lib/python3.11/site-packages (from jiwer->-r requirements.txt (line 9)) (8.1.7)\u001b[0m\n",
      "\u001b[34mCollecting rapidfuzz<4,>=3 (from jiwer->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading rapidfuzz-3.9.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mCollecting datasets>=2.0.0 (from evaluate->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill in /opt/conda/lib/python3.11/site-packages (from evaluate->-r requirements.txt (line 10)) (0.3.8)\u001b[0m\n",
      "\u001b[34mCollecting xxhash (from evaluate->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading xxhash-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from evaluate->-r requirements.txt (line 10)) (0.70.16)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from evaluate->-r requirements.txt (line 10)) (0.23.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from evaluate->-r requirements.txt (line 10)) (23.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.20 in /opt/conda/lib/python3.11/site-packages (from tensorboardX->-r requirements.txt (line 11)) (3.20.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate->-r requirements.txt (line 10)) (16.1.0)\u001b[0m\n",
      "\u001b[34mCollecting pyarrow-hotfix (from datasets>=2.0.0->evaluate->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiohttp (from datasets>=2.0.0->evaluate->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading aiohttp-3.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate->-r requirements.txt (line 10)) (6.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 8)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->-r requirements.txt (line 6)) (3.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->-r requirements.txt (line 6)) (3.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->-r requirements.txt (line 6)) (1.26.18)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->-r requirements.txt (line 6)) (2024.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->-r requirements.txt (line 3)) (2.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch->-r requirements.txt (line 3)) (1.3.0)\u001b[0m\n",
      "\u001b[34mCollecting aiosignal>=1.1.2 (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 10)) (23.2.0)\u001b[0m\n",
      "\u001b[34mCollecting frozenlist>=1.1.1 (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mCollecting multidict<7.0,>=4.5 (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting yarl<2.0,>=1.0 (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\u001b[0m\n",
      "\u001b[34mDownloading more_itertools-10.3.0-py3-none-any.whl (59 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 59.2/59.2 kB 3.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 28.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading jiwer-3.0.4-py3-none-any.whl (21 kB)\u001b[0m\n",
      "\u001b[34mDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.1/84.1 kB 13.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 101.7/101.7 kB 17.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 119.8/119.8 MB 21.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading datasets-2.20.0-py3-none-any.whl (547 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 547.8/547.8 kB 56.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading rapidfuzz-3.9.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.4/3.4 MB 113.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading regex-2024.5.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 785.0/785.0 kB 68.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading xxhash-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 194.8/194.8 kB 25.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading aiohttp-3.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 85.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\u001b[0m\n",
      "\u001b[34mDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\u001b[0m\n",
      "\u001b[34mDownloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 272.3/272.3 kB 40.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (128 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 128.7/128.7 kB 20.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (328 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 328.1/328.1 kB 42.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mInstalling collected packages: xxhash, tensorboardX, regex, rapidfuzz, pyarrow-hotfix, multidict, more-itertools, frozenlist, yarl, tiktoken, jiwer, aiosignal, bitsandbytes, aiohttp, datasets, evaluate\u001b[0m\n",
      "\u001b[34mSuccessfully installed aiohttp-3.9.5 aiosignal-1.3.1 bitsandbytes-0.43.1 datasets-2.20.0 evaluate-0.4.2 frozenlist-1.4.1 jiwer-3.0.4 more-itertools-10.3.0 multidict-6.0.5 pyarrow-hotfix-0.6 rapidfuzz-3.9.3 regex-2024.5.15 tensorboardX-2.6.2.2 tiktoken-0.7.0 xxhash-3.4.1 yarl-1.9.4\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2024-06-20 07:52:05,797 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-06-20 07:52:05,797 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-06-20 07:52:05,915 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-06-20 07:52:06,014 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-06-20 07:52:06,115 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-06-20 07:52:06,124 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.p4d.24xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.p4d.24xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": true,\n",
      "    \"job_name\": \"whisper-launch-2024-06-20-07-42-29-331\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-452145973879/whisper-launch-2024-06-20-07-42-29-331/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"entry\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 96,\n",
      "    \"num_gpus\": 8,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p4d.24xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p4d.24xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"entry.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=entry.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p4d.24xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4d.24xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.p4d.24xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4d.24xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=entry\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=96\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-452145973879/whisper-launch-2024-06-20-07-42-29-331/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.p4d.24xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4d.24xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":true,\"job_name\":\"whisper-launch-2024-06-20-07-42-29-331\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-452145973879/whisper-launch-2024-06-20-07-42-29-331/source/sourcedir.tar.gz\",\"module_name\":\"entry\",\"network_interface_name\":\"eth0\",\"num_cpus\":96,\"num_gpus\":8,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p4d.24xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4d.24xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"entry.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python311.zip:/opt/conda/lib/python3.11:/opt/conda/lib/python3.11/lib-dynload:/opt/conda/lib/python3.11/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.11 entry.py\u001b[0m\n",
      "\u001b[34m2024-06-20 07:52:06,125 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m2024-06-20 07:52:06,125 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pip in /opt/conda/lib/python3.11/site-packages (24.0)\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mCollecting git+https://github.com/huggingface/transformers.git\u001b[0m\n",
      "\u001b[34mCloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-k9ea633_\u001b[0m\n",
      "\u001b[34mRunning command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-k9ea633_\u001b[0m\n",
      "\u001b[34mResolved https://github.com/huggingface/transformers.git to commit 0ed3ffcb4461a244b87781a24e5ebd0a78f98142\u001b[0m\n",
      "\u001b[34mInstalling build dependencies: started\u001b[0m\n",
      "\u001b[34mInstalling build dependencies: finished with status 'done'\u001b[0m\n",
      "\u001b[34mGetting requirements to build wheel: started\u001b[0m\n",
      "\u001b[34mGetting requirements to build wheel: finished with status 'done'\u001b[0m\n",
      "\u001b[34mPreparing metadata (pyproject.toml): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (pyproject.toml): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: accelerate in /opt/conda/lib/python3.11/site-packages (0.30.1)\u001b[0m\n",
      "\u001b[34mCollecting accelerate\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.31.0-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: datasets[audio] in /opt/conda/lib/python3.11/site-packages (2.20.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers==4.42.0.dev0) (3.14.0)\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub<1.0,>=0.23.2 (from transformers==4.42.0.dev0)\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers==4.42.0.dev0) (1.26.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers==4.42.0.dev0) (23.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers==4.42.0.dev0) (6.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers==4.42.0.dev0) (2024.5.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers==4.42.0.dev0) (2.32.2)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers<0.20,>=0.19 (from transformers==4.42.0.dev0)\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers==4.42.0.dev0) (0.4.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers==4.42.0.dev0) (4.66.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate) (5.9.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (2.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets[audio]) (16.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.11/site-packages (from datasets[audio]) (0.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets[audio]) (0.3.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets[audio]) (2.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets[audio]) (3.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from datasets[audio]) (0.70.16)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets[audio]) (2024.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets[audio]) (3.9.5)\u001b[0m\n",
      "\u001b[34mCollecting soundfile>=0.12.1 (from datasets[audio])\u001b[0m\n",
      "\u001b[34mDownloading soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl.metadata (14 kB)\u001b[0m\n",
      "\u001b[34mCollecting librosa (from datasets[audio])\u001b[0m\n",
      "\u001b[34mDownloading librosa-0.10.2.post1-py3-none-any.whl.metadata (8.6 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets[audio]) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets[audio]) (23.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets[audio]) (1.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets[audio]) (6.0.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets[audio]) (1.9.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.42.0.dev0) (4.11.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.42.0.dev0) (3.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.42.0.dev0) (3.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.42.0.dev0) (1.26.18)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.42.0.dev0) (2024.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.11/site-packages (from soundfile>=0.12.1->datasets[audio]) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\u001b[0m\n",
      "\u001b[34mCollecting audioread>=2.1.9 (from librosa->datasets[audio])\u001b[0m\n",
      "\u001b[34mDownloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from librosa->datasets[audio]) (1.13.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.11/site-packages (from librosa->datasets[audio]) (1.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.11/site-packages (from librosa->datasets[audio]) (1.4.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.11/site-packages (from librosa->datasets[audio]) (5.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numba>=0.51.0 in /opt/conda/lib/python3.11/site-packages (from librosa->datasets[audio]) (0.59.1)\u001b[0m\n",
      "\u001b[34mCollecting pooch>=1.1 (from librosa->datasets[audio])\u001b[0m\n",
      "\u001b[34mDownloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\u001b[0m\n",
      "\u001b[34mCollecting soxr>=0.3.2 (from librosa->datasets[audio])\u001b[0m\n",
      "\u001b[34mDownloading soxr-0.3.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting lazy-loader>=0.1 (from librosa->datasets[audio])\u001b[0m\n",
      "\u001b[34mDownloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting msgpack>=1.0 (from librosa->datasets[audio])\u001b[0m\n",
      "\u001b[34mDownloading msgpack-1.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets[audio]) (2.9.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets[audio]) (2024.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets[audio]) (2024.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=1.0->soundfile>=0.12.1->datasets[audio]) (2.21)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /opt/conda/lib/python3.11/site-packages (from numba>=0.51.0->librosa->datasets[audio]) (0.42.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.11/site-packages (from pooch>=1.1->librosa->datasets[audio]) (4.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets[audio]) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn>=0.20.0->librosa->datasets[audio]) (3.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.31.0-py3-none-any.whl (309 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 309.4/309.4 kB 11.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 402.6/402.6 kB 30.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl (1.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 69.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 122.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading librosa-0.10.2.post1-py3-none-any.whl (260 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 260.1/260.1 kB 37.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading audioread-3.0.1-py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34mDownloading lazy_loader-0.4-py3-none-any.whl (12 kB)\u001b[0m\n",
      "\u001b[34mDownloading msgpack-1.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (409 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 409.3/409.3 kB 49.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading pooch-1.8.2-py3-none-any.whl (64 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 64.6/64.6 kB 11.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading soxr-0.3.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 85.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: transformers\u001b[0m\n",
      "\u001b[34mBuilding wheel for transformers (pyproject.toml): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for transformers (pyproject.toml): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for transformers: filename=transformers-4.42.0.dev0-py3-none-any.whl size=9165394 sha256=87526976af59c083157e6f898bcecac8c0721f7980d3b88b784bd7469ffee47c\u001b[0m\n",
      "\u001b[34mStored in directory: /tmp/pip-ephem-wheel-cache-vpxxrxgf/wheels/32/4b/78/f195c684dd3a9ed21f3b39fe8f85b48df7918581b6437be143\u001b[0m\n",
      "\u001b[34mSuccessfully built transformers\u001b[0m\n",
      "\u001b[34mInstalling collected packages: soxr, msgpack, lazy-loader, audioread, soundfile, pooch, huggingface-hub, tokenizers, librosa, accelerate, transformers\u001b[0m\n",
      "\u001b[34mAttempting uninstall: huggingface-hub\u001b[0m\n",
      "\u001b[34mFound existing installation: huggingface_hub 0.23.0\u001b[0m\n",
      "\u001b[34mUninstalling huggingface_hub-0.23.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled huggingface_hub-0.23.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: accelerate\u001b[0m\n",
      "\u001b[34mFound existing installation: accelerate 0.30.1\u001b[0m\n",
      "\u001b[34mUninstalling accelerate-0.30.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled accelerate-0.30.1\u001b[0m\n",
      "\u001b[34mSuccessfully installed accelerate-0.31.0 audioread-3.0.1 huggingface-hub-0.23.4 lazy-loader-0.4 librosa-0.10.2.post1 msgpack-1.0.8 pooch-1.8.2 soundfile-0.12.1 soxr-0.3.7 tokenizers-0.19.1 transformers-4.42.0.dev0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mCollecting openai-whisper\u001b[0m\n",
      "\u001b[34mDownloading openai-whisper-20231117.tar.gz (798 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 798.6/798.6 kB 17.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mInstalling build dependencies: started\u001b[0m\n",
      "\u001b[34mInstalling build dependencies: finished with status 'done'\u001b[0m\n",
      "\u001b[34mGetting requirements to build wheel: started\u001b[0m\n",
      "\u001b[34mGetting requirements to build wheel: finished with status 'done'\u001b[0m\n",
      "\u001b[34mPreparing metadata (pyproject.toml): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (pyproject.toml): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: triton<3,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from openai-whisper) (2.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numba in /opt/conda/lib/python3.11/site-packages (from openai-whisper) (0.59.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from openai-whisper) (1.26.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from openai-whisper) (2.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from openai-whisper) (4.66.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: more-itertools in /opt/conda/lib/python3.11/site-packages (from openai-whisper) (10.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tiktoken in /opt/conda/lib/python3.11/site-packages (from openai-whisper) (0.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from triton<3,>=2.0.0->openai-whisper) (3.14.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /opt/conda/lib/python3.11/site-packages (from numba->openai-whisper) (0.42.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.11/site-packages (from tiktoken->openai-whisper) (2024.5.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.11/site-packages (from tiktoken->openai-whisper) (2.32.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch->openai-whisper) (4.11.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch->openai-whisper) (1.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->openai-whisper) (3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->openai-whisper) (3.1.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch->openai-whisper) (2024.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (1.26.18)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->openai-whisper) (2.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch->openai-whisper) (1.3.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: openai-whisper\u001b[0m\n",
      "\u001b[34mBuilding wheel for openai-whisper (pyproject.toml): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for openai-whisper (pyproject.toml): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801359 sha256=ba2e4f511d2c34af5cb9e4aeb64f3b778bb020045c3091a3921c1c90e4a50d2f\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/55/5d/42/c296ab046d52caa0adc0e3f159e98f011b3994a022d6282105\u001b[0m\n",
      "\u001b[34mSuccessfully built openai-whisper\u001b[0m\n",
      "\u001b[34mInstalling collected packages: openai-whisper\u001b[0m\n",
      "\u001b[34mSuccessfully installed openai-whisper-20231117\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numba in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (0.59.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (1.26.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (2.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (4.66.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: more-itertools in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (10.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tiktoken in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (0.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: triton<3,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (2.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (2.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jiwer in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (3.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: evaluate in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (0.4.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tensorboardX in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (2.6.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: bitsandbytes in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (0.43.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /opt/conda/lib/python3.11/site-packages (from numba->-r requirements.txt (line 1)) (0.42.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 3)) (3.14.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 3)) (4.11.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 3)) (1.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 3)) (3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 3)) (3.1.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 3)) (2024.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.11/site-packages (from tiktoken->-r requirements.txt (line 6)) (2024.5.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.11/site-packages (from tiktoken->-r requirements.txt (line 6)) (2.32.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 8)) (2.9.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 8)) (2024.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 8)) (2024.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click<9.0.0,>=8.1.3 in /opt/conda/lib/python3.11/site-packages (from jiwer->-r requirements.txt (line 9)) (8.1.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rapidfuzz<4,>=3 in /opt/conda/lib/python3.11/site-packages (from jiwer->-r requirements.txt (line 9)) (3.9.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from evaluate->-r requirements.txt (line 10)) (2.20.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill in /opt/conda/lib/python3.11/site-packages (from evaluate->-r requirements.txt (line 10)) (0.3.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from evaluate->-r requirements.txt (line 10)) (3.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from evaluate->-r requirements.txt (line 10)) (0.70.16)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from evaluate->-r requirements.txt (line 10)) (0.23.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from evaluate->-r requirements.txt (line 10)) (23.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.20 in /opt/conda/lib/python3.11/site-packages (from tensorboardX->-r requirements.txt (line 11)) (3.20.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate->-r requirements.txt (line 10)) (16.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate->-r requirements.txt (line 10)) (0.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate->-r requirements.txt (line 10)) (3.9.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate->-r requirements.txt (line 10)) (6.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 8)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->-r requirements.txt (line 6)) (3.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->-r requirements.txt (line 6)) (3.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->-r requirements.txt (line 6)) (1.26.18)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->-r requirements.txt (line 6)) (2024.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->-r requirements.txt (line 3)) (2.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch->-r requirements.txt (line 3)) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 10)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 10)) (23.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 10)) (1.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 10)) (6.0.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 10)) (1.9.4)\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mCollecting ffmpeg\u001b[0m\n",
      "\u001b[34mDownloading ffmpeg-1.4.tar.gz (5.1 kB)\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: ffmpeg\u001b[0m\n",
      "\u001b[34mBuilding wheel for ffmpeg (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for ffmpeg (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6080 sha256=1d48a900ab3863ecf4215522c8bb4f5aa89558c445d015321562c9cd18c37f0d\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/56/30/c5/576bdd729f3bc062d62a551be7fefd6ed2f761901568171e4e\u001b[0m\n",
      "\u001b[34mSuccessfully built ffmpeg\u001b[0m\n",
      "\u001b[34mInstalling collected packages: ffmpeg\u001b[0m\n",
      "\u001b[34mSuccessfully installed ffmpeg-1.4\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mW0620 07:52:40.636000 140604473853760 torch/distributed/run.py:757] \u001b[0m\n",
      "\u001b[34mW0620 07:52:40.636000 140604473853760 torch/distributed/run.py:757] *****************************************\u001b[0m\n",
      "\u001b[34mW0620 07:52:40.636000 140604473853760 torch/distributed/run.py:757] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \u001b[0m\n",
      "\u001b[34mW0620 07:52:40.636000 140604473853760 torch/distributed/run.py:757] *****************************************\u001b[0m\n",
      "\u001b[34m+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[34mARGUMENTS OF INTEREST:\u001b[0m\n",
      "\u001b[34m{'model_name': 'whisper-large-v3', 'language': 'Cantonese', 'sampling_rate': 16000, 'num_proc': 1, 'train_strategy': 'steps', 'learning_rate': 5e-06, 'warmup': 10, 'train_batchsize': 8, 'eval_batchsize': 8, 'num_epochs': 10, 'num_steps': 500, 'resume_from_ckpt': 'None', 'output_dir': '/opt/ml/checkpoints', 'train_datasets': ['/tmp/data/train'], 'eval_datasets': ['/tmp/data/valid']}\u001b[0m\n",
      "\u001b[34m+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[34mRunning on rank 6/8\u001b[0m\n",
      "\u001b[34m+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[34mARGUMENTS OF INTEREST:\u001b[0m\n",
      "\u001b[34m+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[34mARGUMENTS OF INTEREST:\u001b[0m\n",
      "\u001b[34m+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[34mARGUMENTS OF INTEREST:\u001b[0m\n",
      "\u001b[34m{'model_name': 'whisper-large-v3', 'language': 'Cantonese', 'sampling_rate': 16000, 'num_proc': 1, 'train_strategy': 'steps', 'learning_rate': 5e-06, 'warmup': 10, 'train_batchsize': 8, 'eval_batchsize': 8, 'num_epochs': 10, 'num_steps': 500, 'resume_from_ckpt': 'None', 'output_dir': '/opt/ml/checkpoints', 'train_datasets': ['/tmp/data/train'], 'eval_datasets': ['/tmp/data/valid']}\u001b[0m\n",
      "\u001b[34m{'model_name': 'whisper-large-v3', 'language': 'Cantonese', 'sampling_rate': 16000, 'num_proc': 1, 'train_strategy': 'steps', 'learning_rate': 5e-06, 'warmup': 10, 'train_batchsize': 8, 'eval_batchsize': 8, 'num_epochs': 10, 'num_steps': 500, 'resume_from_ckpt': 'None', 'output_dir': '/opt/ml/checkpoints', 'train_datasets': ['/tmp/data/train'], 'eval_datasets': ['/tmp/data/valid']}\u001b[0m\n",
      "\u001b[34m+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[34m+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[34m+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[34m{'model_name': 'whisper-large-v3', 'language': 'Cantonese', 'sampling_rate': 16000, 'num_proc': 1, 'train_strategy': 'steps', 'learning_rate': 5e-06, 'warmup': 10, 'train_batchsize': 8, 'eval_batchsize': 8, 'num_epochs': 10, 'num_steps': 500, 'resume_from_ckpt': 'None', 'output_dir': '/opt/ml/checkpoints', 'train_datasets': ['/tmp/data/train'], 'eval_datasets': ['/tmp/data/valid']}\u001b[0m\n",
      "\u001b[34m+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[34mARGUMENTS OF INTEREST:\u001b[0m\n",
      "\u001b[34m+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[34mARGUMENTS OF INTEREST:\u001b[0m\n",
      "\u001b[34m{'model_name': 'whisper-large-v3', 'language': 'Cantonese', 'sampling_rate': 16000, 'num_proc': 1, 'train_strategy': 'steps', 'learning_rate': 5e-06, 'warmup': 10, 'train_batchsize': 8, 'eval_batchsize': 8, 'num_epochs': 10, 'num_steps': 500, 'resume_from_ckpt': 'None', 'output_dir': '/opt/ml/checkpoints', 'train_datasets': ['/tmp/data/train'], 'eval_datasets': ['/tmp/data/valid']}{'model_name': 'whisper-large-v3', 'language': 'Cantonese', 'sampling_rate': 16000, 'num_proc': 1, 'train_strategy': 'steps', 'learning_rate': 5e-06, 'warmup': 10, 'train_batchsize': 8, 'eval_batchsize': 8, 'num_epochs': 10, 'num_steps': 500, 'resume_from_ckpt': 'None', 'output_dir': '/opt/ml/checkpoints', 'train_datasets': ['/tmp/data/train'], 'eval_datasets': ['/tmp/data/valid']}\u001b[0m\n",
      "\u001b[34m+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[34m+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[34mRunning on rank 0/8\u001b[0m\n",
      "\u001b[34m*****************start cp data and pretrained models*****************************\u001b[0m\n",
      "\u001b[34mRunning on rank 4/8\u001b[0m\n",
      "\u001b[34mRunning on rank 7/8Running on rank 5/8\u001b[0m\n",
      "\u001b[34mRunning on rank 3/8\u001b[0m\n",
      "\u001b[34m+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[34mARGUMENTS OF INTEREST:\u001b[0m\n",
      "\u001b[34m{'model_name': 'whisper-large-v3', 'language': 'Cantonese', 'sampling_rate': 16000, 'num_proc': 1, 'train_strategy': 'steps', 'learning_rate': 5e-06, 'warmup': 10, 'train_batchsize': 8, 'eval_batchsize': 8, 'num_epochs': 10, 'num_steps': 500, 'resume_from_ckpt': 'None', 'output_dir': '/opt/ml/checkpoints', 'train_datasets': ['/tmp/data/train'], 'eval_datasets': ['/tmp/data/valid']}\u001b[0m\n",
      "\u001b[34m+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[34mRunning on rank 2/8\u001b[0m\n",
      "\u001b[34m+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[34mARGUMENTS OF INTEREST:\u001b[0m\n",
      "\u001b[34m{'model_name': 'whisper-large-v3', 'language': 'Cantonese', 'sampling_rate': 16000, 'num_proc': 1, 'train_strategy': 'steps', 'learning_rate': 5e-06, 'warmup': 10, 'train_batchsize': 8, 'eval_batchsize': 8, 'num_epochs': 10, 'num_steps': 500, 'resume_from_ckpt': 'None', 'output_dir': '/opt/ml/checkpoints', 'train_datasets': ['/tmp/data/train'], 'eval_datasets': ['/tmp/data/valid']}\u001b[0m\n",
      "\u001b[34m+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[34mRunning on rank 1/8\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/datasets/midea_data/custom_data_v8/train/dataset_info.json /tmp/data/train/dataset_info.json\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/datasets/midea_data/custom_data_v8/train/state.json /tmp/data/train/state.json\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/datasets/midea_data/custom_data_v8/train/text /tmp/data/train/text\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/datasets/midea_data/custom_data_v8/train/audio_paths /tmp/data/train/audio_paths\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/datasets/midea_data/custom_data_v8/train/data-00000-of-00002.arrow /tmp/data/train/data-00000-of-00002.arrow\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/datasets/midea_data/custom_data_v8/train/data-00001-of-00002.arrow /tmp/data/train/data-00001-of-00002.arrow\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/datasets/midea_data/custom_data_v8/valid/state.json /tmp/data/valid/state.json\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/datasets/midea_data/custom_data_v8/valid/text /tmp/data/valid/text\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/datasets/midea_data/custom_data_v8/valid/dataset_info.json /tmp/data/valid/dataset_info.json\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/datasets/midea_data/custom_data_v8/valid/audio_paths /tmp/data/valid/audio_paths\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/datasets/midea_data/custom_data_v8/valid/data-00000-of-00001.arrow /tmp/data/valid/data-00000-of-00001.arrow\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/.gitattributes whisper-large-v3/.gitattributes\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/generation_config.json whisper-large-v3/generation_config.json\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/preprocessor_config.json whisper-large-v3/preprocessor_config.json\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/added_tokens.json whisper-large-v3/added_tokens.json\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/config.json whisper-large-v3/config.json\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/tokenizer_config.json whisper-large-v3/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/model.safetensors.index.fp32.json whisper-large-v3/model.safetensors.index.fp32.json\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/normalizer.json whisper-large-v3/normalizer.json\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/.ipynb_checkpoints/generation_config-checkpoint.json whisper-large-v3/.ipynb_checkpoints/generation_config-checkpoint.json\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/merges.txt whisper-large-v3/merges.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/vocab.json whisper-large-v3/vocab.json\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/pytorch_model.bin.index.fp32.json whisper-large-v3/pytorch_model.bin.index.fp32.json\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/README.md whisper-large-v3/README.md\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/tokenizer.json whisper-large-v3/tokenizer.json\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/special_tokens_map.json whisper-large-v3/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/model.fp32-00002-of-00002.safetensors whisper-large-v3/model.fp32-00002-of-00002.safetensors\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/pytorch_model.fp32-00002-of-00002.bin whisper-large-v3/pytorch_model.fp32-00002-of-00002.bin\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/model.safetensors whisper-large-v3/model.safetensors\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/pytorch_model.bin whisper-large-v3/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/model.fp32-00001-of-00002.safetensors whisper-large-v3/model.fp32-00001-of-00002.safetensors\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/pytorch_model.fp32-00001-of-00002.bin whisper-large-v3/pytorch_model.fp32-00001-of-00002.bin\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/flax_model.msgpack whisper-large-v3/flax_model.msgpack\u001b[0m\n",
      "\u001b[34malgo-1:135:135 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34malgo-1:135:135 [0] NCCL INFO Bootstrap : Using eth0:10.0.246.120<0>\u001b[0m\n",
      "\u001b[34malgo-1:135:135 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34malgo-1:135:135 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34malgo-1:135:135 [0] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34mNCCL version 2.21.5+cuda12.1\u001b[0m\n",
      "\u001b[34malgo-1:142:142 [7] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34malgo-1:140:140 [5] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34malgo-1:139:139 [4] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34malgo-1:138:138 [3] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34malgo-1:141:141 [6] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34malgo-1:136:136 [1] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34malgo-1:137:137 [2] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34malgo-1:142:142 [7] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34malgo-1:139:139 [4] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34malgo-1:140:140 [5] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34malgo-1:138:138 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34malgo-1:141:141 [6] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34malgo-1:136:136 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34malgo-1:137:137 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34malgo-1:142:142 [7] NCCL INFO Bootstrap : Using eth0:10.0.246.120<0>\u001b[0m\n",
      "\u001b[34malgo-1:139:139 [4] NCCL INFO Bootstrap : Using eth0:10.0.246.120<0>\u001b[0m\n",
      "\u001b[34malgo-1:138:138 [3] NCCL INFO Bootstrap : Using eth0:10.0.246.120<0>\u001b[0m\n",
      "\u001b[34malgo-1:141:141 [6] NCCL INFO Bootstrap : Using eth0:10.0.246.120<0>\u001b[0m\n",
      "\u001b[34malgo-1:136:136 [1] NCCL INFO Bootstrap : Using eth0:10.0.246.120<0>\u001b[0m\n",
      "\u001b[34malgo-1:137:137 [2] NCCL INFO Bootstrap : Using eth0:10.0.246.120<0>\u001b[0m\n",
      "\u001b[34malgo-1:140:140 [5] NCCL INFO Bootstrap : Using eth0:10.0.246.120<0>\u001b[0m\n",
      "\u001b[34malgo-1:142:142 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34malgo-1:139:139 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34malgo-1:137:137 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34malgo-1:136:136 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34malgo-1:138:138 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34malgo-1:142:142 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34malgo-1:139:139 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34malgo-1:140:140 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34malgo-1:137:137 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34malgo-1:136:136 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34malgo-1:138:138 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34malgo-1:141:141 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34malgo-1:140:140 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34malgo-1:141:141 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO NET/OFI Using Libfabric version 1.21\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO NET/OFI Using CUDA driver version 12020\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO NET/OFI Running on p4d.24xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO NET/OFI Internode latency set at 75.0 us\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO NET/OFI Selected Provider is efa (found 4 nics)\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO NET/OFI Using Libfabric version 1.21\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO NET/OFI Using CUDA driver version 12020\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO NET/OFI Running on p4d.24xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO NET/OFI Internode latency set at 75.0 us\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO NET/OFI Using Libfabric version 1.21\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO NET/OFI Using CUDA driver version 12020\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO NET/OFI Running on p4d.24xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO NET/OFI Internode latency set at 75.0 us\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO NET/OFI Selected Provider is efa (found 4 nics)\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO NET/OFI Selected Provider is efa (found 4 nics)\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO NET/OFI Using Libfabric version 1.21\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO NET/OFI Using CUDA driver version 12020\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO NET/OFI Running on p4d.24xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO NET/OFI Internode latency set at 75.0 us\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO NET/OFI Using Libfabric version 1.21\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO NET/OFI Using Libfabric version 1.21\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO NET/OFI Using CUDA driver version 12020\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO NET/OFI Running on p4d.24xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO NET/OFI Internode latency set at 75.0 us\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO NET/OFI Using CUDA driver version 12020\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO NET/OFI Running on p4d.24xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO NET/OFI Internode latency set at 75.0 us\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO NET/OFI Using Libfabric version 1.21\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO NET/OFI Using CUDA driver version 12020\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO NET/OFI Running on p4d.24xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO NET/OFI Internode latency set at 75.0 us\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO NET/OFI Selected Provider is efa (found 4 nics)\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO NET/OFI Selected Provider is efa (found 4 nics)\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO NET/OFI Selected Provider is efa (found 4 nics)\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO NET/OFI Selected Provider is efa (found 4 nics)\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO NET/OFI Using Libfabric version 1.21\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO NET/OFI Using CUDA driver version 12020\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO NET/OFI Running on p4d.24xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO NET/OFI Internode latency set at 75.0 us\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO NET/OFI Selected Provider is efa (found 4 nics)\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO DMA-BUF is available on GPU device 0\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO DMA-BUF is available on GPU device 4\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO DMA-BUF is available on GPU device 7\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO DMA-BUF is available on GPU device 5\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO DMA-BUF is available on GPU device 1\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO DMA-BUF is available on GPU device 3\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO DMA-BUF is available on GPU device 6\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO DMA-BUF is available on GPU device 2\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO ncclCommInitRank comm 0x55643a9c8b00 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 201c0 commId 0x71c908fe42bb1072 - Init START\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO ncclCommInitRank comm 0x56473f28db40 rank 6 nranks 8 cudaDev 6 nvmlDev 6 busId a01c0 commId 0x71c908fe42bb1072 - Init START\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO ncclCommInitRank comm 0x558fc59548f0 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId 201d0 commId 0x71c908fe42bb1072 - Init START\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO ncclCommInitRank comm 0x55b4c31a9e70 rank 5 nranks 8 cudaDev 5 nvmlDev 5 busId 901d0 commId 0x71c908fe42bb1072 - Init START\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO ncclCommInitRank comm 0x55e8bb79e750 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 101c0 commId 0x71c908fe42bb1072 - Init START\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO ncclCommInitRank comm 0x559b076c0830 rank 4 nranks 8 cudaDev 4 nvmlDev 4 busId 901c0 commId 0x71c908fe42bb1072 - Init START\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO ncclCommInitRank comm 0x55b83d8c36f0 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 101d0 commId 0x71c908fe42bb1072 - Init START\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO ncclCommInitRank comm 0x555b6a6b96a0 rank 7 nranks 8 cudaDev 7 nvmlDev 7 busId a01d0 commId 0x71c908fe42bb1072 - Init START\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Setting affinity for GPU 7 to ffffff00,0000ffff,ff000000\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO NVLS multicast support is not available on dev 7\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Setting affinity for GPU 1 to ff,ffff0000,00ffffff\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO NVLS multicast support is not available on dev 1\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Setting affinity for GPU 3 to ff,ffff0000,00ffffff\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO NVLS multicast support is not available on dev 3\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Setting affinity for GPU 2 to ff,ffff0000,00ffffff\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffff0000,00ffffff\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Setting affinity for GPU 6 to ffffff00,0000ffff,ff000000\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO NVLS multicast support is not available on dev 6\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Setting affinity for GPU 5 to ffffff00,0000ffff,ff000000\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO NVLS multicast support is not available on dev 5\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO NVLS multicast support is not available on dev 2\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO NVLS multicast support is not available on dev 0\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Setting affinity for GPU 4 to ffffff00,0000ffff,ff000000\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO NVLS multicast support is not available on dev 4\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO comm 0x56473f28db40 rank 6 nRanks 8 nNodes 1 localRanks 8 localRank 6 MNNVL 0\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO comm 0x558fc59548f0 rank 3 nRanks 8 nNodes 1 localRanks 8 localRank 3 MNNVL 0\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO comm 0x55b4c31a9e70 rank 5 nRanks 8 nNodes 1 localRanks 8 localRank 5 MNNVL 0\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO comm 0x55643a9c8b00 rank 2 nRanks 8 nNodes 1 localRanks 8 localRank 2 MNNVL 0\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO comm 0x559b076c0830 rank 4 nRanks 8 nNodes 1 localRanks 8 localRank 4 MNNVL 0\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO comm 0x55b83d8c36f0 rank 1 nRanks 8 nNodes 1 localRanks 8 localRank 1 MNNVL 0\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO comm 0x55e8bb79e750 rank 0 nRanks 8 nNodes 1 localRanks 8 localRank 0 MNNVL 0\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO comm 0x555b6a6b96a0 rank 7 nRanks 8 nNodes 1 localRanks 8 localRank 7 MNNVL 0\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 00/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 01/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 02/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 03/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 7/-1/-1->6->5 [3] 7/-1/-1->6->5 [4] 7/-1/-1->6->5 [5] 7/-1/-1->6->5 [6] 7/-1/-1->6->5 [7] 7/-1/-1->6->5 [8] 7/-1/-1->6->5 [9] 7/-1/-1->6->5 [10] 7/-1/-1->6->5 [11] 7/-1/-1->6->5 [12] 7/-1/-1->6->5 [13] 7/-1/-1->6->5 [14] 7/-1/-1->6->5 [15] 7/-1/-1->6->5 [16] 7/-1/-1->6->5 [17] 7/-1/-1->6->5 [18] 7/-1/-1->6->5 [19] 7/-1/-1->6->5 [20] 7/-1/-1->6->5 [21] 7/-1/-1->6->5 [22] 7/-1/-1->6->5 [23] 7/-1/-1->6->5\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3 [2] 5/-1/-1->4->3 [3] 5/-1/-1->4->3 [4] 5/-1/-1->4->3 [5] 5/-1/-1->4->3 [6] 5/-1/-1->4->3 [7] 5/-1/-1->4->3 [8] 5/-1/-1->4->3 [9] 5/-1/-1->4->3 [10] 5/-1/-1->4->3 [11] 5/-1/-1->4->3 [12] 5/-1/-1->4->3 [13] 5/-1/-1->4->3 [14] 5/-1/-1->4->3 [15] 5/-1/-1->4->3 [16] 5/-1/-1->4->3 [17] 5/-1/-1->4->3 [18] 5/-1/-1->4->3 [19] 5/-1/-1->4->3 [20] 5/-1/-1->4->3 [21] 5/-1/-1->4->3 [22] 5/-1/-1->4->3 [23] 5/-1/-1->4->3\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4 [2] 6/-1/-1->5->4 [3] 6/-1/-1->5->4 [4] 6/-1/-1->5->4 [5] 6/-1/-1->5->4 [6] 6/-1/-1->5->4 [7] 6/-1/-1->5->4 [8] 6/-1/-1->5->4 [9] 6/-1/-1->5->4 [10] 6/-1/-1->5->4 [11] 6/-1/-1->5->4 [12] 6/-1/-1->5->4 [13] 6/-1/-1->5->4 [14] 6/-1/-1->5->4 [15] 6/-1/-1->5->4 [16] 6/-1/-1->5->4 [17] 6/-1/-1->5->4 [18] 6/-1/-1->5->4 [19] 6/-1/-1->5->4 [20] 6/-1/-1->5->4 [21] 6/-1/-1->5->4 [22] 6/-1/-1->5->4 [23] 6/-1/-1->5->4\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 04/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2 [2] 4/-1/-1->3->2 [3] 4/-1/-1->3->2 [4] 4/-1/-1->3->2 [5] 4/-1/-1->3->2 [6] 4/-1/-1->3->2 [7] 4/-1/-1->3->2 [8] 4/-1/-1->3->2 [9] 4/-1/-1->3->2 [10] 4/-1/-1->3->2 [11] 4/-1/-1->3->2 [12] 4/-1/-1->3->2 [13] 4/-1/-1->3->2 [14] 4/-1/-1->3->2 [15] 4/-1/-1->3->2 [16] 4/-1/-1->3->2 [17] 4/-1/-1->3->2 [18] 4/-1/-1->3->2 [19] 4/-1/-1->3->2 [20] 4/-1/-1->3->2 [21] 4/-1/-1->3->2 [22] 4/-1/-1->3->2 [23] 4/-1/-1->3->2\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO P2P Chunksize set to 524288\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO P2P Chunksize set to 524288\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO P2P Chunksize set to 524288\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 05/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO P2P Chunksize set to 524288\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 3/-1/-1->2->1 [5] 3/-1/-1->2->1 [6] 3/-1/-1->2->1 [7] 3/-1/-1->2->1 [8] 3/-1/-1->2->1 [9] 3/-1/-1->2->1 [10] 3/-1/-1->2->1 [11] 3/-1/-1->2->1 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 3/-1/-1->2->1 [17] 3/-1/-1->2->1 [18] 3/-1/-1->2->1 [19] 3/-1/-1->2->1 [20] 3/-1/-1->2->1 [21] 3/-1/-1->2->1 [22] 3/-1/-1->2->1 [23] 3/-1/-1->2->1\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 06/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 2/-1/-1->1->0 [5] 2/-1/-1->1->0 [6] 2/-1/-1->1->0 [7] 2/-1/-1->1->0 [8] 2/-1/-1->1->0 [9] 2/-1/-1->1->0 [10] 2/-1/-1->1->0 [11] 2/-1/-1->1->0 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 2/-1/-1->1->0 [17] 2/-1/-1->1->0 [18] 2/-1/-1->1->0 [19] 2/-1/-1->1->0 [20] 2/-1/-1->1->0 [21] 2/-1/-1->1->0 [22] 2/-1/-1->1->0 [23] 2/-1/-1->1->0\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO P2P Chunksize set to 524288\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 07/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO P2P Chunksize set to 524288\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 08/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6 [2] -1/-1/-1->7->6 [3] -1/-1/-1->7->6 [4] -1/-1/-1->7->6 [5] -1/-1/-1->7->6 [6] -1/-1/-1->7->6 [7] -1/-1/-1->7->6 [8] -1/-1/-1->7->6 [9] -1/-1/-1->7->6 [10] -1/-1/-1->7->6 [11] -1/-1/-1->7->6 [12] -1/-1/-1->7->6 [13] -1/-1/-1->7->6 [14] -1/-1/-1->7->6 [15] -1/-1/-1->7->6 [16] -1/-1/-1->7->6 [17] -1/-1/-1->7->6 [18] -1/-1/-1->7->6 [19] -1/-1/-1->7->6 [20] -1/-1/-1->7->6 [21] -1/-1/-1->7->6 [22] -1/-1/-1->7->6 [23] -1/-1/-1->7->6\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 09/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 10/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO P2P Chunksize set to 524288\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 11/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 12/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 13/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 14/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 15/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 16/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 17/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 18/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 19/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 20/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 21/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 22/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 23/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1 [8] 1/-1/-1->0->-1 [9] 1/-1/-1->0->-1 [10] 1/-1/-1->0->-1 [11] 1/-1/-1->0->-1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 1/-1/-1->0->-1 [17] 1/-1/-1->0->-1 [18] 1/-1/-1->0->-1 [19] 1/-1/-1->0->-1 [20] 1/-1/-1->0->-1 [21] 1/-1/-1->0->-1 [22] 1/-1/-1->0->-1 [23] 1/-1/-1->0->-1\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO P2P Chunksize set to 524288\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 00/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 00/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 00/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 00/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 01/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 01/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 01/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 01/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 01/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 01/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 02/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 02/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 02/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 02/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 02/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 02/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 03/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 03/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 03/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 03/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 03/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 03/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 03/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 04/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 04/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 04/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 04/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 04/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 04/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 05/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 05/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 05/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 05/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 05/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 05/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 05/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 06/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 06/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 06/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 06/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 07/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 07/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 07/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 07/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 07/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 07/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 00/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 08/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 08/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 08/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 08/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 08/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 08/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 09/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 01/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 09/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 09/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 09/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 09/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 09/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 09/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 10/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 10/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 10/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 10/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 10/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 10/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 11/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 11/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 11/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 11/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 11/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 11/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 11/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 12/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 12/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 12/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 12/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 13/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 13/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 13/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 13/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 13/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 13/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 14/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 14/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 14/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 14/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 14/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 14/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 15/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 15/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 15/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 15/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 15/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 15/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 15/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 16/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 16/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 16/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 16/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 16/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 16/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 17/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 17/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 17/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 17/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 17/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 17/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 17/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 18/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 18/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 18/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 18/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 19/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 19/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 19/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 19/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 19/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 19/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 20/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 20/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 20/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 20/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 20/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 20/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 21/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 21/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 21/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 21/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 21/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 21/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 21/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 22/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 22/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 22/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 22/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 22/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 22/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 23/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 23/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 23/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Channel 23/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 23/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 23/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 23/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 02/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 03/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 04/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 05/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 06/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 07/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 08/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 09/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 10/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 11/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 12/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 13/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 14/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 15/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 16/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 17/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 18/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 19/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 20/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 21/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 22/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 23/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 00/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 01/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 00/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 02/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 04/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 02/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 06/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 03/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 07/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 04/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 08/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 03/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 10/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 04/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 12/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 13/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 14/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 06/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 06/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 08/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 07/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 16/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 09/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 10/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 09/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 18/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 10/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 19/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 12/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 20/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 12/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 13/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 14/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 22/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 15/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 15/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 16/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 16/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 18/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 18/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 19/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 00/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 20/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 01/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 21/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 21/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 02/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 22/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 22/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 03/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 04/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 05/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 06/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 07/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 08/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 09/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 10/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 11/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 12/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 13/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 14/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 15/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 16/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 17/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 18/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 19/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 20/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 21/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 22/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Channel 23/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 00/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 01/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 00/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 02/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 01/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 03/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 04/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 02/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 00/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 05/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 03/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 01/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 06/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 04/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 02/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 07/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 05/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 03/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 08/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 06/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 04/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 09/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 07/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 05/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 10/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 08/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 06/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 11/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 07/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 09/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 12/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 08/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 10/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 13/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 09/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 11/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 10/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 14/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 11/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 15/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 12/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 12/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 16/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 13/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 13/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 17/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 14/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 14/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 18/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 15/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 15/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 19/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 16/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 16/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 20/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 17/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 17/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 18/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 18/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 19/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 21/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 19/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 20/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 21/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 22/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 20/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 22/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Channel 23/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 21/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Channel 23/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 22/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Channel 23/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.\u001b[0m\n",
      "\u001b[34malgo-1:138:881 [3] NCCL INFO ncclCommInitRank comm 0x558fc59548f0 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId 201d0 commId 0x71c908fe42bb1072 - Init COMPLETE\u001b[0m\n",
      "\u001b[34malgo-1:137:885 [2] NCCL INFO ncclCommInitRank comm 0x55643a9c8b00 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 201c0 commId 0x71c908fe42bb1072 - Init COMPLETE\u001b[0m\n",
      "\u001b[34malgo-1:142:882 [7] NCCL INFO ncclCommInitRank comm 0x555b6a6b96a0 rank 7 nranks 8 cudaDev 7 nvmlDev 7 busId a01d0 commId 0x71c908fe42bb1072 - Init COMPLETE\u001b[0m\n",
      "\u001b[34malgo-1:135:879 [0] NCCL INFO ncclCommInitRank comm 0x55e8bb79e750 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 101c0 commId 0x71c908fe42bb1072 - Init COMPLETE\u001b[0m\n",
      "\u001b[34malgo-1:139:883 [4] NCCL INFO ncclCommInitRank comm 0x559b076c0830 rank 4 nranks 8 cudaDev 4 nvmlDev 4 busId 901c0 commId 0x71c908fe42bb1072 - Init COMPLETE\u001b[0m\n",
      "\u001b[34malgo-1:140:884 [5] NCCL INFO ncclCommInitRank comm 0x55b4c31a9e70 rank 5 nranks 8 cudaDev 5 nvmlDev 5 busId 901d0 commId 0x71c908fe42bb1072 - Init COMPLETE\u001b[0m\n",
      "\u001b[34malgo-1:136:880 [1] NCCL INFO ncclCommInitRank comm 0x55b83d8c36f0 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 101d0 commId 0x71c908fe42bb1072 - Init COMPLETE\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.\u001b[0m\n",
      "\u001b[34malgo-1:141:886 [6] NCCL INFO ncclCommInitRank comm 0x56473f28db40 rank 6 nranks 8 cudaDev 6 nvmlDev 6 busId a01c0 commId 0x71c908fe42bb1072 - Init COMPLETE\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mDATASET PREPARATION IN PROGRESS...\u001b[0m\n",
      "\u001b[34mDATASET PREPARATION IN PROGRESS...\u001b[0m\n",
      "\u001b[34mDATASET PREPARATION IN PROGRESS...\u001b[0m\n",
      "\u001b[34mDATASET PREPARATION IN PROGRESS...\u001b[0m\n",
      "\u001b[34mDATASET PREPARATION IN PROGRESS...\u001b[0m\n",
      "\u001b[34mDATASET PREPARATION IN PROGRESS...\u001b[0m\n",
      "\u001b[34mDATASET PREPARATION IN PROGRESS...\u001b[0m\n",
      "\u001b[34mDATASET PREPARATION IN PROGRESS...\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 0/3304 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 0/3304 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 0/3304 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 0/3304 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 0/3304 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 0/3304 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 0/3304 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 0/3304 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 1/3304 [00:07<6:28:40,  7.06s/ examples]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 1/3304 [00:06<6:07:04,  6.67s/ examples]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 1/3304 [00:06<6:07:26,  6.67s/ examples]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 1/3304 [00:06<6:08:30,  6.69s/ examples]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 1/3304 [00:06<6:07:53,  6.68s/ examples]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 1/3304 [00:06<6:07:46,  6.68s/ examples]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 1/3304 [00:06<6:09:19,  6.71s/ examples]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 1/3304 [00:06<6:08:50,  6.70s/ examples]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 7/3304 [00:06<39:11,  1.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 8/3304 [00:07<36:04,  1.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 8/3304 [00:06<34:07,  1.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 8/3304 [00:06<34:11,  1.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 7/3304 [00:06<39:20,  1.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 9/3304 [00:06<30:23,  1.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 9/3304 [00:06<30:20,  1.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 8/3304 [00:06<34:17,  1.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 15/3304 [00:06<15:19,  3.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 15/3304 [00:07<16:11,  3.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 14/3304 [00:06<16:17,  3.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 15/3304 [00:06<15:22,  3.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 16/3304 [00:06<14:32,  3.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 16/3304 [00:06<14:34,  3.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 14/3304 [00:06<16:20,  3.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 15/3304 [00:06<15:25,  3.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|          | 21/3304 [00:07<09:10,  5.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|          | 23/3304 [00:07<08:21,  6.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|          | 23/3304 [00:07<08:48,  6.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|          | 24/3304 [00:07<08:06,  6.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|          | 24/3304 [00:07<08:07,  6.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|          | 21/3304 [00:07<09:11,  5.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|          | 23/3304 [00:07<08:23,  6.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|          | 22/3304 [00:07<08:54,  6.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|          | 32/3304 [00:07<05:09, 10.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|          | 31/3304 [00:07<05:26, 10.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|          | 29/3304 [00:07<05:35,  9.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|          | 31/3304 [00:07<05:33,  9.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|          | 31/3304 [00:07<05:18, 10.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|          | 29/3304 [00:07<05:36,  9.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|          | 31/3304 [00:07<05:19, 10.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|          | 30/3304 [00:07<05:30,  9.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|          | 39/3304 [00:07<03:43, 14.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|          | 39/3304 [00:07<03:43, 14.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|          | 37/3304 [00:07<03:48, 14.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|          | 36/3304 [00:07<03:57, 13.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|          | 39/3304 [00:07<03:49, 14.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|          | 39/3304 [00:07<03:40, 14.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|          | 39/3304 [00:07<03:41, 14.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|          | 38/3304 [00:07<03:46, 14.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|▏         | 46/3304 [00:07<02:48, 19.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|▏         | 45/3304 [00:07<03:00, 18.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|▏         | 42/3304 [00:07<03:03, 17.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|▏         | 45/3304 [00:07<02:53, 18.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|▏         | 43/3304 [00:07<02:58, 18.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|▏         | 47/3304 [00:07<02:43, 19.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|▏         | 45/3304 [00:07<02:55, 18.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|▏         | 46/3304 [00:07<02:47, 19.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 53/3304 [00:07<02:11, 24.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|▏         | 48/3304 [00:07<02:25, 22.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|▏         | 49/3304 [00:07<02:22, 22.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 52/3304 [00:07<02:15, 24.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 53/3304 [00:07<02:14, 24.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 55/3304 [00:07<02:06, 25.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 53/3304 [00:07<02:12, 24.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 54/3304 [00:07<02:08, 25.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 61/3304 [00:07<01:43, 31.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 56/3304 [00:07<01:53, 28.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 60/3304 [00:08<01:49, 29.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 56/3304 [00:07<01:51, 29.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 59/3304 [00:07<01:50, 29.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 63/3304 [00:07<01:41, 31.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 60/3304 [00:07<01:47, 30.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 60/3304 [00:07<01:49, 29.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 69/3304 [00:07<01:26, 37.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 63/3304 [00:07<01:32, 34.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 64/3304 [00:07<01:31, 35.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 68/3304 [00:08<01:29, 35.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 67/3304 [00:07<01:29, 36.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 70/3304 [00:07<01:27, 36.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 68/3304 [00:07<01:29, 36.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 68/3304 [00:07<01:30, 35.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 76/3304 [00:07<01:16, 42.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 70/3304 [00:07<01:23, 38.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 70/3304 [00:07<01:22, 39.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 77/3304 [00:07<01:16, 42.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 74/3304 [00:07<01:21, 39.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 78/3304 [00:08<01:16, 42.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 77/3304 [00:07<01:16, 41.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 75/3304 [00:07<01:21, 39.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 76/3304 [00:07<01:15, 42.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 84/3304 [00:07<01:07, 47.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 77/3304 [00:07<01:12, 44.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 84/3304 [00:08<01:08, 46.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 81/3304 [00:08<01:12, 44.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 84/3304 [00:08<01:09, 46.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 86/3304 [00:08<01:08, 46.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 82/3304 [00:08<01:12, 44.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 84/3304 [00:08<01:07, 47.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 92/3304 [00:08<01:01, 52.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 84/3304 [00:08<01:07, 47.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 92/3304 [00:08<01:02, 51.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 91/3304 [00:08<01:03, 50.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 89/3304 [00:08<01:06, 48.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 93/3304 [00:08<01:03, 50.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 90/3304 [00:08<01:05, 48.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 91/3304 [00:08<01:02, 51.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 99/3304 [00:08<00:58, 54.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 91/3304 [00:08<01:02, 51.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 99/3304 [00:08<00:58, 54.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 98/3304 [00:08<01:00, 52.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 97/3304 [00:08<01:01, 51.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 97/3304 [00:08<01:01, 51.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 102/3304 [00:08<01:00, 52.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 106/3304 [00:08<00:56, 56.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 98/3304 [00:08<01:00, 53.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 98/3304 [00:08<01:00, 53.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 106/3304 [00:08<00:57, 55.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 103/3304 [00:08<01:00, 53.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 106/3304 [00:08<00:58, 54.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 103/3304 [00:08<01:00, 52.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 104/3304 [00:08<00:59, 54.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 105/3304 [00:08<00:58, 54.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 110/3304 [00:08<00:58, 54.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 114/3304 [00:08<00:54, 58.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 114/3304 [00:08<00:55, 57.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 110/3304 [00:08<00:59, 53.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 114/3304 [00:08<00:57, 55.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 110/3304 [00:08<00:59, 53.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 110/3304 [00:08<00:59, 54.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 111/3304 [00:08<00:58, 54.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▎         | 122/3304 [00:08<00:52, 61.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▎         | 118/3304 [00:08<00:55, 57.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▎         | 122/3304 [00:08<00:53, 59.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▎         | 117/3304 [00:08<00:56, 56.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▎         | 122/3304 [00:08<00:54, 58.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▎         | 118/3304 [00:08<00:56, 56.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▎         | 118/3304 [00:08<00:56, 56.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▎         | 118/3304 [00:08<00:56, 56.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▍         | 129/3304 [00:08<00:53, 59.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▍         | 126/3304 [00:09<00:54, 58.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▍         | 129/3304 [00:08<00:53, 59.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▍         | 125/3304 [00:08<00:54, 58.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▍         | 125/3304 [00:08<00:54, 58.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▍         | 129/3304 [00:08<00:55, 57.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▍         | 136/3304 [00:08<00:52, 60.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▍         | 126/3304 [00:08<00:55, 57.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▍         | 126/3304 [00:08<00:55, 57.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▍         | 133/3304 [00:09<00:54, 57.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▍         | 136/3304 [00:08<00:52, 60.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▍         | 136/3304 [00:08<00:54, 58.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▍         | 131/3304 [00:08<00:57, 55.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▍         | 132/3304 [00:08<00:57, 55.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▍         | 144/3304 [00:08<00:51, 61.01 examples/s]#015Map:   4%|▍         | 132/3304 [00:08<00:56, 55.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▍         | 135/3304 [00:08<00:55, 56.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▍         | 140/3304 [00:09<00:53, 58.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▍         | 144/3304 [00:08<00:51, 60.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▍         | 143/3304 [00:09<00:52, 59.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▍         | 139/3304 [00:09<00:55, 57.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▍         | 139/3304 [00:09<00:54, 57.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▍         | 140/3304 [00:09<00:54, 58.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▍         | 147/3304 [00:09<00:52, 59.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▍         | 151/3304 [00:09<00:52, 60.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▍         | 142/3304 [00:09<00:54, 57.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▍         | 151/3304 [00:09<00:53, 59.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▍         | 146/3304 [00:09<00:53, 58.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▍         | 148/3304 [00:09<00:55, 56.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▍         | 147/3304 [00:09<00:54, 57.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▍         | 152/3304 [00:09<00:55, 57.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▍         | 147/3304 [00:09<00:54, 57.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▍         | 158/3304 [00:09<00:53, 59.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▍         | 156/3304 [00:09<00:53, 58.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▍         | 161/3304 [00:09<00:52, 60.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▍         | 152/3304 [00:09<00:56, 55.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▍         | 154/3304 [00:09<00:55, 56.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▍         | 153/3304 [00:09<00:54, 57.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▍         | 153/3304 [00:09<00:55, 56.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▍         | 160/3304 [00:09<00:53, 58.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▍         | 163/3304 [00:09<00:52, 59.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▌         | 166/3304 [00:09<00:51, 60.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▌         | 168/3304 [00:09<00:52, 60.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▍         | 161/3304 [00:09<00:55, 56.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▍         | 160/3304 [00:09<00:54, 57.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▍         | 160/3304 [00:09<00:55, 56.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▍         | 160/3304 [00:09<00:54, 57.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▌         | 168/3304 [00:09<00:53, 58.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▌         | 176/3304 [00:09<00:50, 62.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▌         | 174/3304 [00:09<00:51, 61.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▌         | 173/3304 [00:09<00:52, 59.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▌         | 166/3304 [00:09<00:55, 56.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▌         | 168/3304 [00:09<00:54, 57.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▌         | 166/3304 [00:09<00:55, 56.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▌         | 168/3304 [00:09<00:55, 56.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▌         | 184/3304 [00:09<00:49, 63.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▌         | 182/3304 [00:09<00:49, 62.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▌         | 176/3304 [00:09<00:52, 59.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▌         | 181/3304 [00:09<00:50, 61.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▌         | 174/3304 [00:09<00:54, 57.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▌         | 173/3304 [00:09<00:54, 57.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▌         | 174/3304 [00:09<00:54, 57.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▌         | 176/3304 [00:09<00:53, 58.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▌         | 192/3304 [00:09<00:48, 64.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▌         | 190/3304 [00:09<00:49, 62.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▌         | 184/3304 [00:09<00:51, 60.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▌         | 189/3304 [00:10<00:49, 62.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▌         | 182/3304 [00:09<00:52, 59.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▌         | 181/3304 [00:09<00:52, 58.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▌         | 182/3304 [00:09<00:52, 59.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▌         | 183/3304 [00:09<00:52, 59.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▌         | 197/3304 [00:09<00:50, 62.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▌         | 192/3304 [00:09<00:50, 61.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▌         | 200/3304 [00:09<00:49, 62.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▌         | 196/3304 [00:10<00:50, 61.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▌         | 190/3304 [00:09<00:51, 60.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▌         | 189/3304 [00:09<00:51, 60.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▌         | 189/3304 [00:09<00:51, 60.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▌         | 190/3304 [00:09<00:52, 59.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▌         | 204/3304 [00:09<00:49, 63.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▋         | 208/3304 [00:09<00:48, 64.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▌         | 203/3304 [00:10<00:50, 61.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▌         | 200/3304 [00:09<00:51, 60.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▌         | 196/3304 [00:10<00:52, 59.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▌         | 196/3304 [00:10<00:52, 59.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▌         | 197/3304 [00:10<00:52, 58.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▌         | 199/3304 [00:10<00:52, 58.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▋         | 211/3304 [00:10<00:49, 63.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 215/3304 [00:10<00:48, 63.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▋         | 208/3304 [00:10<00:49, 62.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▋         | 211/3304 [00:10<00:49, 61.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▌         | 202/3304 [00:10<00:52, 59.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▌         | 203/3304 [00:10<00:52, 59.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▌         | 205/3304 [00:10<00:51, 59.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▋         | 207/3304 [00:10<00:51, 59.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 219/3304 [00:10<00:49, 62.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 223/3304 [00:10<00:48, 62.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 215/3304 [00:10<00:50, 61.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▋         | 209/3304 [00:10<00:51, 60.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 219/3304 [00:10<00:50, 61.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▋         | 211/3304 [00:10<00:51, 59.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 226/3304 [00:10<00:49, 61.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▋         | 213/3304 [00:10<00:52, 59.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 215/3304 [00:10<00:52, 59.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 231/3304 [00:10<00:48, 62.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 222/3304 [00:10<00:51, 60.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 227/3304 [00:10<00:49, 61.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 218/3304 [00:10<00:52, 59.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 219/3304 [00:10<00:52, 59.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 234/3304 [00:10<00:48, 62.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 223/3304 [00:10<00:52, 58.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 221/3304 [00:10<00:52, 58.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 239/3304 [00:10<00:48, 62.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 230/3304 [00:10<00:50, 61.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 234/3304 [00:10<00:49, 61.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 224/3304 [00:10<00:52, 58.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 227/3304 [00:10<00:51, 59.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 242/3304 [00:10<00:49, 62.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 229/3304 [00:10<00:51, 59.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 231/3304 [00:10<00:51, 59.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 247/3304 [00:10<00:47, 63.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 241/3304 [00:10<00:49, 61.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 232/3304 [00:10<00:51, 59.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 240/3304 [00:10<00:51, 59.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 234/3304 [00:10<00:51, 59.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 250/3304 [00:10<00:47, 63.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 235/3304 [00:10<00:52, 58.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 254/3304 [00:10<00:47, 64.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 239/3304 [00:10<00:51, 59.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 249/3304 [00:11<00:48, 62.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 248/3304 [00:10<00:49, 61.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 240/3304 [00:10<00:51, 58.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 241/3304 [00:10<00:51, 59.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 257/3304 [00:10<00:48, 62.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 262/3304 [00:10<00:46, 64.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 243/3304 [00:10<00:51, 59.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 247/3304 [00:10<00:51, 59.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 257/3304 [00:11<00:49, 61.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 248/3304 [00:10<00:50, 60.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 256/3304 [00:10<00:49, 61.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 248/3304 [00:10<00:50, 60.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 264/3304 [00:10<00:48, 62.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 270/3304 [00:10<00:46, 65.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 251/3304 [00:10<00:50, 60.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 254/3304 [00:10<00:51, 59.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 264/3304 [00:11<00:49, 61.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 263/3304 [00:10<00:49, 61.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 255/3304 [00:11<00:51, 59.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 256/3304 [00:11<00:50, 60.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 272/3304 [00:11<00:47, 63.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 277/3304 [00:11<00:46, 65.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 261/3304 [00:11<00:50, 59.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 272/3304 [00:11<00:48, 62.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 261/3304 [00:11<00:50, 59.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 271/3304 [00:11<00:48, 62.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 262/3304 [00:11<00:50, 59.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 263/3304 [00:11<00:51, 59.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▊         | 284/3304 [00:11<00:46, 65.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 280/3304 [00:11<00:48, 62.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 268/3304 [00:11<00:50, 60.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 279/3304 [00:11<00:49, 61.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 268/3304 [00:11<00:50, 59.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 268/3304 [00:11<00:50, 59.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 270/3304 [00:11<00:50, 60.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 278/3304 [00:11<00:49, 60.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▉         | 292/3304 [00:11<00:46, 65.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▊         | 288/3304 [00:11<00:48, 62.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▊         | 287/3304 [00:11<00:49, 61.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 275/3304 [00:11<00:50, 59.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 277/3304 [00:11<00:50, 59.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 276/3304 [00:11<00:50, 59.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▊         | 285/3304 [00:11<00:49, 60.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 277/3304 [00:11<00:50, 59.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▉         | 295/3304 [00:11<00:48, 62.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▉         | 300/3304 [00:11<00:46, 64.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▊         | 283/3304 [00:11<00:51, 59.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▊         | 282/3304 [00:11<00:50, 59.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▉         | 295/3304 [00:11<00:49, 60.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▉         | 292/3304 [00:11<00:49, 61.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▊         | 283/3304 [00:11<00:51, 59.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▊         | 284/3304 [00:11<00:50, 59.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▉         | 302/3304 [00:11<00:47, 62.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▉         | 308/3304 [00:11<00:45, 65.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▉         | 290/3304 [00:11<00:50, 59.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▊         | 289/3304 [00:11<00:51, 58.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▉         | 302/3304 [00:11<00:49, 60.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▉         | 299/3304 [00:11<00:49, 60.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▉         | 290/3304 [00:11<00:51, 58.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▉         | 291/3304 [00:11<00:51, 59.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▉         | 310/3304 [00:11<00:46, 63.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|▉         | 316/3304 [00:11<00:46, 64.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▉         | 296/3304 [00:11<00:51, 58.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▉         | 309/3304 [00:12<00:48, 61.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▉         | 296/3304 [00:11<00:51, 58.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▉         | 296/3304 [00:11<00:51, 58.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▉         | 307/3304 [00:11<00:48, 61.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▉         | 299/3304 [00:11<00:49, 60.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|▉         | 317/3304 [00:11<00:47, 62.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|▉         | 324/3304 [00:11<00:45, 65.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▉         | 304/3304 [00:11<00:50, 59.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|▉         | 316/3304 [00:12<00:49, 59.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▉         | 304/3304 [00:11<00:50, 59.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|▉         | 314/3304 [00:11<00:49, 60.89 examples/s]#015Map:   9%|▉         | 304/3304 [00:11<00:50, 59.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▉         | 306/3304 [00:11<00:49, 60.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|▉         | 325/3304 [00:11<00:46, 63.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|█         | 331/3304 [00:11<00:45, 64.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▉         | 312/3304 [00:11<00:50, 59.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|▉         | 323/3304 [00:12<00:50, 59.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▉         | 311/3304 [00:11<00:50, 59.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|▉         | 322/3304 [00:11<00:49, 60.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▉         | 312/3304 [00:11<00:50, 58.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|█         | 339/3304 [00:11<00:45, 64.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|█         | 333/3304 [00:12<00:48, 61.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|▉         | 316/3304 [00:12<00:50, 59.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|▉         | 319/3304 [00:12<00:50, 59.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|▉         | 330/3304 [00:12<00:50, 58.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|▉         | 318/3304 [00:12<00:51, 58.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|▉         | 329/3304 [00:12<00:49, 60.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|▉         | 319/3304 [00:12<00:50, 58.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█         | 347/3304 [00:12<00:45, 65.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|█         | 341/3304 [00:12<00:47, 62.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|▉         | 323/3304 [00:12<00:50, 59.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|█         | 337/3304 [00:12<00:50, 58.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|▉         | 327/3304 [00:12<00:49, 59.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|▉         | 326/3304 [00:12<00:49, 60.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|█         | 337/3304 [00:12<00:48, 60.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|▉         | 327/3304 [00:12<00:50, 59.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█         | 355/3304 [00:12<00:45, 65.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█         | 349/3304 [00:12<00:47, 62.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|█         | 331/3304 [00:12<00:50, 58.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|█         | 333/3304 [00:12<00:50, 58.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|█         | 345/3304 [00:12<00:50, 58.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|█         | 333/3304 [00:12<00:50, 58.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|█         | 345/3304 [00:12<00:48, 60.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█         | 363/3304 [00:12<00:45, 64.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|█         | 335/3304 [00:12<00:51, 57.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█         | 357/3304 [00:12<00:46, 63.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|█         | 338/3304 [00:12<00:50, 58.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|█         | 340/3304 [00:12<00:49, 59.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|█         | 340/3304 [00:12<00:50, 59.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█         | 353/3304 [00:12<00:49, 59.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|█         | 341/3304 [00:12<00:51, 57.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█         | 370/3304 [00:12<00:47, 62.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█         | 353/3304 [00:12<00:48, 60.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█         | 364/3304 [00:12<00:47, 61.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|█         | 345/3304 [00:12<00:50, 59.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█         | 347/3304 [00:12<00:49, 59.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█         | 347/3304 [00:12<00:49, 59.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█         | 361/3304 [00:12<00:49, 60.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█         | 348/3304 [00:12<00:50, 58.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█▏        | 378/3304 [00:12<00:45, 63.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█         | 371/3304 [00:12<00:47, 61.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█         | 361/3304 [00:12<00:48, 60.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█         | 353/3304 [00:12<00:49, 59.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█         | 352/3304 [00:12<00:49, 59.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█         | 355/3304 [00:12<00:49, 59.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█         | 355/3304 [00:12<00:50, 58.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 385/3304 [00:12<00:45, 63.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█         | 359/3304 [00:12<00:49, 58.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█▏        | 379/3304 [00:12<00:46, 62.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█         | 368/3304 [00:12<00:48, 60.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█         | 359/3304 [00:12<00:49, 59.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█         | 370/3304 [00:13<00:50, 57.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█         | 362/3304 [00:12<00:49, 59.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█         | 362/3304 [00:12<00:49, 58.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 393/3304 [00:12<00:44, 65.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 386/3304 [00:12<00:46, 63.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█         | 366/3304 [00:12<00:49, 58.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█▏        | 375/3304 [00:12<00:49, 59.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█         | 366/3304 [00:12<00:49, 59.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█▏        | 378/3304 [00:13<00:49, 58.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█         | 369/3304 [00:12<00:49, 59.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 400/3304 [00:12<00:45, 64.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█         | 369/3304 [00:12<00:49, 58.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 394/3304 [00:12<00:45, 63.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 383/3304 [00:12<00:47, 61.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█▏        | 374/3304 [00:12<00:50, 58.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 385/3304 [00:13<00:49, 59.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█▏        | 374/3304 [00:12<00:49, 58.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 407/3304 [00:13<00:46, 62.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█▏        | 376/3304 [00:13<00:49, 59.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█▏        | 376/3304 [00:13<00:50, 58.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 380/3304 [00:13<00:50, 58.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 390/3304 [00:13<00:47, 61.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 402/3304 [00:13<00:46, 62.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 393/3304 [00:13<00:48, 59.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 382/3304 [00:13<00:49, 59.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 383/3304 [00:13<00:48, 59.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 415/3304 [00:13<00:45, 64.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 383/3304 [00:13<00:49, 58.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 387/3304 [00:13<00:49, 59.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 397/3304 [00:13<00:47, 61.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 410/3304 [00:13<00:45, 62.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 399/3304 [00:13<00:49, 58.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 389/3304 [00:13<00:49, 59.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 423/3304 [00:13<00:43, 65.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 390/3304 [00:13<00:49, 59.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 390/3304 [00:13<00:49, 58.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 394/3304 [00:13<00:49, 58.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 418/3304 [00:13<00:44, 64.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 395/3304 [00:13<00:48, 59.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 406/3304 [00:13<00:50, 57.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 406/3304 [00:13<00:49, 58.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 396/3304 [00:13<00:48, 59.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 396/3304 [00:13<00:49, 58.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 430/3304 [00:13<00:45, 63.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 401/3304 [00:13<00:50, 57.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 426/3304 [00:13<00:44, 64.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 412/3304 [00:13<00:49, 58.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 401/3304 [00:13<00:50, 57.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 414/3304 [00:13<00:48, 59.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 402/3304 [00:13<00:51, 56.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 437/3304 [00:13<00:45, 63.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 402/3304 [00:13<00:52, 55.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 407/3304 [00:13<00:50, 57.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 433/3304 [00:13<00:44, 64.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 419/3304 [00:13<00:48, 59.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 408/3304 [00:13<00:50, 57.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 421/3304 [00:13<00:48, 60.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 444/3304 [00:13<00:45, 62.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 410/3304 [00:13<00:49, 57.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 409/3304 [00:13<00:50, 56.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 414/3304 [00:13<00:49, 58.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 440/3304 [00:13<00:45, 63.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 426/3304 [00:14<00:48, 59.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 415/3304 [00:13<00:49, 58.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 428/3304 [00:13<00:48, 59.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▎        | 451/3304 [00:13<00:45, 62.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 416/3304 [00:13<00:49, 58.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 417/3304 [00:13<00:49, 58.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 421/3304 [00:13<00:49, 58.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 422/3304 [00:13<00:49, 58.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 433/3304 [00:14<00:48, 59.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▎        | 448/3304 [00:13<00:45, 63.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 436/3304 [00:13<00:47, 60.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 422/3304 [00:13<00:49, 58.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▍        | 459/3304 [00:13<00:44, 64.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 425/3304 [00:13<00:48, 59.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 439/3304 [00:14<00:48, 58.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 428/3304 [00:13<00:49, 58.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 429/3304 [00:13<00:48, 58.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▍        | 455/3304 [00:13<00:45, 62.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 443/3304 [00:13<00:47, 60.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 429/3304 [00:13<00:49, 58.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▍        | 466/3304 [00:13<00:45, 62.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 432/3304 [00:14<00:48, 59.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 436/3304 [00:14<00:48, 58.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▎        | 447/3304 [00:14<00:48, 59.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▍        | 463/3304 [00:14<00:45, 62.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 436/3304 [00:14<00:48, 59.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 436/3304 [00:14<00:48, 58.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▎        | 450/3304 [00:14<00:47, 59.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▍        | 474/3304 [00:14<00:44, 64.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 439/3304 [00:14<00:48, 59.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▍        | 470/3304 [00:14<00:45, 62.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 443/3304 [00:14<00:48, 58.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▎        | 454/3304 [00:14<00:48, 58.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 443/3304 [00:14<00:48, 59.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▍        | 482/3304 [00:14<00:42, 65.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 443/3304 [00:14<00:48, 58.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▍        | 458/3304 [00:14<00:46, 61.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 446/3304 [00:14<00:48, 58.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▍        | 461/3304 [00:14<00:47, 59.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▍        | 478/3304 [00:14<00:44, 64.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▎        | 450/3304 [00:14<00:48, 58.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▎        | 450/3304 [00:14<00:49, 58.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▎        | 449/3304 [00:14<00:49, 58.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▍        | 489/3304 [00:14<00:43, 64.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▍        | 465/3304 [00:14<00:47, 60.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▎        | 454/3304 [00:14<00:48, 59.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▍        | 468/3304 [00:14<00:47, 59.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▍        | 486/3304 [00:14<00:43, 64.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▍        | 458/3304 [00:14<00:47, 60.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▍        | 458/3304 [00:14<00:47, 60.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▍        | 456/3304 [00:14<00:48, 58.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▌        | 497/3304 [00:14<00:42, 65.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▍        | 473/3304 [00:14<00:46, 61.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▍        | 462/3304 [00:14<00:46, 60.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▍        | 493/3304 [00:14<00:43, 64.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▍        | 475/3304 [00:14<00:47, 59.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▍        | 465/3304 [00:14<00:46, 60.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▍        | 465/3304 [00:14<00:47, 60.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▍        | 463/3304 [00:14<00:48, 58.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▍        | 481/3304 [00:14<00:44, 63.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▌        | 506/3304 [00:14<00:44, 62.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▍        | 469/3304 [00:14<00:46, 60.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▌        | 500/3304 [00:14<00:44, 63.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▍        | 483/3304 [00:15<00:46, 60.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▍        | 473/3304 [00:14<00:46, 61.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▍        | 469/3304 [00:14<00:48, 58.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▍        | 473/3304 [00:14<00:46, 61.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▍        | 477/3304 [00:14<00:45, 61.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▍        | 491/3304 [00:14<00:45, 62.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▌        | 507/3304 [00:14<00:45, 61.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▍        | 490/3304 [00:15<00:46, 60.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▍        | 481/3304 [00:14<00:44, 63.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▌        | 516/3304 [00:14<00:45, 61.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▍        | 476/3304 [00:14<00:47, 59.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▍        | 481/3304 [00:14<00:44, 63.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▍        | 485/3304 [00:14<00:44, 62.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▌        | 499/3304 [00:14<00:44, 63.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▍        | 488/3304 [00:14<00:45, 62.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▌        | 498/3304 [00:15<00:45, 61.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▍        | 483/3304 [00:14<00:46, 60.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▌        | 523/3304 [00:14<00:45, 60.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▍        | 489/3304 [00:14<00:44, 62.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▌        | 517/3304 [00:14<00:45, 61.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▍        | 493/3304 [00:14<00:44, 62.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▌        | 496/3304 [00:14<00:43, 63.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▌        | 530/3304 [00:15<00:45, 61.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▍        | 491/3304 [00:15<00:46, 60.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▌        | 497/3304 [00:15<00:44, 63.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▌        | 508/3304 [00:15<00:46, 59.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▌        | 524/3304 [00:15<00:47, 59.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▌        | 507/3304 [00:15<00:48, 58.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▌        | 500/3304 [00:15<00:44, 62.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▋        | 537/3304 [00:15<00:45, 61.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▌        | 504/3304 [00:15<00:44, 62.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▌        | 499/3304 [00:15<00:45, 61.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▌        | 504/3304 [00:15<00:45, 61.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▌        | 532/3304 [00:15<00:45, 61.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▌        | 516/3304 [00:15<00:46, 59.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▌        | 515/3304 [00:15<00:47, 58.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▋        | 544/3304 [00:15<00:46, 59.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▌        | 509/3304 [00:15<00:46, 59.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▋        | 539/3304 [00:15<00:44, 61.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▌        | 513/3304 [00:15<00:46, 59.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▌        | 523/3304 [00:15<00:47, 58.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▌        | 513/3304 [00:15<00:46, 59.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▌        | 508/3304 [00:15<00:48, 57.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▌        | 522/3304 [00:15<00:48, 57.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 551/3304 [00:15<00:46, 59.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▌        | 516/3304 [00:15<00:46, 60.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▌        | 529/3304 [00:15<00:48, 57.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▌        | 520/3304 [00:15<00:46, 59.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▌        | 528/3304 [00:15<00:48, 57.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▌        | 520/3304 [00:15<00:46, 59.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▌        | 516/3304 [00:15<00:48, 58.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 549/3304 [00:15<00:47, 57.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 558/3304 [00:15<00:45, 60.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▌        | 526/3304 [00:15<00:47, 58.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▌        | 535/3304 [00:15<00:48, 57.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▋        | 537/3304 [00:15<00:47, 58.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▌        | 525/3304 [00:15<00:47, 58.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▌        | 528/3304 [00:15<00:46, 59.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▌        | 523/3304 [00:15<00:48, 56.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 566/3304 [00:15<00:44, 62.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 557/3304 [00:15<00:46, 59.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▌        | 534/3304 [00:15<00:45, 60.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▋        | 542/3304 [00:16<00:48, 56.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▌        | 533/3304 [00:15<00:46, 59.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▋        | 544/3304 [00:15<00:48, 56.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▌        | 529/3304 [00:15<00:49, 56.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▌        | 536/3304 [00:15<00:46, 59.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 565/3304 [00:15<00:44, 61.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 574/3304 [00:15<00:43, 62.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▋        | 541/3304 [00:15<00:47, 58.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 548/3304 [00:16<00:49, 55.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▋        | 540/3304 [00:15<00:45, 60.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 550/3304 [00:15<00:49, 55.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▌        | 536/3304 [00:15<00:47, 57.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 581/3304 [00:15<00:43, 62.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▋        | 543/3304 [00:15<00:47, 57.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 573/3304 [00:15<00:43, 62.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 547/3304 [00:15<00:47, 57.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 557/3304 [00:15<00:48, 57.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 556/3304 [00:16<00:48, 56.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▋        | 542/3304 [00:15<00:49, 55.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 548/3304 [00:15<00:47, 57.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 550/3304 [00:15<00:47, 58.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 580/3304 [00:15<00:43, 62.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 589/3304 [00:15<00:43, 62.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 554/3304 [00:15<00:46, 59.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 565/3304 [00:16<00:46, 58.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 548/3304 [00:16<00:49, 55.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 564/3304 [00:16<00:46, 58.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 555/3304 [00:16<00:46, 58.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 557/3304 [00:16<00:46, 59.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 588/3304 [00:16<00:43, 62.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 597/3304 [00:16<00:42, 63.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 561/3304 [00:16<00:45, 60.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 572/3304 [00:16<00:45, 59.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 555/3304 [00:16<00:48, 56.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 562/3304 [00:16<00:46, 59.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 572/3304 [00:16<00:45, 59.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 565/3304 [00:16<00:44, 61.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 604/3304 [00:16<00:42, 63.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 596/3304 [00:16<00:43, 62.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 569/3304 [00:16<00:44, 60.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 562/3304 [00:16<00:47, 58.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 580/3304 [00:16<00:45, 59.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 570/3304 [00:16<00:44, 61.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 573/3304 [00:16<00:43, 62.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 580/3304 [00:16<00:45, 59.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▊        | 612/3304 [00:16<00:43, 62.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 604/3304 [00:16<00:43, 62.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 576/3304 [00:16<00:44, 61.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 569/3304 [00:16<00:46, 58.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 577/3304 [00:16<00:44, 61.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 588/3304 [00:16<00:45, 59.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 580/3304 [00:16<00:44, 61.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 611/3304 [00:16<00:42, 62.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 588/3304 [00:16<00:45, 59.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▊        | 619/3304 [00:16<00:44, 60.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 583/3304 [00:16<00:43, 61.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 576/3304 [00:16<00:46, 58.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 584/3304 [00:16<00:44, 61.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 595/3304 [00:16<00:45, 59.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 587/3304 [00:16<00:43, 61.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▉        | 626/3304 [00:16<00:43, 61.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 595/3304 [00:16<00:45, 59.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 590/3304 [00:16<00:43, 62.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▊        | 618/3304 [00:16<00:44, 59.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 584/3304 [00:16<00:45, 59.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 592/3304 [00:16<00:43, 62.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 594/3304 [00:16<00:43, 61.87 examples/s]#015Map:  18%|█▊        | 602/3304 [00:16<00:45, 59.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▉        | 633/3304 [00:16<00:43, 61.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 602/3304 [00:17<00:45, 59.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▉        | 625/3304 [00:16<00:44, 60.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 598/3304 [00:16<00:43, 62.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 609/3304 [00:16<00:44, 60.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 592/3304 [00:16<00:45, 59.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 602/3304 [00:16<00:43, 61.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▉        | 640/3304 [00:16<00:43, 60.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 609/3304 [00:17<00:44, 60.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▉        | 632/3304 [00:16<00:43, 60.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 602/3304 [00:16<00:44, 61.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 606/3304 [00:16<00:42, 62.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 609/3304 [00:16<00:42, 63.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 600/3304 [00:16<00:45, 59.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|█▉        | 647/3304 [00:16<00:43, 60.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 609/3304 [00:16<00:43, 62.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▊        | 619/3304 [00:16<00:46, 58.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▊        | 613/3304 [00:16<00:45, 59.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▊        | 618/3304 [00:17<00:46, 57.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▉        | 642/3304 [00:16<00:44, 59.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|█▉        | 654/3304 [00:17<00:43, 60.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 608/3304 [00:17<00:44, 60.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▊        | 619/3304 [00:17<00:44, 60.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▉        | 626/3304 [00:17<00:46, 57.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▉        | 625/3304 [00:17<00:46, 58.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▉        | 621/3304 [00:17<00:44, 60.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▊        | 619/3304 [00:17<00:44, 59.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|█▉        | 650/3304 [00:17<00:43, 60.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|██        | 661/3304 [00:17<00:45, 58.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▉        | 626/3304 [00:17<00:44, 60.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▉        | 633/3304 [00:17<00:45, 58.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▊        | 616/3304 [00:17<00:47, 57.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▉        | 628/3304 [00:17<00:43, 61.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▉        | 632/3304 [00:17<00:45, 58.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▉        | 626/3304 [00:17<00:44, 60.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|█▉        | 657/3304 [00:17<00:43, 60.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|██        | 669/3304 [00:17<00:42, 62.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▉        | 633/3304 [00:17<00:43, 60.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▉        | 623/3304 [00:17<00:46, 58.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▉        | 638/3304 [00:17<00:46, 57.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▉        | 640/3304 [00:17<00:46, 57.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▉        | 635/3304 [00:17<00:44, 60.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▉        | 633/3304 [00:17<00:43, 60.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|██        | 664/3304 [00:17<00:43, 60.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|██        | 677/3304 [00:17<00:41, 63.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▉        | 640/3304 [00:17<00:44, 60.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▉        | 644/3304 [00:17<00:46, 57.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▉        | 630/3304 [00:17<00:45, 58.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|█▉        | 647/3304 [00:17<00:45, 58.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▉        | 642/3304 [00:17<00:45, 59.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▉        | 640/3304 [00:17<00:44, 59.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|██        | 672/3304 [00:17<00:42, 61.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██        | 685/3304 [00:17<00:41, 63.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|█▉        | 651/3304 [00:17<00:44, 58.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|█▉        | 647/3304 [00:17<00:43, 60.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|█▉        | 653/3304 [00:17<00:45, 58.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▉        | 636/3304 [00:17<00:46, 56.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|█▉        | 647/3304 [00:17<00:44, 60.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|█▉        | 650/3304 [00:17<00:43, 60.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██        | 680/3304 [00:17<00:41, 63.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|█▉        | 657/3304 [00:18<00:45, 57.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██        | 693/3304 [00:17<00:40, 64.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|█▉        | 659/3304 [00:17<00:45, 57.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|█▉        | 654/3304 [00:17<00:44, 60.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▉        | 643/3304 [00:17<00:46, 57.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|█▉        | 654/3304 [00:17<00:44, 59.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|█▉        | 657/3304 [00:17<00:43, 60.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██        | 687/3304 [00:17<00:41, 62.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|██        | 663/3304 [00:18<00:46, 57.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|██        | 666/3304 [00:17<00:45, 57.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██        | 701/3304 [00:17<00:41, 62.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|█▉        | 650/3304 [00:17<00:45, 58.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|██        | 661/3304 [00:17<00:44, 59.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|██        | 664/3304 [00:17<00:44, 59.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|██        | 664/3304 [00:17<00:44, 59.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██        | 695/3304 [00:17<00:41, 62.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|██        | 671/3304 [00:18<00:44, 58.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|█▉        | 656/3304 [00:17<00:45, 57.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|██        | 674/3304 [00:17<00:44, 59.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██▏       | 709/3304 [00:17<00:40, 63.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|██        | 668/3304 [00:17<00:43, 60.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|██        | 672/3304 [00:17<00:42, 61.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|██        | 672/3304 [00:17<00:43, 60.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██▏       | 703/3304 [00:17<00:41, 62.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██        | 678/3304 [00:18<00:44, 59.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██        | 681/3304 [00:17<00:43, 60.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|██        | 664/3304 [00:18<00:46, 57.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 717/3304 [00:18<00:41, 62.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|██        | 676/3304 [00:18<00:42, 61.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██        | 680/3304 [00:18<00:41, 62.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██        | 680/3304 [00:18<00:42, 62.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 711/3304 [00:18<00:41, 62.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██        | 685/3304 [00:18<00:44, 58.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|██        | 671/3304 [00:18<00:44, 58.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 724/3304 [00:18<00:41, 61.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██        | 684/3304 [00:18<00:42, 61.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██        | 691/3304 [00:18<00:44, 59.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██        | 690/3304 [00:18<00:42, 62.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██        | 690/3304 [00:18<00:42, 61.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 721/3304 [00:18<00:41, 62.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██        | 693/3304 [00:18<00:43, 59.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██        | 678/3304 [00:18<00:44, 59.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 731/3304 [00:18<00:41, 61.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██        | 691/3304 [00:18<00:42, 61.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██        | 699/3304 [00:18<00:44, 58.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██        | 697/3304 [00:18<00:42, 61.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██        | 697/3304 [00:18<00:42, 61.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██        | 700/3304 [00:18<00:44, 58.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██        | 685/3304 [00:18<00:44, 59.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 738/3304 [00:18<00:41, 61.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 731/3304 [00:18<00:42, 60.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██        | 699/3304 [00:18<00:42, 61.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██▏       | 705/3304 [00:18<00:44, 58.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██▏       | 707/3304 [00:18<00:43, 59.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██        | 692/3304 [00:18<00:43, 59.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██▏       | 707/3304 [00:18<00:42, 61.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 746/3304 [00:18<00:41, 62.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██▏       | 707/3304 [00:18<00:42, 61.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 738/3304 [00:18<00:42, 60.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 712/3304 [00:18<00:44, 58.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██▏       | 707/3304 [00:18<00:42, 61.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██        | 699/3304 [00:18<00:44, 58.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 714/3304 [00:18<00:44, 58.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 753/3304 [00:18<00:41, 61.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 714/3304 [00:18<00:42, 60.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 714/3304 [00:18<00:43, 60.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 719/3304 [00:18<00:44, 58.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 746/3304 [00:18<00:42, 60.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 714/3304 [00:18<00:42, 60.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 721/3304 [00:19<00:43, 59.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██▏       | 706/3304 [00:18<00:44, 58.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 721/3304 [00:18<00:42, 61.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 761/3304 [00:18<00:40, 63.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 721/3304 [00:18<00:42, 60.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 725/3304 [00:18<00:45, 56.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 753/3304 [00:18<00:41, 60.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 722/3304 [00:18<00:43, 60.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 727/3304 [00:19<00:45, 56.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 768/3304 [00:18<00:40, 62.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 713/3304 [00:18<00:44, 58.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 761/3304 [00:18<00:40, 62.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 731/3304 [00:18<00:43, 59.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 733/3304 [00:18<00:45, 56.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 731/3304 [00:18<00:43, 59.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 729/3304 [00:18<00:43, 59.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 734/3304 [00:19<00:45, 56.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 720/3304 [00:18<00:43, 58.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 776/3304 [00:18<00:39, 63.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 768/3304 [00:19<00:40, 62.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 738/3304 [00:19<00:43, 58.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 737/3304 [00:19<00:43, 58.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 740/3304 [00:19<00:45, 56.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 737/3304 [00:19<00:43, 59.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 741/3304 [00:19<00:44, 57.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 726/3304 [00:19<00:45, 56.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▎       | 784/3304 [00:19<00:39, 63.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 744/3304 [00:19<00:43, 58.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 776/3304 [00:19<00:39, 63.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 745/3304 [00:19<00:43, 59.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 747/3304 [00:19<00:44, 57.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 745/3304 [00:19<00:42, 59.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 748/3304 [00:19<00:44, 57.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 733/3304 [00:19<00:45, 56.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▍       | 791/3304 [00:19<00:41, 60.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 752/3304 [00:19<00:42, 60.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▎       | 784/3304 [00:19<00:40, 62.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 754/3304 [00:19<00:43, 58.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 752/3304 [00:19<00:42, 59.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 752/3304 [00:19<00:42, 59.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 739/3304 [00:19<00:45, 56.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 756/3304 [00:19<00:43, 58.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▍       | 799/3304 [00:19<00:41, 60.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 759/3304 [00:19<00:41, 61.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 761/3304 [00:19<00:43, 59.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▍       | 791/3304 [00:19<00:41, 60.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 760/3304 [00:19<00:41, 61.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 746/3304 [00:19<00:44, 57.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 760/3304 [00:19<00:41, 61.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 764/3304 [00:19<00:42, 59.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▍       | 806/3304 [00:19<00:41, 60.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 766/3304 [00:19<00:41, 61.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 768/3304 [00:19<00:43, 58.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▍       | 799/3304 [00:19<00:41, 60.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 768/3304 [00:19<00:41, 60.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 752/3304 [00:19<00:44, 57.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 768/3304 [00:19<00:41, 61.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 770/3304 [00:19<00:42, 59.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▍       | 813/3304 [00:19<00:40, 61.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 773/3304 [00:19<00:41, 60.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 775/3304 [00:19<00:42, 59.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▍       | 806/3304 [00:19<00:41, 60.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 776/3304 [00:19<00:41, 61.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 760/3304 [00:19<00:43, 58.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 776/3304 [00:20<00:43, 58.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 776/3304 [00:19<00:41, 61.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▍       | 820/3304 [00:19<00:41, 60.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▎       | 781/3304 [00:19<00:41, 61.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▎       | 782/3304 [00:19<00:42, 59.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▍       | 813/3304 [00:19<00:41, 60.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▎       | 784/3304 [00:19<00:41, 60.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 768/3304 [00:19<00:43, 58.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▎       | 784/3304 [00:20<00:42, 58.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▎       | 784/3304 [00:19<00:40, 61.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▌       | 828/3304 [00:19<00:40, 61.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▍       | 789/3304 [00:19<00:40, 61.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▍       | 789/3304 [00:19<00:42, 59.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▍       | 820/3304 [00:19<00:41, 60.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▍       | 790/3304 [00:20<00:43, 57.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 775/3304 [00:19<00:42, 59.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▍       | 791/3304 [00:19<00:42, 58.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▌       | 835/3304 [00:19<00:40, 61.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▍       | 791/3304 [00:19<00:42, 59.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▌       | 828/3304 [00:20<00:40, 61.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▍       | 797/3304 [00:20<00:44, 55.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▍       | 796/3304 [00:20<00:44, 56.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▍       | 799/3304 [00:20<00:42, 59.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▎       | 782/3304 [00:20<00:42, 59.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▍       | 798/3304 [00:20<00:42, 58.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▌       | 843/3304 [00:20<00:39, 62.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▍       | 798/3304 [00:20<00:42, 59.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▌       | 835/3304 [00:20<00:40, 61.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▍       | 804/3304 [00:20<00:43, 57.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▍       | 803/3304 [00:20<00:43, 57.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▍       | 806/3304 [00:20<00:42, 59.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▍       | 789/3304 [00:20<00:42, 58.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▍       | 806/3304 [00:20<00:41, 60.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▍       | 805/3304 [00:20<00:41, 59.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▌       | 851/3304 [00:20<00:38, 63.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▌       | 842/3304 [00:20<00:40, 61.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▍       | 809/3304 [00:20<00:45, 55.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▍       | 813/3304 [00:20<00:42, 58.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▍       | 813/3304 [00:20<00:41, 59.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▍       | 813/3304 [00:20<00:44, 56.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▍       | 797/3304 [00:20<00:44, 55.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▌       | 859/3304 [00:20<00:39, 62.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▌       | 849/3304 [00:20<00:39, 62.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▍       | 815/3304 [00:20<00:42, 59.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▍       | 816/3304 [00:20<00:44, 56.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▍       | 820/3304 [00:20<00:42, 58.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▍       | 820/3304 [00:20<00:41, 59.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▍       | 819/3304 [00:20<00:44, 56.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▍       | 805/3304 [00:20<00:43, 56.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▌       | 867/3304 [00:20<00:39, 61.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▌       | 857/3304 [00:20<00:39, 62.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▍       | 822/3304 [00:20<00:42, 58.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▍       | 822/3304 [00:20<00:44, 55.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▌       | 827/3304 [00:20<00:41, 60.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▌       | 828/3304 [00:20<00:41, 59.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▌       | 826/3304 [00:20<00:43, 56.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▋       | 875/3304 [00:20<00:38, 62.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▌       | 865/3304 [00:20<00:39, 62.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▌       | 829/3304 [00:20<00:41, 59.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▍       | 813/3304 [00:20<00:44, 56.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▌       | 829/3304 [00:20<00:43, 56.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▌       | 834/3304 [00:20<00:41, 59.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▌       | 832/3304 [00:20<00:43, 56.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▌       | 834/3304 [00:20<00:41, 59.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 883/3304 [00:20<00:37, 64.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▋       | 872/3304 [00:20<00:39, 62.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▍       | 820/3304 [00:20<00:44, 56.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▌       | 837/3304 [00:20<00:41, 59.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▌       | 836/3304 [00:21<00:43, 57.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▌       | 842/3304 [00:20<00:40, 61.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▌       | 841/3304 [00:20<00:40, 60.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▌       | 840/3304 [00:20<00:42, 58.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 890/3304 [00:20<00:37, 63.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 879/3304 [00:20<00:39, 62.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▌       | 827/3304 [00:20<00:43, 57.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▌       | 843/3304 [00:21<00:41, 58.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▌       | 845/3304 [00:20<00:40, 61.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▌       | 849/3304 [00:20<00:40, 61.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▌       | 848/3304 [00:20<00:40, 60.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▌       | 847/3304 [00:20<00:42, 58.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 898/3304 [00:20<00:37, 64.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 887/3304 [00:20<00:38, 63.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▌       | 833/3304 [00:20<00:43, 56.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▌       | 850/3304 [00:21<00:41, 58.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▌       | 852/3304 [00:20<00:40, 60.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▌       | 856/3304 [00:20<00:40, 60.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▌       | 856/3304 [00:20<00:40, 60.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▌       | 854/3304 [00:20<00:41, 59.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 894/3304 [00:21<00:38, 62.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 906/3304 [00:21<00:37, 63.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▌       | 856/3304 [00:21<00:42, 58.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▌       | 841/3304 [00:21<00:42, 57.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▌       | 860/3304 [00:21<00:40, 60.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▌       | 860/3304 [00:21<00:41, 58.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▌       | 863/3304 [00:21<00:40, 60.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▌       | 864/3304 [00:21<00:40, 60.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 914/3304 [00:21<00:36, 66.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 902/3304 [00:21<00:37, 63.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▌       | 848/3304 [00:21<00:41, 58.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▌       | 864/3304 [00:21<00:41, 58.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▌       | 867/3304 [00:21<00:40, 60.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▋       | 871/3304 [00:21<00:40, 60.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▌       | 867/3304 [00:21<00:41, 58.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▋       | 871/3304 [00:21<00:40, 60.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 921/3304 [00:21<00:36, 65.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▌       | 854/3304 [00:21<00:41, 58.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 910/3304 [00:21<00:37, 63.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▋       | 870/3304 [00:21<00:42, 57.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▋       | 874/3304 [00:21<00:39, 60.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▋       | 874/3304 [00:21<00:41, 58.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 881/3304 [00:21<00:39, 60.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 881/3304 [00:21<00:39, 61.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 876/3304 [00:21<00:41, 57.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 918/3304 [00:21<00:36, 64.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▌       | 861/3304 [00:21<00:42, 57.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 931/3304 [00:21<00:36, 64.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 881/3304 [00:21<00:39, 61.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 881/3304 [00:21<00:40, 59.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 888/3304 [00:21<00:39, 61.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 888/3304 [00:21<00:39, 61.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 925/3304 [00:21<00:37, 63.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▋       | 868/3304 [00:21<00:42, 57.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 884/3304 [00:21<00:40, 59.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 938/3304 [00:21<00:37, 63.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 889/3304 [00:21<00:39, 61.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 888/3304 [00:21<00:40, 59.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 895/3304 [00:21<00:39, 60.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 895/3304 [00:21<00:39, 61.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▋       | 874/3304 [00:21<00:41, 58.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 932/3304 [00:21<00:37, 63.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 890/3304 [00:22<00:41, 58.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▊       | 946/3304 [00:21<00:36, 63.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 896/3304 [00:21<00:39, 61.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 895/3304 [00:21<00:40, 59.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 903/3304 [00:21<00:38, 62.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 903/3304 [00:21<00:38, 62.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 881/3304 [00:21<00:41, 59.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 897/3304 [00:22<00:40, 59.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 940/3304 [00:21<00:37, 63.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▉       | 953/3304 [00:21<00:37, 62.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 904/3304 [00:21<00:38, 61.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 903/3304 [00:21<00:39, 60.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 910/3304 [00:21<00:38, 62.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 911/3304 [00:21<00:38, 62.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 888/3304 [00:21<00:40, 58.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 905/3304 [00:22<00:39, 60.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▊       | 948/3304 [00:21<00:36, 63.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▉       | 960/3304 [00:21<00:37, 62.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 911/3304 [00:21<00:38, 62.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 910/3304 [00:21<00:39, 60.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 919/3304 [00:21<00:37, 63.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 918/3304 [00:21<00:37, 63.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 895/3304 [00:21<00:41, 58.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 912/3304 [00:22<00:39, 60.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▉       | 967/3304 [00:22<00:37, 62.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 918/3304 [00:22<00:37, 63.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▉       | 956/3304 [00:22<00:37, 62.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 918/3304 [00:22<00:39, 61.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 925/3304 [00:22<00:38, 61.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▉       | 974/3304 [00:22<00:36, 63.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 927/3304 [00:22<00:38, 62.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 903/3304 [00:22<00:39, 60.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 920/3304 [00:22<00:38, 61.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 925/3304 [00:22<00:38, 61.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▉       | 964/3304 [00:22<00:37, 62.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 925/3304 [00:22<00:39, 60.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 933/3304 [00:22<00:38, 62.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 934/3304 [00:22<00:38, 61.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 910/3304 [00:22<00:39, 60.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|██▉       | 982/3304 [00:22<00:36, 63.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 932/3304 [00:22<00:38, 61.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▉       | 972/3304 [00:22<00:37, 62.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 930/3304 [00:22<00:39, 60.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 932/3304 [00:22<00:39, 59.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 941/3304 [00:22<00:38, 61.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 940/3304 [00:22<00:38, 61.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 917/3304 [00:22<00:39, 60.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|██▉       | 990/3304 [00:22<00:35, 64.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 940/3304 [00:22<00:38, 61.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|██▉       | 979/3304 [00:22<00:37, 62.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 939/3304 [00:22<00:40, 59.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 939/3304 [00:22<00:39, 59.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▊       | 948/3304 [00:22<00:37, 62.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 924/3304 [00:22<00:39, 59.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▊       | 948/3304 [00:22<00:37, 62.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|███       | 998/3304 [00:22<00:35, 65.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▊       | 948/3304 [00:22<00:37, 62.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|██▉       | 987/3304 [00:22<00:36, 63.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▊       | 947/3304 [00:22<00:39, 59.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 930/3304 [00:22<00:40, 59.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▊       | 947/3304 [00:22<00:39, 59.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▉       | 956/3304 [00:22<00:38, 60.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▉       | 957/3304 [00:22<00:38, 60.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|███       | 995/3304 [00:22<00:36, 64.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▉       | 953/3304 [00:22<00:40, 58.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▉       | 958/3304 [00:22<00:38, 61.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 937/3304 [00:22<00:39, 59.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▉       | 964/3304 [00:22<00:38, 61.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▉       | 965/3304 [00:22<00:38, 61.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▉       | 957/3304 [00:23<00:39, 58.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▉       | 965/3304 [00:22<00:38, 61.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▉       | 961/3304 [00:22<00:40, 58.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▊       | 944/3304 [00:22<00:39, 59.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▉       | 972/3304 [00:22<00:37, 62.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▉       | 964/3304 [00:23<00:39, 59.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▉       | 973/3304 [00:22<00:38, 60.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▉       | 968/3304 [00:22<00:39, 59.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▉       | 972/3304 [00:22<00:38, 60.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▉       | 951/3304 [00:22<00:39, 59.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|██▉       | 979/3304 [00:22<00:37, 61.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▉       | 971/3304 [00:23<00:38, 59.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|██▉       | 981/3304 [00:23<00:37, 61.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▉       | 974/3304 [00:23<00:39, 58.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▉       | 958/3304 [00:23<00:40, 58.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|██▉       | 982/3304 [00:23<00:38, 59.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|██▉       | 987/3304 [00:23<00:37, 61.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|██▉       | 981/3304 [00:23<00:39, 59.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|██▉       | 989/3304 [00:23<00:36, 62.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|██▉       | 981/3304 [00:23<00:38, 59.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▉       | 965/3304 [00:23<00:39, 59.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|██▉       | 989/3304 [00:23<00:38, 60.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|███       | 995/3304 [00:23<00:36, 62.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|██▉       | 988/3304 [00:23<00:38, 59.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▉       | 971/3304 [00:23<00:39, 59.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|██▉       | 988/3304 [00:23<00:38, 60.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|███       | 999/3304 [00:23<00:37, 61.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|███       | 996/3304 [00:23<00:38, 60.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|███       | 994/3304 [00:23<00:38, 59.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|██▉       | 977/3304 [00:23<00:39, 58.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|███       | 995/3304 [00:23<00:38, 60.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|██▉       | 984/3304 [00:23<00:38, 59.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|███       | 992/3304 [00:23<00:37, 61.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|███       | 999/3304 [00:23<00:37, 61.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|███       | 999/3304 [00:39<00:38, 60.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|███       | 998/3304 [00:39<00:38, 59.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|███       | 999/3304 [00:39<00:38, 60.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|███       | 999/3304 [00:39<00:37, 61.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|███       | 999/3304 [00:39<00:37, 61.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|███       | 999/3304 [00:39<00:36, 62.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|███       | 999/3304 [00:39<00:36, 64.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|███       | 998/3304 [00:39<00:35, 65.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|███       | 1000/3304 [01:09<1:17:34,  2.02s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 1008/3304 [01:09<51:59,  1.36s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 1016/3304 [01:09<35:24,  1.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 1025/3304 [01:09<23:27,  1.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███▏      | 1034/3304 [01:09<15:53,  2.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 1042/3304 [01:09<11:20,  3.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 1053/3304 [01:10<07:21,  5.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 1061/3304 [01:10<05:26,  6.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 1072/3304 [01:10<03:42, 10.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 1080/3304 [01:10<02:51, 12.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 1088/3304 [01:10<02:12, 16.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 1097/3304 [01:10<01:40, 22.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 1106/3304 [01:10<01:17, 28.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▎      | 1114/3304 [01:10<01:04, 34.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▍      | 1122/3304 [01:10<00:53, 40.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▍      | 1131/3304 [01:11<00:45, 47.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▍      | 1140/3304 [01:11<00:39, 54.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▍      | 1148/3304 [01:11<00:37, 57.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▍      | 1156/3304 [01:11<00:35, 60.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▌      | 1164/3304 [01:11<00:33, 63.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▌      | 1172/3304 [01:11<00:31, 67.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▌      | 1180/3304 [01:11<00:31, 68.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▌      | 1188/3304 [01:11<00:30, 70.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▌      | 1197/3304 [01:12<00:29, 71.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 1206/3304 [01:12<00:28, 72.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 1214/3304 [01:12<00:28, 72.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 1222/3304 [01:12<00:28, 74.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 1230/3304 [01:12<00:28, 73.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 1238/3304 [01:12<00:28, 72.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 1246/3304 [01:12<00:28, 72.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 1254/3304 [01:12<00:28, 71.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 1262/3304 [01:12<00:28, 71.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 1270/3304 [01:12<00:27, 72.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▊      | 1278/3304 [01:13<00:28, 72.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▉      | 1286/3304 [01:13<00:28, 70.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▉      | 1297/3304 [01:13<00:29, 68.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▉      | 1305/3304 [01:13<00:28, 69.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|███▉      | 1313/3304 [01:13<00:28, 70.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|███▉      | 1321/3304 [01:13<00:28, 69.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|████      | 1329/3304 [01:13<00:28, 69.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|████      | 1337/3304 [01:13<00:28, 69.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████      | 1345/3304 [01:14<00:28, 69.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████      | 1353/3304 [01:14<00:28, 68.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████      | 1361/3304 [01:14<00:28, 67.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|███       | 1000/3304 [01:14<1:31:31,  2.38s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  41%|████▏     | 1369/3304 [01:14<00:27, 69.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 1008/3304 [01:14<59:45,  1.56s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 1377/3304 [01:14<00:28, 68.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|███       | 1000/3304 [01:14<1:40:20,  2.61s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 1016/3304 [01:14<40:00,  1.05s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 1385/3304 [01:14<00:28, 67.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 1024/3304 [01:14<27:13,  1.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 1008/3304 [01:14<1:03:52,  1.67s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 1392/3304 [01:14<00:28, 66.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 1032/3304 [01:14<18:45,  2.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 1016/3304 [01:14<42:06,  1.10s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 1400/3304 [01:14<00:28, 66.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███▏      | 1040/3304 [01:14<13:03,  2.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 1024/3304 [01:14<28:22,  1.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|███       | 1000/3304 [01:15<1:31:15,  2.38s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 1408/3304 [01:15<00:28, 66.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 1032/3304 [01:15<19:25,  1.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 1048/3304 [01:15<09:11,  4.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 1008/3304 [01:15<59:55,  1.57s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  30%|███       | 1000/3304 [01:15<1:34:59,  2.47s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 1415/3304 [01:15<00:28, 66.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███▏      | 1040/3304 [01:15<13:27,  2.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 1055/3304 [01:15<06:47,  5.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 1008/3304 [01:15<1:01:34,  1.61s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 1016/3304 [01:15<40:16,  1.06s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 1423/3304 [01:15<00:29, 64.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 1063/3304 [01:15<04:49,  7.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 1048/3304 [01:15<09:26,  3.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 1016/3304 [01:15<41:02,  1.08s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 1024/3304 [01:15<27:28,  1.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 1430/3304 [01:15<00:28, 64.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 1055/3304 [01:15<06:57,  5.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 1071/3304 [01:15<03:30, 10.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 1024/3304 [01:15<27:51,  1.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 1032/3304 [01:15<18:58,  2.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▎     | 1438/3304 [01:15<00:28, 65.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|███       | 1000/3304 [01:15<1:27:13,  2.27s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 1063/3304 [01:15<04:55,  7.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 1078/3304 [01:15<02:41, 13.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 1032/3304 [01:15<19:09,  1.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▍     | 1446/3304 [01:15<00:27, 67.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███▏      | 1040/3304 [01:15<13:13,  2.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 1008/3304 [01:15<58:18,  1.52s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 1071/3304 [01:15<03:35, 10.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 1086/3304 [01:15<02:01, 18.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███▏      | 1040/3304 [01:15<13:19,  2.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▍     | 1454/3304 [01:15<00:27, 68.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 1048/3304 [01:15<09:19,  4.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 1015/3304 [01:16<41:18,  1.08s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 1078/3304 [01:15<02:44, 13.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 1094/3304 [01:15<01:33, 23.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▍     | 1461/3304 [01:15<00:27, 67.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 1048/3304 [01:15<09:22,  4.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 1055/3304 [01:15<06:52,  5.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 1023/3304 [01:16<28:01,  1.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 1086/3304 [01:15<02:03, 17.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 1102/3304 [01:15<01:14, 29.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▍     | 1468/3304 [01:15<00:27, 66.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 1055/3304 [01:15<06:54,  5.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 1063/3304 [01:15<04:53,  7.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 1031/3304 [01:16<19:17,  1.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 1094/3304 [01:15<01:34, 23.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▎      | 1110/3304 [01:15<01:00, 35.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▍     | 1475/3304 [01:16<00:27, 66.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 1063/3304 [01:16<04:54,  7.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███▏      | 1039/3304 [01:16<13:25,  2.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 1102/3304 [01:16<01:15, 29.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▍      | 1118/3304 [01:16<00:52, 41.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 1073/3304 [01:16<03:21, 11.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▍     | 1482/3304 [01:16<00:27, 65.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 1071/3304 [01:16<03:34, 10.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▎      | 1110/3304 [01:16<01:01, 35.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 1047/3304 [01:16<09:26,  3.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▍      | 1126/3304 [01:16<00:46, 46.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 1080/3304 [01:16<02:37, 14.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▌     | 1489/3304 [01:16<00:28, 64.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 1078/3304 [01:16<02:44, 13.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▍      | 1118/3304 [01:16<00:52, 41.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 1054/3304 [01:16<06:58,  5.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▍      | 1134/3304 [01:16<00:41, 52.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 1087/3304 [01:16<02:04, 17.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▌     | 1497/3304 [01:16<00:28, 64.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 1086/3304 [01:16<02:03, 17.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▍      | 1126/3304 [01:16<00:46, 46.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 1062/3304 [01:16<04:57,  7.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▍      | 1142/3304 [01:16<00:38, 56.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 1095/3304 [01:16<01:34, 23.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▌     | 1505/3304 [01:16<00:28, 63.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 1094/3304 [01:16<01:34, 23.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▍      | 1134/3304 [01:16<00:41, 52.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▍      | 1149/3304 [01:16<00:37, 57.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 1103/3304 [01:16<01:15, 29.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 1069/3304 [01:16<03:44,  9.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▌     | 1513/3304 [01:16<00:28, 63.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 1102/3304 [01:16<01:15, 29.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▍      | 1142/3304 [01:16<00:38, 56.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▍      | 1156/3304 [01:16<00:36, 58.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▎      | 1111/3304 [01:16<01:02, 35.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 1076/3304 [01:17<02:50, 13.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|███       | 1000/3304 [01:16<1:29:17,  2.33s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▌     | 1520/3304 [01:16<00:28, 62.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▎      | 1110/3304 [01:16<01:01, 35.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▍      | 1149/3304 [01:16<00:37, 57.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▌      | 1164/3304 [01:16<00:35, 60.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▍      | 1119/3304 [01:16<00:53, 40.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 1084/3304 [01:17<02:07, 17.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 1008/3304 [01:16<59:44,  1.56s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▌     | 1528/3304 [01:16<00:28, 62.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▍      | 1118/3304 [01:16<00:53, 41.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▍      | 1156/3304 [01:16<00:36, 58.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▌      | 1172/3304 [01:16<00:33, 62.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▍      | 1126/3304 [01:16<00:48, 44.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 1091/3304 [01:17<01:40, 22.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 1015/3304 [01:16<42:19,  1.11s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▋     | 1535/3304 [01:16<00:28, 62.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▍      | 1126/3304 [01:17<00:46, 46.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▌      | 1164/3304 [01:17<00:35, 61.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▌      | 1179/3304 [01:17<00:33, 62.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▍      | 1134/3304 [01:17<00:43, 50.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 1099/3304 [01:17<01:19, 27.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 1023/3304 [01:17<28:43,  1.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 1543/3304 [01:17<00:28, 62.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▍      | 1134/3304 [01:17<00:41, 52.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▌      | 1172/3304 [01:17<00:33, 63.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▌      | 1187/3304 [01:17<00:32, 64.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▎      | 1107/3304 [01:17<01:04, 34.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▍      | 1142/3304 [01:17<00:40, 53.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 1031/3304 [01:17<19:45,  1.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 1550/3304 [01:17<00:27, 62.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▍      | 1142/3304 [01:17<00:38, 55.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▌      | 1179/3304 [01:17<00:33, 63.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▌      | 1195/3304 [01:17<00:31, 66.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▍      | 1149/3304 [01:17<00:39, 54.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▎      | 1115/3304 [01:17<00:55, 39.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███▏      | 1039/3304 [01:17<13:44,  2.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|███       | 1000/3304 [01:17<1:58:55,  3.10s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 1557/3304 [01:17<00:28, 62.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▍      | 1149/3304 [01:17<00:37, 57.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▌      | 1187/3304 [01:17<00:32, 64.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▋      | 1203/3304 [01:17<00:31, 66.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▍      | 1156/3304 [01:17<00:38, 56.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▍      | 1123/3304 [01:17<00:48, 45.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 1047/3304 [01:17<09:39,  3.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 1008/3304 [01:17<1:11:45,  1.88s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 1565/3304 [01:17<00:27, 62.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▍      | 1156/3304 [01:17<00:36, 58.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▌      | 1195/3304 [01:17<00:31, 66.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 1211/3304 [01:17<00:32, 65.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▍      | 1130/3304 [01:17<00:43, 49.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▌      | 1164/3304 [01:17<00:36, 58.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 1054/3304 [01:17<07:07,  5.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 1015/3304 [01:17<48:03,  1.26s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 1573/3304 [01:17<00:27, 64.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▌      | 1164/3304 [01:17<00:35, 60.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▋      | 1203/3304 [01:17<00:31, 66.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 1219/3304 [01:17<00:31, 66.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▍      | 1138/3304 [01:18<00:40, 53.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▌      | 1172/3304 [01:17<00:35, 60.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 1062/3304 [01:17<05:03,  7.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 1023/3304 [01:17<31:16,  1.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 1581/3304 [01:17<00:26, 65.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▌      | 1172/3304 [01:17<00:33, 62.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 1211/3304 [01:17<00:31, 65.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 1227/3304 [01:17<00:31, 66.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▍      | 1145/3304 [01:18<00:39, 54.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▌      | 1179/3304 [01:17<00:34, 61.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 1069/3304 [01:17<03:48,  9.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 1589/3304 [01:17<00:25, 66.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▌      | 1179/3304 [01:17<00:33, 62.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 1031/3304 [01:17<20:57,  1.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 1219/3304 [01:17<00:31, 66.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 1235/3304 [01:17<00:31, 65.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▌      | 1187/3304 [01:17<00:33, 62.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▍      | 1153/3304 [01:18<00:37, 57.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 1076/3304 [01:17<02:53, 12.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 1597/3304 [01:17<00:25, 67.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▌      | 1187/3304 [01:17<00:32, 64.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███▏      | 1039/3304 [01:17<14:19,  2.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 1227/3304 [01:17<00:30, 67.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 1243/3304 [01:17<00:31, 65.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▌      | 1195/3304 [01:18<00:32, 64.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▌      | 1160/3304 [01:18<00:37, 57.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 1084/3304 [01:18<02:08, 17.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▊     | 1604/3304 [01:18<00:26, 64.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▌      | 1195/3304 [01:18<00:31, 66.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 1046/3304 [01:18<10:20,  3.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 1235/3304 [01:18<00:31, 66.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 1250/3304 [01:18<00:31, 64.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▋      | 1202/3304 [01:18<00:32, 65.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 1091/3304 [01:18<01:41, 21.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▌      | 1168/3304 [01:18<00:35, 60.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▉     | 1612/3304 [01:18<00:25, 65.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▋      | 1203/3304 [01:18<00:32, 65.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 1053/3304 [01:18<07:29,  5.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 1243/3304 [01:18<00:30, 66.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 1209/3304 [01:18<00:32, 63.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 1258/3304 [01:18<00:31, 64.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 1099/3304 [01:18<01:19, 27.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▌      | 1175/3304 [01:18<00:35, 59.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▉     | 1620/3304 [01:18<00:25, 65.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 1061/3304 [01:18<05:14,  7.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 1211/3304 [01:18<00:32, 65.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 1251/3304 [01:18<00:30, 66.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 1217/3304 [01:18<00:32, 64.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 1266/3304 [01:18<00:31, 65.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▎      | 1107/3304 [01:18<01:03, 34.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▌      | 1183/3304 [01:18<00:34, 62.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▉     | 1627/3304 [01:18<00:26, 64.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 1219/3304 [01:18<00:31, 66.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 1259/3304 [01:18<00:30, 66.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 1225/3304 [01:18<00:31, 65.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 1071/3304 [01:18<03:33, 10.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▊      | 1274/3304 [01:18<00:31, 65.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▎      | 1115/3304 [01:18<00:54, 40.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▌      | 1191/3304 [01:18<00:33, 62.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▉     | 1634/3304 [01:18<00:26, 62.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 1227/3304 [01:18<00:31, 66.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 1267/3304 [01:18<00:29, 68.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 1233/3304 [01:18<00:31, 65.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▉      | 1281/3304 [01:18<00:31, 63.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▍      | 1123/3304 [01:18<00:47, 46.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▋      | 1198/3304 [01:18<00:33, 63.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|████▉     | 1642/3304 [01:18<00:25, 65.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 1081/3304 [01:18<02:32, 14.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▊      | 1275/3304 [01:18<00:29, 69.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 1235/3304 [01:18<00:31, 65.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 1240/3304 [01:18<00:32, 64.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▉      | 1288/3304 [01:18<00:32, 62.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▍      | 1131/3304 [01:18<00:42, 50.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 1206/3304 [01:19<00:33, 63.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|████▉     | 1650/3304 [01:18<00:25, 64.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 1088/3304 [01:18<02:02, 18.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▉      | 1283/3304 [01:18<00:29, 68.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 1243/3304 [01:18<00:31, 65.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▉      | 1295/3304 [01:18<00:32, 61.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 1248/3304 [01:18<00:32, 64.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▍      | 1139/3304 [01:18<00:39, 55.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 1213/3304 [01:19<00:33, 63.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|█████     | 1658/3304 [01:18<00:24, 66.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 1096/3304 [01:18<01:35, 23.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 1251/3304 [01:18<00:31, 64.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 1255/3304 [01:18<00:32, 63.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▉      | 1293/3304 [01:18<00:30, 65.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▉      | 1303/3304 [01:18<00:31, 62.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▍      | 1146/3304 [01:18<00:38, 55.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 1221/3304 [01:19<00:32, 63.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 1103/3304 [01:18<01:19, 27.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|█████     | 1666/3304 [01:19<00:24, 67.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 1259/3304 [01:19<00:31, 64.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 1263/3304 [01:19<00:31, 64.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▉      | 1301/3304 [01:19<00:30, 66.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|███▉      | 1311/3304 [01:19<00:30, 64.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▍      | 1154/3304 [01:19<00:36, 59.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 1229/3304 [01:19<00:32, 63.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████     | 1674/3304 [01:19<00:23, 68.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▎      | 1111/3304 [01:19<01:04, 33.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 1267/3304 [01:19<00:30, 65.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|███▉      | 1309/3304 [01:19<00:28, 68.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 1271/3304 [01:19<00:31, 64.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▌      | 1161/3304 [01:19<00:35, 60.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|███▉      | 1318/3304 [01:19<00:31, 62.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 1236/3304 [01:19<00:33, 62.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████     | 1682/3304 [01:19<00:23, 68.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▍      | 1119/3304 [01:19<00:55, 39.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▊      | 1275/3304 [01:19<00:30, 65.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|███▉      | 1317/3304 [01:19<00:29, 67.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▊      | 1278/3304 [01:19<00:32, 63.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|████      | 1326/3304 [01:19<00:30, 63.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▌      | 1169/3304 [01:19<00:34, 61.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 1244/3304 [01:19<00:32, 62.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████     | 1690/3304 [01:19<00:23, 67.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▍      | 1126/3304 [01:19<00:49, 43.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▉      | 1282/3304 [01:19<00:31, 64.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|████      | 1325/3304 [01:19<00:28, 68.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▌      | 1177/3304 [01:19<00:33, 62.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|████      | 1334/3304 [01:19<00:31, 63.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████▏    | 1698/3304 [01:19<00:23, 68.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▍      | 1134/3304 [01:19<00:43, 49.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▉      | 1288/3304 [01:19<00:32, 61.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 1254/3304 [01:19<00:32, 62.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|████      | 1333/3304 [01:19<00:29, 67.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▌      | 1185/3304 [01:19<00:32, 64.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▉      | 1291/3304 [01:19<00:32, 61.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████      | 1342/3304 [01:19<00:30, 63.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 1706/3304 [01:19<00:23, 67.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▍      | 1142/3304 [01:19<00:40, 53.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▉      | 1295/3304 [01:19<00:33, 60.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 1262/3304 [01:20<00:32, 62.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████      | 1341/3304 [01:19<00:28, 68.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▌      | 1193/3304 [01:19<00:32, 65.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▉      | 1299/3304 [01:19<00:32, 62.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▉      | 1302/3304 [01:19<00:33, 60.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▍      | 1149/3304 [01:19<00:39, 54.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████      | 1352/3304 [01:19<00:31, 62.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 1716/3304 [01:19<00:24, 65.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 1270/3304 [01:20<00:32, 62.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████      | 1349/3304 [01:19<00:28, 67.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▋      | 1201/3304 [01:19<00:31, 66.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|███▉      | 1307/3304 [01:19<00:31, 64.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|███▉      | 1310/3304 [01:19<00:31, 62.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▍      | 1156/3304 [01:19<00:38, 55.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████      | 1359/3304 [01:19<00:31, 61.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 1723/3304 [01:19<00:24, 65.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▊      | 1277/3304 [01:20<00:32, 61.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████      | 1357/3304 [01:19<00:29, 66.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 1208/3304 [01:19<00:32, 65.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|███▉      | 1314/3304 [01:19<00:31, 63.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████▏     | 1367/3304 [01:19<00:30, 63.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▌      | 1164/3304 [01:19<00:37, 57.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 1730/3304 [01:19<00:24, 63.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|███▉      | 1319/3304 [01:19<00:32, 60.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▉      | 1284/3304 [01:20<00:33, 61.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████▏     | 1365/3304 [01:20<00:28, 67.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 1216/3304 [01:20<00:31, 66.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|████      | 1322/3304 [01:20<00:30, 64.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 1375/3304 [01:20<00:30, 64.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▌      | 1172/3304 [01:20<00:35, 59.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 1738/3304 [01:20<00:24, 63.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|████      | 1327/3304 [01:20<00:32, 61.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▉      | 1291/3304 [01:20<00:33, 59.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 1373/3304 [01:20<00:28, 68.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 1224/3304 [01:20<00:30, 67.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|████      | 1330/3304 [01:20<00:30, 64.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▌      | 1179/3304 [01:20<00:35, 59.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 1382/3304 [01:20<00:30, 62.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 1746/3304 [01:20<00:24, 64.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▉      | 1298/3304 [01:20<00:33, 59.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 1380/3304 [01:20<00:29, 66.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 1232/3304 [01:20<00:30, 67.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|████      | 1336/3304 [01:20<00:32, 60.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|████      | 1338/3304 [01:20<00:30, 63.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 1389/3304 [01:20<00:30, 62.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 1754/3304 [01:20<00:23, 66.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▌      | 1187/3304 [01:20<00:34, 61.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 1388/3304 [01:20<00:28, 66.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|███▉      | 1306/3304 [01:20<00:32, 61.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 1239/3304 [01:20<00:31, 66.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████      | 1344/3304 [01:20<00:31, 62.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████      | 1345/3304 [01:20<00:30, 63.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 1396/3304 [01:20<00:30, 62.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 1762/3304 [01:20<00:22, 67.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▌      | 1195/3304 [01:20<00:33, 62.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|███▉      | 1313/3304 [01:20<00:32, 62.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 1396/3304 [01:20<00:28, 67.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 1247/3304 [01:20<00:31, 65.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████      | 1352/3304 [01:20<00:31, 62.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████      | 1351/3304 [01:20<00:32, 59.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▎    | 1770/3304 [01:20<00:22, 68.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▋      | 1202/3304 [01:20<00:33, 63.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 1404/3304 [01:20<00:30, 61.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 1254/3304 [01:20<00:31, 65.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 1404/3304 [01:20<00:28, 66.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████      | 1359/3304 [01:20<00:31, 61.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|████      | 1323/3304 [01:21<00:32, 61.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████      | 1360/3304 [01:20<00:32, 59.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 1412/3304 [01:20<00:29, 64.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 1209/3304 [01:20<00:34, 61.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▍    | 1778/3304 [01:20<00:22, 66.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 1412/3304 [01:20<00:27, 69.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 1262/3304 [01:20<00:31, 64.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|████      | 1330/3304 [01:21<00:31, 61.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████▏     | 1367/3304 [01:20<00:30, 63.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▍    | 1786/3304 [01:20<00:22, 68.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████▏     | 1368/3304 [01:20<00:31, 61.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 1419/3304 [01:20<00:30, 62.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 1217/3304 [01:20<00:33, 62.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 1420/3304 [01:20<00:28, 66.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 1270/3304 [01:20<00:31, 65.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 1375/3304 [01:20<00:30, 64.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▍    | 1793/3304 [01:20<00:22, 66.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████      | 1340/3304 [01:21<00:32, 61.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 1426/3304 [01:20<00:30, 61.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 1376/3304 [01:20<00:31, 61.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 1225/3304 [01:20<00:32, 63.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 1427/3304 [01:20<00:28, 65.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▊      | 1277/3304 [01:20<00:31, 64.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 1382/3304 [01:20<00:30, 62.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▍    | 1801/3304 [01:21<00:22, 66.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████      | 1347/3304 [01:21<00:32, 60.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 1434/3304 [01:21<00:29, 63.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 1383/3304 [01:21<00:31, 60.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 1435/3304 [01:21<00:27, 68.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 1233/3304 [01:21<00:32, 63.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▉      | 1284/3304 [01:21<00:32, 63.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 1389/3304 [01:21<00:30, 62.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▍    | 1809/3304 [01:21<00:22, 67.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████      | 1354/3304 [01:21<00:32, 60.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▎     | 1443/3304 [01:21<00:26, 69.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▎     | 1442/3304 [01:21<00:29, 64.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 1390/3304 [01:21<00:31, 60.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 1240/3304 [01:21<00:33, 62.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▉      | 1291/3304 [01:21<00:32, 61.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 1396/3304 [01:21<00:30, 62.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▍    | 1817/3304 [01:21<00:21, 69.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▍     | 1451/3304 [01:21<00:25, 71.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▍     | 1450/3304 [01:21<00:28, 65.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 1247/3304 [01:21<00:33, 61.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 1398/3304 [01:21<00:31, 60.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████▏     | 1364/3304 [01:21<00:31, 60.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▉      | 1299/3304 [01:21<00:32, 62.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 1404/3304 [01:21<00:30, 62.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▌    | 1825/3304 [01:21<00:21, 68.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▍     | 1459/3304 [01:21<00:26, 70.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▍     | 1457/3304 [01:21<00:28, 64.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 1254/3304 [01:21<00:33, 61.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 1405/3304 [01:21<00:31, 60.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|███▉      | 1307/3304 [01:21<00:31, 64.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 1372/3304 [01:21<00:31, 61.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 1412/3304 [01:21<00:29, 64.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▍     | 1467/3304 [01:21<00:25, 71.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▍     | 1465/3304 [01:21<00:27, 66.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▌    | 1833/3304 [01:21<00:22, 66.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 1262/3304 [01:21<00:33, 61.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 1413/3304 [01:21<00:30, 61.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|███▉      | 1314/3304 [01:21<00:31, 63.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 1379/3304 [01:21<00:32, 60.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 1419/3304 [01:21<00:29, 63.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▍     | 1472/3304 [01:21<00:28, 65.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▌    | 1841/3304 [01:21<00:21, 67.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▍     | 1475/3304 [01:21<00:26, 69.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 1270/3304 [01:21<00:32, 62.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 1420/3304 [01:21<00:31, 60.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|████      | 1322/3304 [01:21<00:30, 64.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 1387/3304 [01:22<00:31, 61.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 1426/3304 [01:21<00:30, 62.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▍     | 1482/3304 [01:21<00:26, 67.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▍     | 1479/3304 [01:21<00:28, 64.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▌    | 1849/3304 [01:21<00:21, 66.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▊      | 1277/3304 [01:21<00:32, 61.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 1427/3304 [01:21<00:31, 59.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|████      | 1330/3304 [01:21<00:30, 64.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 1394/3304 [01:22<00:31, 60.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 1434/3304 [01:21<00:29, 63.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▌     | 1489/3304 [01:21<00:27, 67.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▍     | 1486/3304 [01:21<00:28, 63.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▌    | 1857/3304 [01:21<00:22, 64.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▉      | 1284/3304 [01:21<00:33, 60.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 1435/3304 [01:21<00:30, 61.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|████      | 1338/3304 [01:21<00:30, 63.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 1401/3304 [01:22<00:31, 60.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▎     | 1442/3304 [01:21<00:28, 64.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▌     | 1497/3304 [01:21<00:27, 66.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▌     | 1493/3304 [01:21<00:28, 62.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▋    | 1864/3304 [01:21<00:22, 64.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▎     | 1442/3304 [01:22<00:30, 61.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▉      | 1291/3304 [01:22<00:34, 59.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████      | 1345/3304 [01:22<00:30, 63.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▍     | 1450/3304 [01:22<00:27, 66.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 1409/3304 [01:22<00:30, 61.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▌     | 1505/3304 [01:22<00:26, 66.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▌     | 1501/3304 [01:22<00:28, 62.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 1871/3304 [01:22<00:22, 64.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▍     | 1450/3304 [01:22<00:29, 63.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▉      | 1298/3304 [01:22<00:33, 59.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████      | 1352/3304 [01:22<00:31, 62.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▍     | 1457/3304 [01:22<00:28, 64.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 1417/3304 [01:22<00:30, 61.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▌     | 1513/3304 [01:22<00:26, 66.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 1878/3304 [01:22<00:21, 64.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▌     | 1509/3304 [01:22<00:29, 61.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▍     | 1457/3304 [01:22<00:29, 62.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|███▉      | 1306/3304 [01:22<00:32, 61.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████      | 1359/3304 [01:22<00:31, 61.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▍     | 1465/3304 [01:22<00:27, 66.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 1424/3304 [01:22<00:30, 61.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▌     | 1520/3304 [01:22<00:27, 65.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 1886/3304 [01:22<00:20, 67.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▌     | 1516/3304 [01:22<00:29, 60.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▍     | 1465/3304 [01:22<00:28, 64.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|███▉      | 1313/3304 [01:22<00:32, 61.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████▏     | 1367/3304 [01:22<00:30, 64.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▍     | 1472/3304 [01:22<00:28, 65.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 1893/3304 [01:22<00:20, 67.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 1431/3304 [01:22<00:30, 60.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▌     | 1528/3304 [01:22<00:26, 65.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▌     | 1524/3304 [01:22<00:29, 61.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▍     | 1472/3304 [01:22<00:29, 62.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▍     | 1479/3304 [01:22<00:28, 65.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 1375/3304 [01:22<00:29, 64.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▎     | 1438/3304 [01:22<00:30, 61.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 1901/3304 [01:22<00:20, 66.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|████      | 1323/3304 [01:22<00:32, 61.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▋     | 1536/3304 [01:22<00:26, 66.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▋     | 1531/3304 [01:22<00:29, 61.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▍     | 1479/3304 [01:22<00:29, 62.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▍     | 1486/3304 [01:22<00:28, 63.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 1382/3304 [01:22<00:30, 62.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▍     | 1446/3304 [01:23<00:29, 63.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 1909/3304 [01:22<00:20, 67.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|████      | 1330/3304 [01:22<00:32, 61.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 1543/3304 [01:22<00:26, 66.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 1539/3304 [01:22<00:27, 63.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▍     | 1486/3304 [01:22<00:29, 60.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▌     | 1493/3304 [01:22<00:28, 62.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 1389/3304 [01:22<00:30, 62.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▍     | 1454/3304 [01:23<00:28, 63.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 1917/3304 [01:22<00:20, 66.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 1551/3304 [01:22<00:26, 65.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████      | 1340/3304 [01:22<00:32, 60.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 1546/3304 [01:22<00:28, 61.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▌     | 1493/3304 [01:22<00:30, 60.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▌     | 1501/3304 [01:22<00:28, 63.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 1397/3304 [01:22<00:30, 62.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▍     | 1461/3304 [01:23<00:29, 63.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 1925/3304 [01:22<00:20, 66.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 1559/3304 [01:22<00:26, 66.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████      | 1347/3304 [01:22<00:32, 60.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 1553/3304 [01:22<00:28, 60.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▌     | 1500/3304 [01:22<00:29, 60.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▌     | 1509/3304 [01:22<00:29, 61.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▍     | 1468/3304 [01:23<00:29, 62.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 1405/3304 [01:22<00:30, 62.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▊    | 1933/3304 [01:23<00:20, 68.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 1567/3304 [01:23<00:26, 66.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████      | 1354/3304 [01:23<00:32, 60.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 1561/3304 [01:23<00:28, 61.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▍     | 1475/3304 [01:23<00:29, 62.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▌     | 1516/3304 [01:23<00:29, 60.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 1413/3304 [01:23<00:29, 64.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▌     | 1509/3304 [01:23<00:30, 59.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▊    | 1941/3304 [01:23<00:19, 68.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 1575/3304 [01:23<00:25, 68.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 1569/3304 [01:23<00:27, 62.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████▏     | 1364/3304 [01:23<00:32, 60.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▍     | 1482/3304 [01:23<00:29, 61.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 1420/3304 [01:23<00:30, 62.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▉    | 1949/3304 [01:23<00:19, 68.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▌     | 1524/3304 [01:23<00:29, 61.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▌     | 1516/3304 [01:23<00:30, 58.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 1583/3304 [01:23<00:24, 68.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 1577/3304 [01:23<00:26, 64.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▌     | 1489/3304 [01:23<00:29, 60.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 1591/3304 [01:23<00:24, 70.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 1372/3304 [01:23<00:31, 61.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 1427/3304 [01:23<00:30, 61.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▋     | 1531/3304 [01:23<00:28, 61.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▉    | 1957/3304 [01:23<00:19, 68.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▌     | 1524/3304 [01:23<00:30, 58.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 1585/3304 [01:23<00:26, 64.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▌     | 1496/3304 [01:23<00:29, 60.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 1599/3304 [01:23<00:24, 70.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 1435/3304 [01:23<00:29, 64.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 1539/3304 [01:23<00:27, 63.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▉    | 1965/3304 [01:23<00:19, 68.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 1379/3304 [01:23<00:32, 59.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▋     | 1531/3304 [01:23<00:30, 58.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 1593/3304 [01:23<00:25, 66.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▌     | 1503/3304 [01:23<00:29, 60.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▊     | 1607/3304 [01:23<00:24, 68.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▎     | 1443/3304 [01:23<00:28, 64.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|█████▉    | 1973/3304 [01:23<00:19, 68.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 1546/3304 [01:23<00:28, 62.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 1387/3304 [01:23<00:31, 61.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 1539/3304 [01:23<00:29, 60.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 1601/3304 [01:23<00:26, 65.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▉     | 1615/3304 [01:23<00:24, 69.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|█████▉    | 1980/3304 [01:23<00:19, 66.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▍     | 1451/3304 [01:23<00:27, 66.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 1553/3304 [01:23<00:28, 61.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 1394/3304 [01:23<00:31, 59.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▌     | 1513/3304 [01:24<00:29, 59.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 1549/3304 [01:23<00:29, 59.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▊     | 1608/3304 [01:23<00:26, 63.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▉     | 1623/3304 [01:23<00:24, 69.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|██████    | 1988/3304 [01:23<00:19, 67.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▍     | 1459/3304 [01:23<00:28, 65.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 1561/3304 [01:23<00:27, 62.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 1401/3304 [01:23<00:32, 59.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▌     | 1520/3304 [01:24<00:30, 59.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 1555/3304 [01:23<00:30, 58.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▉     | 1616/3304 [01:23<00:26, 64.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|██████    | 1996/3304 [01:23<00:18, 68.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▉     | 1630/3304 [01:23<00:25, 66.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▍     | 1467/3304 [01:23<00:27, 66.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 1569/3304 [01:23<00:27, 62.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 1409/3304 [01:23<00:31, 61.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▌     | 1528/3304 [01:24<00:29, 59.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 1563/3304 [01:24<00:29, 59.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▉     | 1624/3304 [01:24<00:25, 64.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|████▉     | 1638/3304 [01:24<00:24, 68.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 1577/3304 [01:24<00:26, 64.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▍     | 1475/3304 [01:24<00:28, 64.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 1417/3304 [01:24<00:30, 61.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▋     | 1535/3304 [01:24<00:29, 59.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 1570/3304 [01:24<00:28, 60.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|████▉     | 1647/3304 [01:24<00:23, 70.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▍     | 1482/3304 [01:24<00:28, 63.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 1585/3304 [01:24<00:26, 64.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▉     | 1634/3304 [01:24<00:26, 62.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 1424/3304 [01:24<00:30, 60.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 1542/3304 [01:24<00:28, 60.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 1578/3304 [01:24<00:27, 61.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|█████     | 1656/3304 [01:24<00:22, 72.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▌     | 1489/3304 [01:24<00:28, 62.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 1593/3304 [01:24<00:25, 66.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|████▉     | 1642/3304 [01:24<00:25, 64.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 1431/3304 [01:24<00:30, 60.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 1549/3304 [01:24<00:29, 60.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|█████     | 1664/3304 [01:24<00:22, 74.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 1586/3304 [01:24<00:27, 62.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▌     | 1497/3304 [01:24<00:28, 62.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 1601/3304 [01:24<00:25, 65.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▎     | 1438/3304 [01:24<00:30, 60.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|████▉     | 1650/3304 [01:24<00:26, 63.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████     | 1672/3304 [01:24<00:21, 75.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 1594/3304 [01:24<00:26, 63.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 1559/3304 [01:24<00:29, 59.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▊     | 1608/3304 [01:24<00:26, 63.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▍     | 1446/3304 [01:24<00:29, 62.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▌     | 1505/3304 [01:24<00:28, 62.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|█████     | 1658/3304 [01:24<00:25, 65.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████     | 1680/3304 [01:24<00:21, 76.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 1601/3304 [01:24<00:27, 62.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 1566/3304 [01:25<00:29, 59.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▉     | 1616/3304 [01:24<00:26, 64.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▍     | 1454/3304 [01:24<00:29, 63.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|█████     | 1666/3304 [01:24<00:25, 65.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▌     | 1513/3304 [01:24<00:28, 62.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████     | 1689/3304 [01:24<00:20, 77.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 1574/3304 [01:25<00:28, 61.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▉     | 1623/3304 [01:24<00:26, 64.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▉     | 1611/3304 [01:24<00:27, 61.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▍     | 1461/3304 [01:24<00:29, 62.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████     | 1674/3304 [01:24<00:24, 66.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▌     | 1520/3304 [01:24<00:28, 61.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████▏    | 1698/3304 [01:24<00:20, 76.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 1582/3304 [01:25<00:27, 61.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▍     | 1468/3304 [01:24<00:29, 62.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▉     | 1619/3304 [01:24<00:26, 62.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████     | 1682/3304 [01:24<00:24, 66.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 1707/3304 [01:24<00:20, 77.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▌     | 1528/3304 [01:24<00:28, 61.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▉     | 1633/3304 [01:24<00:26, 62.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 1590/3304 [01:25<00:27, 63.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▍     | 1475/3304 [01:25<00:29, 61.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▉     | 1626/3304 [01:25<00:27, 61.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████     | 1690/3304 [01:25<00:24, 66.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▋     | 1535/3304 [01:25<00:28, 61.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|████▉     | 1641/3304 [01:25<00:25, 64.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 1718/3304 [01:25<00:21, 72.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 1598/3304 [01:25<00:26, 63.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▍     | 1482/3304 [01:25<00:29, 60.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▉     | 1633/3304 [01:25<00:27, 60.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████▏    | 1698/3304 [01:25<00:24, 66.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 1543/3304 [01:25<00:28, 62.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|████▉     | 1649/3304 [01:25<00:26, 63.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 1727/3304 [01:25<00:21, 73.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▌     | 1489/3304 [01:25<00:30, 60.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|████▉     | 1641/3304 [01:25<00:26, 61.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 1706/3304 [01:25<00:24, 65.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 1550/3304 [01:25<00:28, 62.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▊     | 1608/3304 [01:25<00:27, 61.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|█████     | 1657/3304 [01:25<00:25, 65.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 1735/3304 [01:25<00:21, 72.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▌     | 1496/3304 [01:25<00:29, 60.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|████▉     | 1648/3304 [01:25<00:26, 61.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 1557/3304 [01:25<00:28, 61.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▉     | 1616/3304 [01:25<00:26, 62.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|█████     | 1665/3304 [01:25<00:24, 65.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 1743/3304 [01:25<00:21, 73.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 1716/3304 [01:25<00:25, 63.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|█████     | 1655/3304 [01:25<00:26, 62.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▌     | 1504/3304 [01:25<00:29, 61.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 1565/3304 [01:25<00:28, 61.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▉     | 1623/3304 [01:25<00:26, 62.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████     | 1673/3304 [01:25<00:24, 66.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 1753/3304 [01:25<00:20, 76.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 1723/3304 [01:25<00:24, 63.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|█████     | 1663/3304 [01:25<00:25, 63.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 1573/3304 [01:25<00:27, 63.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████     | 1681/3304 [01:25<00:24, 66.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 1763/3304 [01:25<00:19, 77.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▌     | 1514/3304 [01:25<00:30, 59.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 1730/3304 [01:25<00:25, 61.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▉     | 1633/3304 [01:26<00:27, 60.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████     | 1671/3304 [01:25<00:25, 63.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 1581/3304 [01:25<00:26, 64.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▎    | 1772/3304 [01:25<00:19, 78.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████     | 1689/3304 [01:25<00:24, 66.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▌     | 1521/3304 [01:25<00:29, 59.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 1738/3304 [01:25<00:25, 61.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|████▉     | 1641/3304 [01:26<00:26, 61.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████     | 1679/3304 [01:25<00:25, 64.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 1589/3304 [01:25<00:26, 65.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▍    | 1780/3304 [01:25<00:19, 77.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████▏    | 1697/3304 [01:25<00:24, 66.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▌     | 1528/3304 [01:25<00:30, 59.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 1745/3304 [01:25<00:24, 62.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|████▉     | 1648/3304 [01:26<00:26, 61.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████     | 1687/3304 [01:25<00:25, 63.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 1597/3304 [01:25<00:25, 66.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▍    | 1789/3304 [01:25<00:19, 77.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 1705/3304 [01:26<00:23, 66.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▋     | 1535/3304 [01:26<00:30, 58.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 1753/3304 [01:26<00:24, 63.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|█████     | 1655/3304 [01:26<00:26, 62.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▍    | 1797/3304 [01:26<00:19, 77.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████▏    | 1695/3304 [01:26<00:25, 63.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▊     | 1604/3304 [01:26<00:26, 64.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 1542/3304 [01:26<00:29, 60.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 1761/3304 [01:26<00:23, 65.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|█████     | 1663/3304 [01:26<00:25, 63.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 1715/3304 [01:26<00:25, 63.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▍    | 1805/3304 [01:26<00:19, 77.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 1703/3304 [01:26<00:24, 64.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▉     | 1612/3304 [01:26<00:26, 64.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 1549/3304 [01:26<00:29, 59.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▎    | 1769/3304 [01:26<00:23, 66.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████     | 1671/3304 [01:26<00:25, 63.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 1722/3304 [01:26<00:24, 63.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▍    | 1815/3304 [01:26<00:18, 79.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▉     | 1620/3304 [01:26<00:25, 65.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 1555/3304 [01:26<00:30, 58.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▍    | 1777/3304 [01:26<00:23, 65.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 1712/3304 [01:26<00:26, 60.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████     | 1679/3304 [01:26<00:25, 64.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 1730/3304 [01:26<00:25, 62.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▌    | 1825/3304 [01:26<00:18, 78.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▉     | 1627/3304 [01:26<00:26, 63.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▍    | 1784/3304 [01:26<00:23, 64.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 1563/3304 [01:26<00:29, 59.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 1719/3304 [01:26<00:26, 60.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████     | 1687/3304 [01:26<00:25, 63.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 1738/3304 [01:26<00:25, 62.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▌    | 1833/3304 [01:26<00:19, 77.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▉     | 1634/3304 [01:26<00:26, 62.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 1570/3304 [01:26<00:28, 60.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▍    | 1791/3304 [01:26<00:23, 63.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 1726/3304 [01:26<00:26, 60.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████▏    | 1695/3304 [01:27<00:25, 63.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 1746/3304 [01:26<00:24, 63.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▌    | 1843/3304 [01:26<00:18, 78.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|████▉     | 1642/3304 [01:26<00:25, 64.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▍    | 1799/3304 [01:26<00:23, 64.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 1578/3304 [01:26<00:27, 61.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 1733/3304 [01:26<00:26, 59.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 1703/3304 [01:27<00:24, 64.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▌    | 1851/3304 [01:26<00:18, 77.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 1754/3304 [01:26<00:24, 64.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|████▉     | 1650/3304 [01:26<00:26, 63.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▍    | 1806/3304 [01:26<00:23, 64.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 1585/3304 [01:26<00:27, 61.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 1741/3304 [01:26<00:26, 59.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▋    | 1859/3304 [01:26<00:19, 74.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 1762/3304 [01:26<00:23, 65.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 1712/3304 [01:27<00:26, 60.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|█████     | 1658/3304 [01:26<00:25, 65.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▍    | 1814/3304 [01:26<00:22, 66.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 1593/3304 [01:26<00:26, 63.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 1749/3304 [01:27<00:25, 61.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 1867/3304 [01:27<00:19, 72.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▎    | 1770/3304 [01:27<00:22, 66.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 1719/3304 [01:27<00:26, 60.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|█████     | 1666/3304 [01:27<00:25, 65.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▌    | 1822/3304 [01:27<00:22, 66.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 1600/3304 [01:27<00:27, 62.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 1757/3304 [01:27<00:24, 62.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 1875/3304 [01:27<00:19, 73.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▍    | 1777/3304 [01:27<00:23, 66.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 1726/3304 [01:27<00:26, 60.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████     | 1674/3304 [01:27<00:24, 66.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▌    | 1830/3304 [01:27<00:22, 65.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 1765/3304 [01:27<00:24, 63.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▊     | 1610/3304 [01:27<00:27, 61.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 1885/3304 [01:27<00:18, 77.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▍    | 1785/3304 [01:27<00:23, 65.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 1733/3304 [01:27<00:26, 59.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████     | 1682/3304 [01:27<00:24, 66.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▌    | 1837/3304 [01:27<00:22, 64.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▉     | 1617/3304 [01:27<00:27, 61.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 1894/3304 [01:27<00:18, 76.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▎    | 1773/3304 [01:27<00:24, 63.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▍    | 1793/3304 [01:27<00:23, 64.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████     | 1690/3304 [01:27<00:24, 65.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▌    | 1845/3304 [01:27<00:22, 65.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 1741/3304 [01:27<00:26, 59.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 1902/3304 [01:27<00:18, 77.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▉     | 1624/3304 [01:27<00:27, 62.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▍    | 1781/3304 [01:27<00:24, 63.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▍    | 1801/3304 [01:27<00:23, 64.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▌    | 1852/3304 [01:27<00:22, 63.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████▏    | 1698/3304 [01:27<00:24, 66.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 1749/3304 [01:27<00:25, 61.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 1911/3304 [01:27<00:18, 76.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▍    | 1809/3304 [01:27<00:22, 65.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▍    | 1789/3304 [01:27<00:24, 62.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▉     | 1634/3304 [01:27<00:27, 59.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▋    | 1859/3304 [01:27<00:23, 61.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 1706/3304 [01:27<00:24, 65.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 1757/3304 [01:28<00:24, 62.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 1919/3304 [01:27<00:18, 75.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▍    | 1817/3304 [01:27<00:22, 66.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▍    | 1797/3304 [01:27<00:23, 63.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|████▉     | 1642/3304 [01:27<00:26, 61.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 1765/3304 [01:28<00:24, 64.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 1928/3304 [01:27<00:18, 75.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 1869/3304 [01:27<00:23, 61.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 1716/3304 [01:27<00:25, 63.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▌    | 1825/3304 [01:27<00:22, 66.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▍    | 1805/3304 [01:27<00:23, 62.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|████▉     | 1650/3304 [01:27<00:26, 61.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▎    | 1773/3304 [01:28<00:24, 63.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▊    | 1938/3304 [01:27<00:17, 78.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 1876/3304 [01:27<00:23, 61.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 1723/3304 [01:27<00:24, 63.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▌    | 1833/3304 [01:27<00:22, 64.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▍    | 1813/3304 [01:28<00:23, 64.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|█████     | 1658/3304 [01:28<00:26, 63.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▍    | 1780/3304 [01:28<00:24, 63.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 1884/3304 [01:28<00:21, 64.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▉    | 1947/3304 [01:28<00:17, 77.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 1730/3304 [01:28<00:25, 61.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▌    | 1841/3304 [01:28<00:22, 66.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▌    | 1821/3304 [01:28<00:22, 64.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|█████     | 1666/3304 [01:28<00:25, 63.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▍    | 1788/3304 [01:28<00:23, 63.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▉    | 1956/3304 [01:28<00:17, 78.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 1892/3304 [01:28<00:21, 65.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 1737/3304 [01:28<00:25, 61.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▌    | 1828/3304 [01:28<00:23, 63.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▌    | 1849/3304 [01:28<00:22, 64.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████     | 1674/3304 [01:28<00:25, 64.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▍    | 1795/3304 [01:28<00:23, 63.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▉    | 1965/3304 [01:28<00:17, 78.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 1900/3304 [01:28<00:21, 64.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 1745/3304 [01:28<00:24, 62.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▌    | 1835/3304 [01:28<00:23, 62.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▌    | 1857/3304 [01:28<00:22, 63.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████     | 1682/3304 [01:28<00:25, 64.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▍    | 1802/3304 [01:28<00:24, 62.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|█████▉    | 1974/3304 [01:28<00:17, 77.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 1908/3304 [01:28<00:21, 65.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 1753/3304 [01:28<00:24, 64.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▌    | 1843/3304 [01:28<00:23, 63.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▋    | 1864/3304 [01:28<00:23, 62.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|█████▉    | 1982/3304 [01:28<00:17, 77.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▍    | 1810/3304 [01:28<00:23, 63.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████     | 1690/3304 [01:28<00:25, 63.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 1761/3304 [01:28<00:23, 65.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 1916/3304 [01:28<00:21, 63.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▌    | 1850/3304 [01:28<00:23, 62.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 1871/3304 [01:28<00:22, 62.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|██████    | 1991/3304 [01:28<00:16, 78.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▌    | 1818/3304 [01:29<00:22, 65.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████▏    | 1698/3304 [01:28<00:25, 64.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▎    | 1769/3304 [01:28<00:23, 66.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 1924/3304 [01:28<00:21, 65.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 1878/3304 [01:28<00:22, 63.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▌    | 1857/3304 [01:28<00:23, 60.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▌    | 1826/3304 [01:29<00:23, 63.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 1706/3304 [01:28<00:25, 63.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 1932/3304 [01:28<00:20, 65.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▍    | 1777/3304 [01:28<00:23, 64.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 1886/3304 [01:28<00:21, 65.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▋    | 1864/3304 [01:28<00:24, 59.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▌    | 1833/3304 [01:29<00:23, 62.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▍    | 1785/3304 [01:28<00:22, 66.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▊    | 1940/3304 [01:28<00:20, 66.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 1893/3304 [01:28<00:21, 65.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 1716/3304 [01:28<00:26, 60.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 1871/3304 [01:28<00:23, 60.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▌    | 1841/3304 [01:29<00:22, 64.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▉    | 1947/3304 [01:29<00:20, 65.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▍    | 1793/3304 [01:29<00:23, 64.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 1723/3304 [01:29<00:25, 61.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 1901/3304 [01:29<00:21, 64.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 1878/3304 [01:29<00:23, 60.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▌    | 1848/3304 [01:29<00:23, 62.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▉    | 1955/3304 [01:29<00:20, 66.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▍    | 1801/3304 [01:29<00:23, 65.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 1909/3304 [01:29<00:21, 65.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 1730/3304 [01:29<00:26, 59.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 1886/3304 [01:29<00:22, 62.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▌    | 1855/3304 [01:29<00:23, 61.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▉    | 1963/3304 [01:29<00:20, 66.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▍    | 1809/3304 [01:29<00:22, 66.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 1893/3304 [01:29<00:22, 62.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 1737/3304 [01:29<00:26, 59.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 1917/3304 [01:29<00:21, 64.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|█████▉    | 1971/3304 [01:29<00:20, 66.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▍    | 1817/3304 [01:29<00:22, 66.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▋    | 1865/3304 [01:29<00:24, 59.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 1745/3304 [01:29<00:25, 60.21 examples/s]#015Map:  58%|█████▊    | 1901/3304 [01:29<00:22, 62.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 1925/3304 [01:29<00:21, 64.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|█████▉    | 1979/3304 [01:29<00:20, 65.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▌    | 1825/3304 [01:29<00:22, 66.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 1872/3304 [01:29<00:24, 59.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▊    | 1933/3304 [01:29<00:20, 65.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 1909/3304 [01:29<00:22, 62.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 1753/3304 [01:29<00:25, 61.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|██████    | 1987/3304 [01:29<00:20, 65.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 1880/3304 [01:30<00:23, 61.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▌    | 1833/3304 [01:29<00:22, 64.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▊    | 1941/3304 [01:29<00:20, 66.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 1916/3304 [01:29<00:22, 61.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 1761/3304 [01:29<00:24, 62.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|██████    | 1995/3304 [01:29<00:19, 66.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 1888/3304 [01:30<00:22, 63.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▌    | 1841/3304 [01:29<00:22, 66.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▉    | 1948/3304 [01:29<00:20, 65.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▎    | 1769/3304 [01:29<00:24, 63.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 1924/3304 [01:29<00:22, 62.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 1895/3304 [01:30<00:22, 62.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▌    | 1849/3304 [01:29<00:22, 64.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▉    | 1956/3304 [01:29<00:20, 66.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 1931/3304 [01:29<00:22, 62.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▍    | 1776/3304 [01:29<00:24, 63.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 1903/3304 [01:30<00:22, 63.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▉    | 1964/3304 [01:30<00:20, 66.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▌    | 1857/3304 [01:30<00:22, 63.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▍    | 1784/3304 [01:30<00:23, 64.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▊    | 1939/3304 [01:30<00:21, 63.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 1910/3304 [01:30<00:22, 62.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|█████▉    | 1972/3304 [01:30<00:19, 66.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▋    | 1864/3304 [01:30<00:23, 62.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▉    | 1946/3304 [01:30<00:21, 63.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▍    | 1794/3304 [01:30<00:24, 62.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|█████▉    | 1979/3304 [01:30<00:20, 65.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 1871/3304 [01:30<00:22, 62.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 1920/3304 [01:30<00:22, 62.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▉    | 1954/3304 [01:30<00:21, 63.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▍    | 1802/3304 [01:30<00:24, 61.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 1878/3304 [01:30<00:22, 63.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|██████    | 1987/3304 [01:30<00:20, 65.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 1927/3304 [01:30<00:21, 62.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▉    | 1962/3304 [01:30<00:20, 64.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▍    | 1810/3304 [01:30<00:23, 63.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 1886/3304 [01:30<00:21, 65.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|██████    | 1995/3304 [01:30<00:19, 67.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▊    | 1935/3304 [01:30<00:21, 64.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|█████▉    | 1970/3304 [01:30<00:20, 63.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▌    | 1818/3304 [01:30<00:23, 64.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 1893/3304 [01:30<00:21, 65.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▉    | 1942/3304 [01:30<00:21, 63.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|█████▉    | 1978/3304 [01:30<00:20, 63.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 1901/3304 [01:30<00:21, 65.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▌    | 1826/3304 [01:30<00:23, 63.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▉    | 1950/3304 [01:31<00:21, 64.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|██████    | 1985/3304 [01:30<00:20, 63.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 1909/3304 [01:30<00:21, 66.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▌    | 1833/3304 [01:30<00:23, 62.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▉    | 1958/3304 [01:31<00:20, 66.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|██████    | 1993/3304 [01:30<00:20, 64.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▌    | 1841/3304 [01:30<00:22, 64.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 1917/3304 [01:30<00:21, 64.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|█████▉    | 1966/3304 [01:31<00:20, 65.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▌    | 1848/3304 [01:31<00:23, 63.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 1925/3304 [01:31<00:21, 65.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|█████▉    | 1974/3304 [01:31<00:20, 65.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▊    | 1933/3304 [01:31<00:20, 67.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▌    | 1856/3304 [01:31<00:23, 62.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|█████▉    | 1982/3304 [01:31<00:20, 64.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▊    | 1941/3304 [01:31<00:19, 68.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|██████    | 1990/3304 [01:31<00:19, 65.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▋    | 1865/3304 [01:31<00:23, 60.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▉    | 1949/3304 [01:31<00:19, 67.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|██████    | 1998/3304 [01:31<00:19, 66.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 1872/3304 [01:31<00:23, 60.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▉    | 1957/3304 [01:31<00:19, 69.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 1880/3304 [01:31<00:22, 62.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▉    | 1965/3304 [01:31<00:19, 69.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 1888/3304 [01:31<00:21, 65.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|█████▉    | 1973/3304 [01:31<00:19, 69.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 1896/3304 [01:31<00:21, 64.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|█████▉    | 1980/3304 [01:31<00:19, 68.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 1904/3304 [01:31<00:21, 65.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|██████    | 1988/3304 [01:31<00:19, 69.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 1912/3304 [01:32<00:21, 64.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|██████    | 1996/3304 [01:32<00:18, 71.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 1920/3304 [01:32<00:21, 65.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 1928/3304 [01:32<00:20, 66.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▊    | 1936/3304 [01:32<00:19, 69.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▉    | 1944/3304 [01:32<00:19, 68.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▉    | 1952/3304 [01:32<00:19, 69.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▉    | 1960/3304 [01:32<00:18, 71.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|█████▉    | 1968/3304 [01:32<00:18, 70.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|█████▉    | 1976/3304 [01:32<00:18, 71.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|██████    | 1984/3304 [01:33<00:18, 70.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|██████    | 1992/3304 [01:33<00:18, 71.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|██████    | 1996/3304 [01:39<00:18, 68.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|██████    | 1996/3304 [01:39<00:16, 78.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|██████    | 1998/3304 [01:49<00:19, 66.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 1999/3304 [01:49<00:19, 66.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|██████    | 1997/3304 [01:49<00:20, 64.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 1999/3304 [01:49<00:19, 67.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|██████    | 1996/3304 [01:49<00:18, 71.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|██████    | 1996/3304 [01:49<00:18, 71.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 2000/3304 [02:11<46:46,  2.15s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 2008/3304 [02:11<30:50,  1.43s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 2016/3304 [02:11<20:45,  1.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████▏   | 2024/3304 [02:12<14:10,  1.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 2032/3304 [02:12<09:46,  2.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 2040/3304 [02:12<06:48,  3.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 2048/3304 [02:12<04:47,  4.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 2056/3304 [02:12<03:24,  6.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 2064/3304 [02:12<02:27,  8.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 2072/3304 [02:12<01:47, 11.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 2080/3304 [02:12<01:20, 15.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 2088/3304 [02:12<01:00, 20.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 2097/3304 [02:13<00:45, 26.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▎   | 2105/3304 [02:13<00:37, 32.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▍   | 2113/3304 [02:13<00:30, 38.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▍   | 2122/3304 [02:13<00:26, 45.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▍   | 2130/3304 [02:13<00:22, 51.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▍   | 2138/3304 [02:13<00:20, 56.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▍   | 2146/3304 [02:13<00:19, 60.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▌   | 2155/3304 [02:13<00:17, 65.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▌   | 2163/3304 [02:13<00:17, 65.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▌   | 2172/3304 [02:14<00:16, 67.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▌   | 2181/3304 [02:14<00:16, 69.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▋   | 2189/3304 [02:14<00:16, 69.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▋   | 2197/3304 [02:14<00:15, 70.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 2205/3304 [02:14<00:15, 70.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 2213/3304 [02:14<00:15, 72.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 2222/3304 [02:14<00:15, 71.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 2231/3304 [02:14<00:14, 71.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 2239/3304 [02:15<00:14, 72.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 2247/3304 [02:15<00:14, 72.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 2255/3304 [02:15<00:14, 71.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 2263/3304 [02:15<00:14, 70.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▉   | 2273/3304 [02:15<00:13, 74.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▉   | 2284/3304 [02:15<00:13, 73.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▉   | 2292/3304 [02:15<00:14, 72.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|██████▉   | 2300/3304 [02:15<00:14, 71.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|██████▉   | 2308/3304 [02:15<00:13, 72.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|███████   | 2316/3304 [02:16<00:13, 72.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|███████   | 2324/3304 [02:16<00:13, 72.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████   | 2335/3304 [02:16<00:13, 69.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████   | 2343/3304 [02:16<00:13, 71.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████   | 2351/3304 [02:16<00:13, 72.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████▏  | 2359/3304 [02:16<00:13, 72.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 2369/3304 [02:16<00:13, 67.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 2377/3304 [02:16<00:13, 67.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 2385/3304 [02:17<00:13, 67.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 2393/3304 [02:17<00:13, 69.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 2401/3304 [02:17<00:13, 68.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 2409/3304 [02:17<00:12, 69.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 2417/3304 [02:17<00:12, 70.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 2425/3304 [02:17<00:12, 70.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▎  | 2433/3304 [02:17<00:12, 70.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▍  | 2441/3304 [02:17<00:12, 70.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▍  | 2449/3304 [02:17<00:12, 70.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▍  | 2458/3304 [02:18<00:11, 72.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▍  | 2467/3304 [02:18<00:11, 73.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▍  | 2475/3304 [02:18<00:11, 73.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▌  | 2483/3304 [02:18<00:11, 73.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▌  | 2491/3304 [02:18<00:11, 72.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▌  | 2499/3304 [02:18<00:11, 70.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▌  | 2507/3304 [02:18<00:11, 71.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▌  | 2515/3304 [02:18<00:11, 71.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▋  | 2524/3304 [02:19<00:10, 73.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 2532/3304 [02:19<00:10, 73.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 2540/3304 [02:19<00:10, 73.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 2548/3304 [02:19<00:10, 73.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 2556/3304 [02:19<00:10, 73.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 2567/3304 [02:19<00:10, 71.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 2576/3304 [02:19<00:10, 72.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 2584/3304 [02:19<00:10, 71.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▊  | 2595/3304 [02:20<00:10, 68.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▉  | 2602/3304 [02:20<00:10, 67.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▉  | 2610/3304 [02:20<00:10, 66.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▉  | 2618/3304 [02:20<00:10, 68.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 2000/3304 [02:20<38:17,  1.76s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 2008/3304 [02:20<27:31,  1.27s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  80%|███████▉  | 2628/3304 [02:20<00:10, 64.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 2016/3304 [02:20<19:38,  1.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|███████▉  | 2636/3304 [02:20<00:10, 66.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|███████▉  | 2643/3304 [02:20<00:09, 66.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████▏   | 2027/3304 [02:20<12:36,  1.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|████████  | 2651/3304 [02:20<00:09, 67.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 2035/3304 [02:20<09:12,  2.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|████████  | 2659/3304 [02:20<00:09, 67.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 2043/3304 [02:21<06:40,  3.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 2000/3304 [02:21<47:31,  2.19s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████  | 2666/3304 [02:21<00:09, 67.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 2051/3304 [02:21<04:49,  4.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 2008/3304 [02:21<31:55,  1.48s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████  | 2674/3304 [02:21<00:09, 67.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 2059/3304 [02:21<03:30,  5.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 2016/3304 [02:21<21:43,  1.01s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████  | 2682/3304 [02:21<00:09, 66.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 2066/3304 [02:21<02:38,  7.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████▏   | 2024/3304 [02:21<14:57,  1.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████▏ | 2690/3304 [02:21<00:09, 67.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 2074/3304 [02:21<01:54, 10.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 2032/3304 [02:21<10:21,  2.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 2698/3304 [02:21<00:08, 67.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 2081/3304 [02:21<01:28, 13.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 2040/3304 [02:21<07:14,  2.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 2705/3304 [02:21<00:09, 66.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 2089/3304 [02:21<01:06, 18.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 2048/3304 [02:21<05:05,  4.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 2713/3304 [02:21<00:08, 66.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 2097/3304 [02:21<00:50, 23.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 2056/3304 [02:21<03:37,  5.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▎   | 2104/3304 [02:21<00:41, 28.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 2723/3304 [02:21<00:09, 63.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 2064/3304 [02:21<02:36,  7.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 2000/3304 [02:22<48:28,  2.23s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▍   | 2112/3304 [02:22<00:33, 35.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 2731/3304 [02:22<00:08, 66.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 2072/3304 [02:22<01:53, 10.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 2008/3304 [02:22<32:24,  1.50s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▍   | 2120/3304 [02:22<00:28, 42.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 2739/3304 [02:22<00:08, 66.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 2080/3304 [02:22<01:24, 14.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 2016/3304 [02:22<21:59,  1.02s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▍   | 2127/3304 [02:22<00:25, 46.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 2088/3304 [02:22<01:04, 19.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 2749/3304 [02:22<00:08, 65.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 2023/3304 [02:22<15:42,  1.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▍   | 2135/3304 [02:22<00:22, 52.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 2096/3304 [02:22<00:49, 24.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 2757/3304 [02:22<00:08, 66.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████▏   | 2031/3304 [02:22<10:44,  1.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▍   | 2143/3304 [02:22<00:20, 56.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▎   | 2103/3304 [02:22<00:41, 29.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▎ | 2765/3304 [02:22<00:08, 66.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 2039/3304 [02:22<07:25,  2.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▌   | 2151/3304 [02:22<00:19, 60.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▍   | 2111/3304 [02:22<00:33, 35.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▍ | 2773/3304 [02:22<00:07, 67.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 2047/3304 [02:22<05:12,  4.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▌   | 2159/3304 [02:22<00:18, 62.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▍   | 2119/3304 [02:22<00:27, 42.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▍ | 2781/3304 [02:22<00:07, 68.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▌   | 2166/3304 [02:22<00:17, 63.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 2055/3304 [02:22<03:41,  5.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▍ | 2789/3304 [02:22<00:07, 69.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▍   | 2130/3304 [02:22<00:23, 49.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▌   | 2173/3304 [02:22<00:17, 63.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 2062/3304 [02:22<02:44,  7.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▍   | 2138/3304 [02:23<00:21, 54.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▍ | 2797/3304 [02:23<00:07, 68.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▌   | 2181/3304 [02:23<00:17, 65.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 2070/3304 [02:23<01:57, 10.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▍ | 2805/3304 [02:23<00:07, 68.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▍   | 2146/3304 [02:23<00:20, 57.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▋   | 2189/3304 [02:23<00:17, 65.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 2078/3304 [02:23<01:26, 14.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▌ | 2813/3304 [02:23<00:07, 69.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▌   | 2154/3304 [02:23<00:18, 61.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 2000/3304 [02:23<45:44,  2.10s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▋   | 2197/3304 [02:23<00:16, 66.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 2086/3304 [02:23<01:05, 18.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 2007/3304 [02:23<32:36,  1.51s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▌ | 2821/3304 [02:23<00:07, 68.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 2094/3304 [02:23<00:50, 24.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 2205/3304 [02:23<00:16, 66.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▌   | 2165/3304 [02:23<00:18, 62.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 2015/3304 [02:23<22:12,  1.03s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▌ | 2829/3304 [02:23<00:06, 68.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▎   | 2101/3304 [02:23<00:41, 29.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 2213/3304 [02:23<00:16, 67.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▌   | 2173/3304 [02:23<00:18, 62.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 2022/3304 [02:23<15:54,  1.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▌ | 2836/3304 [02:23<00:07, 65.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 2220/3304 [02:23<00:16, 67.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▍   | 2109/3304 [02:23<00:33, 35.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▌   | 2181/3304 [02:23<00:17, 64.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████▏   | 2030/3304 [02:23<10:53,  1.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 2228/3304 [02:23<00:15, 68.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▍   | 2117/3304 [02:23<00:28, 42.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▌ | 2844/3304 [02:23<00:07, 65.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▌   | 2188/3304 [02:23<00:17, 64.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 2235/3304 [02:23<00:15, 67.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 2038/3304 [02:23<07:32,  2.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▋ | 2852/3304 [02:23<00:06, 65.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▍   | 2125/3304 [02:23<00:25, 46.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 2000/3304 [02:24<55:37,  2.56s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▋   | 2196/3304 [02:23<00:16, 65.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 2045/3304 [02:23<05:29,  3.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 2243/3304 [02:23<00:15, 67.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▍   | 2133/3304 [02:23<00:22, 52.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 2859/3304 [02:23<00:06, 63.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 2204/3304 [02:24<00:16, 65.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 2008/3304 [02:24<35:40,  1.65s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 2052/3304 [02:24<03:59,  5.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 2251/3304 [02:24<00:15, 68.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▍   | 2141/3304 [02:24<00:20, 57.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 2867/3304 [02:24<00:06, 64.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 2016/3304 [02:24<23:35,  1.10s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 2212/3304 [02:24<00:16, 66.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 2059/3304 [02:24<02:54,  7.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 2259/3304 [02:24<00:15, 67.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▌   | 2149/3304 [02:24<00:19, 60.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 2875/3304 [02:24<00:06, 65.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 2023/3304 [02:24<16:35,  1.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 2220/3304 [02:24<00:16, 66.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 2066/3304 [02:24<02:08,  9.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▊   | 2266/3304 [02:24<00:15, 66.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▌   | 2157/3304 [02:24<00:18, 62.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 2883/3304 [02:24<00:06, 67.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████▏   | 2031/3304 [02:24<11:12,  1.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 2228/3304 [02:24<00:16, 66.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 2074/3304 [02:24<01:32, 13.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▉   | 2274/3304 [02:24<00:14, 69.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 2891/3304 [02:24<00:06, 68.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▌   | 2165/3304 [02:24<00:18, 62.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 2039/3304 [02:24<07:41,  2.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 2235/3304 [02:24<00:16, 65.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 2081/3304 [02:24<01:11, 17.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▉   | 2282/3304 [02:24<00:15, 67.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 2899/3304 [02:24<00:05, 68.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▌   | 2173/3304 [02:24<00:18, 62.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 2047/3304 [02:24<05:21,  3.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 2243/3304 [02:24<00:16, 65.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 2089/3304 [02:24<00:54, 22.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▉   | 2290/3304 [02:24<00:15, 67.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 2906/3304 [02:24<00:05, 67.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▌   | 2181/3304 [02:24<00:17, 64.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 2054/3304 [02:25<03:55,  5.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 2251/3304 [02:24<00:15, 66.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 2097/3304 [02:24<00:42, 28.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|██████▉   | 2298/3304 [02:24<00:15, 67.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 2914/3304 [02:24<00:05, 66.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▌   | 2188/3304 [02:24<00:17, 64.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 2258/3304 [02:24<00:15, 65.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 2062/3304 [02:25<02:46,  7.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|██████▉   | 2306/3304 [02:24<00:14, 68.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▋   | 2195/3304 [02:24<00:17, 64.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 2922/3304 [02:24<00:05, 66.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▍   | 2107/3304 [02:24<00:34, 35.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▊   | 2265/3304 [02:24<00:16, 64.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 2070/3304 [02:25<01:59, 10.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|███████   | 2314/3304 [02:25<00:14, 68.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▊ | 2930/3304 [02:25<00:05, 67.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 2203/3304 [02:25<00:16, 65.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▍   | 2115/3304 [02:25<00:28, 41.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▉   | 2273/3304 [02:25<00:15, 66.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 2078/3304 [02:25<01:28, 13.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|███████   | 2322/3304 [02:25<00:14, 68.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▉ | 2937/3304 [02:25<00:05, 64.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 2211/3304 [02:25<00:16, 65.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▍   | 2122/3304 [02:25<00:26, 44.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▉   | 2280/3304 [02:25<00:15, 65.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 2085/3304 [02:25<01:08, 17.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████   | 2330/3304 [02:25<00:14, 66.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 2219/3304 [02:25<00:16, 65.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▉ | 2945/3304 [02:25<00:05, 64.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▍   | 2130/3304 [02:25<00:23, 50.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▉   | 2288/3304 [02:25<00:15, 65.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 2093/3304 [02:25<00:52, 23.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████   | 2338/3304 [02:25<00:14, 67.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 2000/3304 [02:25<52:10,  2.40s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 2227/3304 [02:25<00:16, 67.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▉ | 2953/3304 [02:25<00:05, 66.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▍   | 2138/3304 [02:25<00:21, 54.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▎   | 2100/3304 [02:25<00:42, 28.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▉   | 2296/3304 [02:25<00:15, 66.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████   | 2346/3304 [02:25<00:13, 69.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 2007/3304 [02:25<35:56,  1.66s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  90%|████████▉ | 2961/3304 [02:25<00:05, 66.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 2235/3304 [02:25<00:16, 66.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|██████▉   | 2303/3304 [02:25<00:15, 66.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▍   | 2145/3304 [02:25<00:20, 55.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▍   | 2108/3304 [02:25<00:34, 34.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████   | 2354/3304 [02:25<00:13, 69.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 2015/3304 [02:25<23:50,  1.11s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  90%|████████▉ | 2968/3304 [02:25<00:05, 66.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 2243/3304 [02:25<00:16, 65.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▌   | 2153/3304 [02:25<00:19, 59.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|██████▉   | 2311/3304 [02:25<00:14, 66.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▍   | 2116/3304 [02:26<00:28, 41.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|█████████ | 2976/3304 [02:25<00:04, 67.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 2023/3304 [02:25<16:07,  1.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 2251/3304 [02:25<00:15, 66.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▌   | 2160/3304 [02:25<00:19, 59.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 2364/3304 [02:25<00:14, 65.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▍   | 2123/3304 [02:26<00:26, 45.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|███████   | 2319/3304 [02:25<00:14, 65.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|█████████ | 2984/3304 [02:25<00:04, 67.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████▏   | 2031/3304 [02:25<11:02,  1.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▌   | 2167/3304 [02:25<00:18, 60.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 2371/3304 [02:25<00:14, 65.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▍   | 2131/3304 [02:26<00:23, 50.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|███████   | 2326/3304 [02:25<00:15, 64.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 2259/3304 [02:25<00:15, 65.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 2992/3304 [02:25<00:04, 67.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 2039/3304 [02:25<07:39,  2.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▌   | 2174/3304 [02:25<00:18, 59.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▊   | 2266/3304 [02:25<00:15, 65.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▍   | 2139/3304 [02:26<00:20, 55.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 2379/3304 [02:25<00:14, 64.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████   | 2334/3304 [02:25<00:15, 64.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 2999/3304 [02:26<00:04, 66.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 2047/3304 [02:26<05:21,  3.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▉   | 2274/3304 [02:26<00:15, 68.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▌   | 2182/3304 [02:26<00:18, 61.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 2387/3304 [02:26<00:13, 66.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▍   | 2147/3304 [02:26<00:19, 58.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████   | 2342/3304 [02:26<00:14, 66.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 2054/3304 [02:26<03:56,  5.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▉   | 2282/3304 [02:26<00:15, 67.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▌   | 2155/3304 [02:26<00:18, 61.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████   | 2350/3304 [02:26<00:14, 67.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 2396/3304 [02:26<00:13, 68.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▋   | 2190/3304 [02:26<00:18, 61.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 2062/3304 [02:26<02:47,  7.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▉   | 2290/3304 [02:26<00:15, 66.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▌   | 2162/3304 [02:26<00:18, 61.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 2404/3304 [02:26<00:12, 69.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████▏  | 2358/3304 [02:26<00:14, 67.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 2198/3304 [02:26<00:18, 61.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 2070/3304 [02:26<02:00, 10.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 2412/3304 [02:26<00:12, 70.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▌   | 2169/3304 [02:26<00:18, 61.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|██████▉   | 2298/3304 [02:26<00:15, 66.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 2205/3304 [02:26<00:17, 61.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 2368/3304 [02:26<00:14, 63.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 2420/3304 [02:26<00:12, 70.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▌   | 2177/3304 [02:26<00:17, 64.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 2078/3304 [02:26<01:29, 13.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|██████▉   | 2306/3304 [02:26<00:14, 67.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 2213/3304 [02:26<00:17, 63.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 2375/3304 [02:26<00:14, 63.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 2428/3304 [02:26<00:12, 70.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 2085/3304 [02:26<01:09, 17.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|███████   | 2313/3304 [02:26<00:14, 66.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▌   | 2185/3304 [02:27<00:17, 64.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 2220/3304 [02:26<00:17, 63.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 2382/3304 [02:26<00:14, 63.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▎  | 2436/3304 [02:26<00:12, 70.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 2093/3304 [02:26<00:53, 22.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|███████   | 2321/3304 [02:26<00:14, 67.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▋   | 2192/3304 [02:27<00:17, 63.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 2228/3304 [02:26<00:16, 63.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 2390/3304 [02:26<00:14, 64.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▍  | 2444/3304 [02:26<00:12, 71.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▎   | 2100/3304 [02:26<00:43, 27.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 2199/3304 [02:27<00:17, 63.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|███████   | 2328/3304 [02:26<00:15, 64.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 2235/3304 [02:26<00:17, 62.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 2398/3304 [02:26<00:14, 64.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▍  | 2452/3304 [02:27<00:11, 71.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 2207/3304 [02:27<00:16, 64.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▍   | 2108/3304 [02:27<00:35, 33.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████   | 2336/3304 [02:27<00:14, 65.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 2243/3304 [02:27<00:17, 62.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 2406/3304 [02:27<00:13, 64.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▍  | 2461/3304 [02:27<00:11, 73.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▍   | 2116/3304 [02:27<00:29, 40.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████   | 2344/3304 [02:27<00:14, 67.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 2215/3304 [02:27<00:16, 65.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 2251/3304 [02:27<00:16, 63.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 2414/3304 [02:27<00:13, 65.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▍  | 2469/3304 [02:27<00:11, 74.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▍   | 2123/3304 [02:27<00:26, 44.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████   | 2352/3304 [02:27<00:13, 68.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 2223/3304 [02:27<00:16, 65.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 2258/3304 [02:27<00:16, 62.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▍  | 2477/3304 [02:27<00:11, 74.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 2422/3304 [02:27<00:13, 64.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▍   | 2131/3304 [02:27<00:23, 50.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████▏  | 2360/3304 [02:27<00:14, 67.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 2231/3304 [02:27<00:16, 64.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▊   | 2265/3304 [02:27<00:16, 62.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▌  | 2486/3304 [02:27<00:11, 73.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▎  | 2429/3304 [02:27<00:13, 63.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▍   | 2139/3304 [02:27<00:20, 55.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 2239/3304 [02:27<00:16, 65.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▉   | 2273/3304 [02:27<00:15, 65.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 2370/3304 [02:27<00:14, 62.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▌  | 2494/3304 [02:27<00:11, 72.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▍  | 2437/3304 [02:27<00:13, 63.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▍   | 2147/3304 [02:27<00:19, 58.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 2247/3304 [02:28<00:16, 65.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▉   | 2280/3304 [02:27<00:15, 64.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 2378/3304 [02:27<00:14, 63.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▌   | 2155/3304 [02:27<00:18, 61.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▍  | 2445/3304 [02:27<00:13, 63.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▌  | 2506/3304 [02:27<00:11, 71.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 2000/3304 [02:27<44:41,  2.06s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 2255/3304 [02:28<00:15, 65.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▉   | 2288/3304 [02:27<00:15, 64.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 2386/3304 [02:27<00:14, 64.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▌   | 2162/3304 [02:27<00:18, 60.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▍  | 2453/3304 [02:27<00:13, 64.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 2007/3304 [02:27<32:25,  1.50s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▌  | 2515/3304 [02:27<00:10, 72.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 2262/3304 [02:28<00:16, 64.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▉   | 2296/3304 [02:27<00:15, 64.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 2394/3304 [02:27<00:14, 64.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▌   | 2169/3304 [02:27<00:18, 61.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▍  | 2461/3304 [02:27<00:12, 66.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▊   | 2270/3304 [02:28<00:15, 66.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 2015/3304 [02:27<22:23,  1.04s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▋  | 2525/3304 [02:27<00:10, 74.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|██████▉   | 2303/3304 [02:27<00:15, 65.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 2402/3304 [02:28<00:13, 64.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▌   | 2177/3304 [02:28<00:17, 63.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▍  | 2469/3304 [02:28<00:12, 66.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▉   | 2278/3304 [02:28<00:15, 66.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 2022/3304 [02:28<16:10,  1.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 2534/3304 [02:28<00:10, 74.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|██████▉   | 2311/3304 [02:28<00:15, 65.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 2410/3304 [02:28<00:13, 65.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▌   | 2185/3304 [02:28<00:17, 64.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▍  | 2477/3304 [02:28<00:12, 65.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 2542/3304 [02:28<00:10, 73.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████▏   | 2030/3304 [02:28<11:09,  1.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▉   | 2286/3304 [02:28<00:15, 65.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|███████   | 2319/3304 [02:28<00:15, 65.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 2418/3304 [02:28<00:13, 65.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▌  | 2484/3304 [02:28<00:12, 65.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 2551/3304 [02:28<00:09, 75.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▉   | 2293/3304 [02:28<00:15, 64.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▋   | 2195/3304 [02:28<00:17, 63.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 2038/3304 [02:28<07:46,  2.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|███████   | 2326/3304 [02:28<00:15, 63.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 2426/3304 [02:28<00:13, 65.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▌  | 2492/3304 [02:28<00:12, 64.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|██████▉   | 2300/3304 [02:28<00:15, 65.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 2560/3304 [02:28<00:09, 75.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 2203/3304 [02:28<00:17, 64.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 2045/3304 [02:28<05:40,  3.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████   | 2333/3304 [02:28<00:15, 63.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▎  | 2433/3304 [02:28<00:13, 64.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▌  | 2499/3304 [02:28<00:12, 63.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|██████▉   | 2308/3304 [02:28<00:15, 66.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 2052/3304 [02:28<04:07,  5.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 2569/3304 [02:28<00:09, 73.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 2211/3304 [02:28<00:16, 64.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████   | 2341/3304 [02:28<00:14, 65.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▍  | 2441/3304 [02:28<00:13, 64.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▌  | 2507/3304 [02:28<00:12, 63.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|███████   | 2316/3304 [02:29<00:15, 65.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 2059/3304 [02:28<03:00,  6.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 2578/3304 [02:28<00:09, 75.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████   | 2349/3304 [02:28<00:14, 65.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 2219/3304 [02:28<00:16, 64.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▍  | 2449/3304 [02:28<00:13, 64.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▌  | 2514/3304 [02:28<00:12, 64.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 2066/3304 [02:28<02:13,  9.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|███████   | 2324/3304 [02:29<00:14, 66.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 2227/3304 [02:28<00:16, 65.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████▏  | 2357/3304 [02:28<00:14, 65.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 2589/3304 [02:28<00:09, 72.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▍  | 2457/3304 [02:28<00:12, 65.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▋  | 2522/3304 [02:28<00:11, 66.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 2074/3304 [02:28<01:35, 12.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 2235/3304 [02:28<00:16, 64.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 2364/3304 [02:28<00:15, 62.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████   | 2334/3304 [02:29<00:15, 64.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▊  | 2597/3304 [02:28<00:09, 71.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▍  | 2465/3304 [02:28<00:12, 66.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 2530/3304 [02:28<00:11, 66.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 2081/3304 [02:29<01:13, 16.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 2371/3304 [02:29<00:15, 61.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 2243/3304 [02:29<00:16, 64.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████   | 2342/3304 [02:29<00:14, 66.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▉  | 2605/3304 [02:29<00:09, 70.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▍  | 2473/3304 [02:29<00:12, 66.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 2538/3304 [02:29<00:11, 65.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 2089/3304 [02:29<00:56, 21.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 2378/3304 [02:29<00:14, 61.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 2251/3304 [02:29<00:16, 65.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████   | 2350/3304 [02:29<00:14, 66.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▉  | 2613/3304 [02:29<00:09, 70.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▌  | 2480/3304 [02:29<00:12, 64.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 2546/3304 [02:29<00:11, 66.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 2097/3304 [02:29<00:43, 27.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 2386/3304 [02:29<00:14, 63.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 2258/3304 [02:29<00:16, 64.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████▏  | 2358/3304 [02:29<00:14, 66.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▉  | 2621/3304 [02:29<00:09, 69.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▌  | 2488/3304 [02:29<00:12, 65.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 2554/3304 [02:29<00:11, 66.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▊   | 2265/3304 [02:29<00:16, 64.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 2394/3304 [02:29<00:14, 63.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|███████▉  | 2628/3304 [02:29<00:09, 68.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▍   | 2107/3304 [02:29<00:35, 34.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▌  | 2496/3304 [02:29<00:12, 64.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 2368/3304 [02:29<00:14, 63.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 2562/3304 [02:29<00:11, 64.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▉   | 2273/3304 [02:29<00:15, 66.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 2402/3304 [02:29<00:14, 63.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|███████▉  | 2638/3304 [02:29<00:09, 71.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▍   | 2115/3304 [02:29<00:29, 39.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 2375/3304 [02:29<00:14, 63.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 2570/3304 [02:29<00:11, 65.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▉   | 2280/3304 [02:29<00:15, 65.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▌  | 2506/3304 [02:29<00:12, 63.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 2410/3304 [02:29<00:13, 64.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|████████  | 2647/3304 [02:29<00:09, 72.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▍   | 2122/3304 [02:29<00:26, 43.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 2382/3304 [02:30<00:14, 63.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 2578/3304 [02:29<00:10, 67.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▌  | 2513/3304 [02:29<00:12, 63.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▉   | 2288/3304 [02:29<00:15, 65.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|████████  | 2655/3304 [02:29<00:08, 72.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 2418/3304 [02:29<00:13, 64.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▍   | 2130/3304 [02:29<00:23, 48.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 2390/3304 [02:30<00:14, 64.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 2585/3304 [02:29<00:11, 64.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▋  | 2521/3304 [02:29<00:11, 65.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▉   | 2296/3304 [02:29<00:15, 65.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████  | 2663/3304 [02:29<00:08, 72.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 2426/3304 [02:29<00:13, 64.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▍   | 2138/3304 [02:29<00:21, 53.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 2398/3304 [02:30<00:14, 64.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 2592/3304 [02:29<00:11, 63.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 2529/3304 [02:29<00:11, 65.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|██████▉   | 2303/3304 [02:29<00:15, 65.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████  | 2671/3304 [02:30<00:08, 73.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▎  | 2433/3304 [02:30<00:13, 63.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▍   | 2145/3304 [02:30<00:21, 55.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 2406/3304 [02:30<00:13, 64.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|██████▉   | 2311/3304 [02:30<00:14, 66.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 2537/3304 [02:30<00:11, 65.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████  | 2679/3304 [02:30<00:08, 72.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▊  | 2601/3304 [02:30<00:11, 61.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▍  | 2441/3304 [02:30<00:13, 63.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▌   | 2153/3304 [02:30<00:19, 58.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 2414/3304 [02:30<00:13, 65.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 2545/3304 [02:30<00:11, 65.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|███████   | 2319/3304 [02:30<00:14, 65.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████▏ | 2688/3304 [02:30<00:08, 73.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▉  | 2608/3304 [02:30<00:11, 60.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▌   | 2160/3304 [02:30<00:19, 59.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▍  | 2449/3304 [02:30<00:13, 63.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 2422/3304 [02:30<00:13, 65.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|███████   | 2326/3304 [02:30<00:15, 64.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 2553/3304 [02:30<00:11, 66.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 2697/3304 [02:30<00:08, 74.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▉  | 2616/3304 [02:30<00:11, 61.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▌   | 2167/3304 [02:30<00:18, 60.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▍  | 2457/3304 [02:30<00:13, 64.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▎  | 2429/3304 [02:30<00:13, 63.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 2705/3304 [02:30<00:08, 73.05 examples/s]#015Map:  78%|███████▊  | 2561/3304 [02:30<00:11, 66.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████   | 2334/3304 [02:30<00:15, 64.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▉  | 2623/3304 [02:30<00:11, 60.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▌   | 2174/3304 [02:30<00:19, 59.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▍  | 2465/3304 [02:30<00:12, 65.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▍  | 2437/3304 [02:30<00:13, 63.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 2713/3304 [02:30<00:08, 73.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 2568/3304 [02:30<00:11, 65.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████   | 2342/3304 [02:30<00:14, 66.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|███████▉  | 2630/3304 [02:30<00:10, 61.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▌   | 2182/3304 [02:30<00:18, 60.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▍  | 2473/3304 [02:30<00:12, 65.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▍  | 2445/3304 [02:31<00:13, 63.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 2576/3304 [02:30<00:10, 66.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████   | 2350/3304 [02:30<00:14, 67.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|███████▉  | 2638/3304 [02:30<00:10, 63.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 2724/3304 [02:30<00:08, 70.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▌  | 2480/3304 [02:30<00:12, 63.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▋   | 2190/3304 [02:30<00:18, 60.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▍  | 2453/3304 [02:31<00:13, 64.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████▏  | 2358/3304 [02:30<00:14, 66.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 2584/3304 [02:30<00:11, 65.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|████████  | 2646/3304 [02:30<00:10, 63.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 2734/3304 [02:30<00:07, 73.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▌  | 2488/3304 [02:30<00:12, 64.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 2198/3304 [02:30<00:18, 60.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▍  | 2461/3304 [02:31<00:12, 66.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 2591/3304 [02:30<00:11, 63.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|████████  | 2654/3304 [02:30<00:10, 64.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 2368/3304 [02:30<00:14, 63.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▌  | 2496/3304 [02:31<00:12, 64.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 2205/3304 [02:31<00:18, 61.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 2745/3304 [02:31<00:07, 70.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▍  | 2469/3304 [02:31<00:12, 66.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████  | 2661/3304 [02:31<00:10, 64.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▊  | 2599/3304 [02:31<00:11, 63.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 2375/3304 [02:31<00:14, 63.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 2213/3304 [02:31<00:17, 62.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 2753/3304 [02:31<00:07, 72.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▍  | 2477/3304 [02:31<00:12, 65.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▌  | 2506/3304 [02:31<00:12, 62.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████  | 2669/3304 [02:31<00:09, 64.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 2382/3304 [02:31<00:14, 63.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▉  | 2608/3304 [02:31<00:11, 61.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▎ | 2761/3304 [02:31<00:07, 73.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 2220/3304 [02:31<00:17, 62.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▌  | 2484/3304 [02:31<00:12, 65.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▌  | 2513/3304 [02:31<00:12, 63.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████  | 2677/3304 [02:31<00:09, 65.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 2390/3304 [02:31<00:14, 64.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▉  | 2616/3304 [02:31<00:11, 62.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▍ | 2769/3304 [02:31<00:07, 73.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 2228/3304 [02:31<00:17, 63.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▋  | 2521/3304 [02:31<00:12, 65.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▌  | 2492/3304 [02:31<00:12, 64.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████▏ | 2685/3304 [02:31<00:09, 64.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▍ | 2777/3304 [02:31<00:07, 74.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 2398/3304 [02:31<00:14, 64.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▉  | 2623/3304 [02:31<00:11, 61.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 2235/3304 [02:31<00:17, 62.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 2529/3304 [02:31<00:11, 65.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▌  | 2499/3304 [02:31<00:12, 62.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 2693/3304 [02:31<00:09, 66.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▍ | 2786/3304 [02:31<00:06, 75.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|███████▉  | 2630/3304 [02:31<00:10, 62.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 2406/3304 [02:31<00:13, 64.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 2243/3304 [02:31<00:17, 61.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 2536/3304 [02:31<00:11, 65.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▌  | 2506/3304 [02:32<00:12, 63.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 2701/3304 [02:31<00:09, 64.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▍ | 2794/3304 [02:31<00:06, 75.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|███████▉  | 2638/3304 [02:31<00:10, 63.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 2414/3304 [02:31<00:13, 65.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▌  | 2513/3304 [02:32<00:12, 63.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 2251/3304 [02:31<00:16, 62.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 2544/3304 [02:31<00:11, 65.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▍ | 2802/3304 [02:31<00:06, 75.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 2709/3304 [02:31<00:09, 64.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|████████  | 2646/3304 [02:31<00:10, 64.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 2422/3304 [02:31<00:13, 65.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▋  | 2521/3304 [02:32<00:11, 65.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 2552/3304 [02:31<00:11, 66.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 2258/3304 [02:31<00:16, 61.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▌ | 2811/3304 [02:31<00:06, 76.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 2716/3304 [02:31<00:09, 63.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▎  | 2429/3304 [02:31<00:13, 63.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|████████  | 2654/3304 [02:31<00:10, 64.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 2559/3304 [02:31<00:11, 66.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 2529/3304 [02:32<00:11, 66.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▊   | 2265/3304 [02:31<00:16, 61.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▌ | 2819/3304 [02:32<00:06, 75.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████  | 2661/3304 [02:32<00:09, 64.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▍  | 2437/3304 [02:32<00:13, 63.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 2726/3304 [02:32<00:09, 62.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 2536/3304 [02:32<00:11, 65.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 2566/3304 [02:32<00:11, 64.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▉   | 2273/3304 [02:32<00:16, 63.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▌ | 2827/3304 [02:32<00:06, 74.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████  | 2669/3304 [02:32<00:09, 65.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▍  | 2445/3304 [02:32<00:13, 63.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 2734/3304 [02:32<00:08, 64.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 2574/3304 [02:32<00:11, 65.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 2544/3304 [02:32<00:11, 65.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▉   | 2280/3304 [02:32<00:16, 62.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▌ | 2838/3304 [02:32<00:06, 72.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████  | 2677/3304 [02:32<00:09, 65.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▍  | 2453/3304 [02:32<00:13, 64.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 2552/3304 [02:32<00:11, 67.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 2741/3304 [02:32<00:08, 62.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 2582/3304 [02:32<00:10, 66.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▉   | 2288/3304 [02:32<00:16, 62.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▌ | 2846/3304 [02:32<00:06, 71.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████▏ | 2685/3304 [02:32<00:09, 65.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▍  | 2461/3304 [02:32<00:12, 66.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 2748/3304 [02:32<00:08, 62.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 2560/3304 [02:32<00:11, 66.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▉   | 2296/3304 [02:32<00:16, 62.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 2592/3304 [02:32<00:11, 62.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▋ | 2854/3304 [02:32<00:06, 70.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 2693/3304 [02:32<00:09, 66.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▍  | 2469/3304 [02:32<00:12, 66.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 2756/3304 [02:32<00:08, 64.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 2567/3304 [02:32<00:11, 65.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|██████▉   | 2303/3304 [02:32<00:15, 62.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 2862/3304 [02:32<00:06, 69.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▊  | 2601/3304 [02:32<00:11, 61.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 2701/3304 [02:32<00:09, 65.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▎ | 2764/3304 [02:32<00:08, 64.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 2575/3304 [02:33<00:10, 66.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▍  | 2477/3304 [02:32<00:12, 65.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|██████▉   | 2311/3304 [02:32<00:15, 63.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 2871/3304 [02:32<00:06, 71.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▉  | 2608/3304 [02:32<00:11, 60.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 2709/3304 [02:32<00:09, 65.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▌  | 2484/3304 [02:32<00:12, 65.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 2583/3304 [02:33<00:10, 67.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▍ | 2772/3304 [02:32<00:08, 65.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|███████   | 2318/3304 [02:32<00:15, 62.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 2880/3304 [02:32<00:05, 72.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 2716/3304 [02:32<00:09, 63.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▉  | 2616/3304 [02:32<00:11, 60.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▌  | 2492/3304 [02:32<00:12, 64.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▍ | 2780/3304 [02:32<00:07, 65.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 2590/3304 [02:33<00:11, 63.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|███████   | 2326/3304 [02:32<00:15, 61.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 2888/3304 [02:32<00:05, 73.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▍ | 2788/3304 [02:33<00:07, 67.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▉  | 2623/3304 [02:33<00:11, 59.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▌  | 2499/3304 [02:33<00:12, 62.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▊  | 2597/3304 [02:33<00:11, 62.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 2726/3304 [02:33<00:09, 63.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████   | 2333/3304 [02:33<00:15, 62.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 2897/3304 [02:33<00:05, 74.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▌  | 2506/3304 [02:33<00:12, 63.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|███████▉  | 2630/3304 [02:33<00:11, 60.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▍ | 2796/3304 [02:33<00:07, 65.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▉  | 2605/3304 [02:33<00:11, 61.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 2734/3304 [02:33<00:08, 65.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████   | 2341/3304 [02:33<00:15, 63.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 2905/3304 [02:33<00:05, 75.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▌  | 2513/3304 [02:33<00:12, 63.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|███████▉  | 2638/3304 [02:33<00:10, 61.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▍ | 2804/3304 [02:33<00:07, 66.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▉  | 2612/3304 [02:33<00:11, 61.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 2741/3304 [02:33<00:08, 63.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████   | 2349/3304 [02:33<00:14, 64.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 2913/3304 [02:33<00:05, 73.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▋  | 2521/3304 [02:33<00:11, 65.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▌ | 2812/3304 [02:33<00:07, 66.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|████████  | 2646/3304 [02:33<00:10, 61.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 2748/3304 [02:33<00:08, 63.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▉  | 2620/3304 [02:33<00:11, 62.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████▏  | 2356/3304 [02:33<00:14, 63.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 2921/3304 [02:33<00:05, 72.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 2529/3304 [02:33<00:11, 66.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▌ | 2819/3304 [02:33<00:07, 66.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|████████  | 2653/3304 [02:33<00:10, 61.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 2756/3304 [02:33<00:08, 65.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▊ | 2930/3304 [02:33<00:05, 74.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 2363/3304 [02:33<00:15, 61.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|███████▉  | 2630/3304 [02:33<00:10, 61.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 2537/3304 [02:33<00:11, 65.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████  | 2660/3304 [02:33<00:10, 62.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▌ | 2827/3304 [02:33<00:07, 65.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▎ | 2764/3304 [02:33<00:08, 65.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 2370/3304 [02:33<00:15, 59.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|███████▉  | 2638/3304 [02:34<00:10, 63.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▉ | 2941/3304 [02:33<00:05, 70.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 2545/3304 [02:33<00:11, 65.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▌ | 2834/3304 [02:33<00:07, 63.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████  | 2668/3304 [02:33<00:10, 62.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▍ | 2772/3304 [02:33<00:08, 65.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 2377/3304 [02:33<00:15, 60.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|████████  | 2646/3304 [02:34<00:10, 63.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▉ | 2950/3304 [02:33<00:04, 72.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 2553/3304 [02:33<00:11, 66.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████  | 2675/3304 [02:33<00:10, 62.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▌ | 2842/3304 [02:33<00:07, 63.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▍ | 2780/3304 [02:33<00:07, 66.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 2384/3304 [02:33<00:15, 60.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|████████  | 2654/3304 [02:34<00:10, 64.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|████████▉ | 2958/3304 [02:33<00:04, 73.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 2561/3304 [02:33<00:11, 66.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████  | 2682/3304 [02:33<00:10, 62.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▍ | 2788/3304 [02:33<00:07, 68.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▌ | 2849/3304 [02:33<00:07, 61.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 2392/3304 [02:34<00:14, 62.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████  | 2661/3304 [02:34<00:09, 64.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|████████▉ | 2966/3304 [02:34<00:04, 72.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 2568/3304 [02:34<00:11, 65.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████▏ | 2690/3304 [02:34<00:09, 63.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▋ | 2857/3304 [02:34<00:07, 62.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▍ | 2796/3304 [02:34<00:07, 66.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 2399/3304 [02:34<00:14, 62.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|█████████ | 2974/3304 [02:34<00:04, 74.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████  | 2669/3304 [02:34<00:09, 65.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 2576/3304 [02:34<00:11, 66.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 2698/3304 [02:34<00:09, 63.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 2864/3304 [02:34<00:07, 61.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▍ | 2804/3304 [02:34<00:07, 66.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 2406/3304 [02:34<00:14, 61.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|█████████ | 2982/3304 [02:34<00:04, 73.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████  | 2677/3304 [02:34<00:09, 65.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 2584/3304 [02:34<00:11, 64.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 2705/3304 [02:34<00:09, 62.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▌ | 2812/3304 [02:34<00:07, 67.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 2872/3304 [02:34<00:06, 62.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 2414/3304 [02:34<00:14, 63.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 2991/3304 [02:34<00:04, 74.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████▏ | 2685/3304 [02:34<00:09, 65.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 2591/3304 [02:34<00:11, 63.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▌ | 2819/3304 [02:34<00:07, 66.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 2713/3304 [02:34<00:09, 62.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 2880/3304 [02:34<00:06, 64.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 2999/3304 [02:34<00:04, 73.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 2422/3304 [02:34<00:14, 62.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 2693/3304 [02:34<00:09, 66.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▊  | 2599/3304 [02:34<00:11, 63.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▌ | 2827/3304 [02:34<00:07, 65.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 2888/3304 [02:34<00:06, 64.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 2722/3304 [02:34<00:09, 59.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 2701/3304 [02:35<00:09, 65.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▎  | 2432/3304 [02:34<00:14, 61.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▌ | 2834/3304 [02:34<00:07, 64.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 2896/3304 [02:34<00:06, 65.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▉  | 2608/3304 [02:34<00:11, 60.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 2730/3304 [02:34<00:09, 61.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 2709/3304 [02:35<00:09, 65.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▍  | 2439/3304 [02:34<00:14, 61.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▌ | 2842/3304 [02:34<00:07, 63.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 2904/3304 [02:34<00:06, 66.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▉  | 2616/3304 [02:34<00:11, 61.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 2738/3304 [02:34<00:08, 62.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 2716/3304 [02:35<00:09, 63.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▍  | 2446/3304 [02:34<00:14, 60.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▌ | 2849/3304 [02:34<00:07, 62.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 2911/3304 [02:34<00:06, 64.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▉  | 2623/3304 [02:34<00:11, 60.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▍  | 2454/3304 [02:35<00:13, 62.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 2748/3304 [02:35<00:09, 60.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 2726/3304 [02:35<00:09, 63.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▋ | 2856/3304 [02:35<00:07, 63.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 2919/3304 [02:35<00:06, 64.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|███████▉  | 2630/3304 [02:35<00:10, 61.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▍  | 2462/3304 [02:35<00:13, 63.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 2734/3304 [02:35<00:08, 65.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 2756/3304 [02:35<00:08, 61.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 2863/3304 [02:35<00:07, 61.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▊ | 2927/3304 [02:35<00:05, 64.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|███████▉  | 2638/3304 [02:35<00:10, 63.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▍  | 2470/3304 [02:35<00:13, 63.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 2741/3304 [02:35<00:08, 63.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 2871/3304 [02:35<00:06, 63.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▎ | 2764/3304 [02:35<00:08, 62.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▉ | 2934/3304 [02:35<00:05, 64.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|████████  | 2646/3304 [02:35<00:10, 63.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 2748/3304 [02:35<00:08, 62.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 2878/3304 [02:35<00:06, 64.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▍ | 2771/3304 [02:35<00:08, 62.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▉ | 2941/3304 [02:35<00:05, 61.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▌  | 2480/3304 [02:35<00:13, 61.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|████████  | 2654/3304 [02:35<00:10, 64.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 2756/3304 [02:35<00:08, 64.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 2886/3304 [02:35<00:06, 64.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▍ | 2779/3304 [02:35<00:08, 62.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▉ | 2949/3304 [02:35<00:05, 63.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████  | 2661/3304 [02:35<00:10, 63.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▌  | 2488/3304 [02:35<00:13, 62.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 2894/3304 [02:35<00:06, 66.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▎ | 2764/3304 [02:36<00:08, 65.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▍ | 2787/3304 [02:35<00:08, 64.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▉ | 2957/3304 [02:35<00:05, 63.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████  | 2669/3304 [02:35<00:09, 64.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▌  | 2495/3304 [02:35<00:13, 61.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 2902/3304 [02:35<00:06, 66.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▍ | 2772/3304 [02:36<00:08, 65.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▍ | 2795/3304 [02:35<00:08, 63.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|████████▉ | 2965/3304 [02:35<00:05, 65.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████  | 2677/3304 [02:35<00:09, 65.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▌  | 2505/3304 [02:35<00:13, 60.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▍ | 2780/3304 [02:36<00:07, 66.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 2910/3304 [02:35<00:06, 65.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|████████▉ | 2972/3304 [02:35<00:05, 64.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▍ | 2803/3304 [02:35<00:07, 63.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████▏ | 2685/3304 [02:35<00:09, 64.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▌  | 2513/3304 [02:35<00:12, 60.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▍ | 2788/3304 [02:36<00:07, 67.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 2918/3304 [02:35<00:05, 64.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▌ | 2811/3304 [02:36<00:07, 64.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|█████████ | 2980/3304 [02:36<00:05, 63.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 2693/3304 [02:36<00:09, 66.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▋  | 2521/3304 [02:36<00:12, 62.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▍ | 2796/3304 [02:36<00:07, 65.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▊ | 2925/3304 [02:36<00:05, 64.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|█████████ | 2988/3304 [02:36<00:04, 64.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▌ | 2819/3304 [02:36<00:07, 63.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 2701/3304 [02:36<00:09, 64.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 2529/3304 [02:36<00:12, 62.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▍ | 2804/3304 [02:36<00:07, 66.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▉ | 2933/3304 [02:36<00:05, 65.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 2996/3304 [02:36<00:04, 64.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▌ | 2827/3304 [02:36<00:07, 63.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 2709/3304 [02:36<00:09, 65.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 2536/3304 [02:36<00:12, 62.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▌ | 2812/3304 [02:36<00:07, 67.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▉ | 2940/3304 [02:36<00:05, 62.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▌ | 2834/3304 [02:36<00:07, 61.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 2716/3304 [02:36<00:09, 63.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 2543/3304 [02:36<00:12, 62.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▌ | 2819/3304 [02:36<00:07, 66.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▉ | 2947/3304 [02:36<00:05, 63.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▌ | 2841/3304 [02:36<00:07, 61.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 2726/3304 [02:36<00:09, 63.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 2551/3304 [02:36<00:11, 64.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▌ | 2827/3304 [02:36<00:07, 65.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▉ | 2955/3304 [02:36<00:05, 64.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▌ | 2848/3304 [02:36<00:07, 60.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 2734/3304 [02:36<00:08, 65.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 2559/3304 [02:36<00:11, 64.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▌ | 2834/3304 [02:37<00:07, 64.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|████████▉ | 2963/3304 [02:36<00:05, 65.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▋ | 2855/3304 [02:36<00:07, 60.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 2741/3304 [02:36<00:08, 63.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|████████▉ | 2970/3304 [02:36<00:05, 64.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 2566/3304 [02:36<00:11, 62.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▌ | 2842/3304 [02:37<00:07, 63.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 2862/3304 [02:36<00:07, 59.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 2748/3304 [02:36<00:08, 63.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|█████████ | 2978/3304 [02:36<00:04, 65.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 2574/3304 [02:36<00:11, 63.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▌ | 2849/3304 [02:37<00:07, 62.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 2870/3304 [02:36<00:07, 61.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 2756/3304 [02:37<00:08, 65.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|█████████ | 2985/3304 [02:37<00:04, 64.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 2582/3304 [02:37<00:11, 64.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▋ | 2857/3304 [02:37<00:07, 63.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 2877/3304 [02:37<00:06, 61.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▎ | 2764/3304 [02:37<00:08, 65.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 2993/3304 [02:37<00:04, 64.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 2864/3304 [02:37<00:07, 62.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 2591/3304 [02:37<00:11, 60.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 2885/3304 [02:37<00:06, 62.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▍ | 2772/3304 [02:37<00:08, 65.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 2872/3304 [02:37<00:06, 63.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▊  | 2598/3304 [02:37<00:11, 60.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 2893/3304 [02:37<00:06, 64.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▍ | 2780/3304 [02:37<00:07, 66.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 2880/3304 [02:37<00:06, 65.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 2901/3304 [02:37<00:06, 63.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▍ | 2788/3304 [02:37<00:07, 68.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▉  | 2607/3304 [02:37<00:11, 59.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 2888/3304 [02:37<00:06, 66.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 2909/3304 [02:37<00:06, 64.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▉  | 2614/3304 [02:37<00:11, 59.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▍ | 2796/3304 [02:37<00:07, 66.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 2896/3304 [02:38<00:06, 66.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 2916/3304 [02:37<00:06, 63.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▍ | 2804/3304 [02:37<00:07, 67.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 2904/3304 [02:38<00:05, 67.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▉  | 2623/3304 [02:37<00:11, 59.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 2924/3304 [02:37<00:06, 62.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▌ | 2812/3304 [02:37<00:07, 68.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 2911/3304 [02:38<00:05, 65.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|███████▉  | 2630/3304 [02:37<00:11, 59.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▊ | 2932/3304 [02:37<00:05, 64.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▌ | 2820/3304 [02:37<00:07, 66.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 2919/3304 [02:38<00:05, 65.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|███████▉  | 2638/3304 [02:37<00:10, 61.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▌ | 2828/3304 [02:38<00:07, 67.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▊ | 2927/3304 [02:38<00:05, 66.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|████████  | 2646/3304 [02:38<00:10, 62.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▉ | 2941/3304 [02:38<00:06, 60.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▌ | 2835/3304 [02:38<00:07, 64.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▉ | 2949/3304 [02:38<00:05, 62.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▉ | 2935/3304 [02:38<00:05, 65.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|████████  | 2654/3304 [02:38<00:10, 62.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▌ | 2843/3304 [02:38<00:07, 65.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▉ | 2942/3304 [02:38<00:05, 63.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████  | 2661/3304 [02:38<00:10, 62.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▉ | 2957/3304 [02:38<00:05, 62.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▉ | 2950/3304 [02:38<00:05, 66.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▋ | 2853/3304 [02:38<00:06, 64.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████  | 2669/3304 [02:38<00:10, 63.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|████████▉ | 2965/3304 [02:38<00:05, 64.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|████████▉ | 2958/3304 [02:38<00:05, 66.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|████████▉ | 2972/3304 [02:38<00:05, 63.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 2860/3304 [02:38<00:07, 62.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████  | 2677/3304 [02:38<00:09, 63.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|████████▉ | 2966/3304 [02:39<00:05, 66.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 2868/3304 [02:38<00:06, 64.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|█████████ | 2980/3304 [02:38<00:05, 62.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████▏ | 2685/3304 [02:38<00:09, 63.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|█████████ | 2974/3304 [02:39<00:04, 67.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 2876/3304 [02:38<00:06, 64.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 2693/3304 [02:38<00:09, 64.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|█████████ | 2988/3304 [02:38<00:04, 63.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|█████████ | 2982/3304 [02:39<00:04, 66.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 2884/3304 [02:38<00:06, 66.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 2996/3304 [02:38<00:04, 63.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 2701/3304 [02:38<00:09, 63.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|█████████ | 2990/3304 [02:39<00:04, 67.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 2892/3304 [02:39<00:06, 67.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 2709/3304 [02:39<00:09, 63.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 2998/3304 [02:39<00:04, 66.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 2900/3304 [02:39<00:06, 67.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 2716/3304 [02:39<00:09, 62.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 2908/3304 [02:39<00:05, 67.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 2726/3304 [02:39<00:09, 62.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 2915/3304 [02:39<00:05, 66.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 2999/3304 [02:39<00:04, 66.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 2734/3304 [02:39<00:08, 64.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 2923/3304 [02:39<00:05, 66.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 2741/3304 [02:39<00:08, 63.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▊ | 2931/3304 [02:39<00:05, 68.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 2748/3304 [02:39<00:08, 62.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▉ | 2938/3304 [02:39<00:05, 65.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 2756/3304 [02:39<00:08, 64.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▉ | 2946/3304 [02:39<00:05, 66.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▎ | 2764/3304 [02:39<00:08, 65.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▉ | 2954/3304 [02:39<00:05, 68.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▍ | 2772/3304 [02:40<00:08, 65.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|████████▉ | 2962/3304 [02:40<00:04, 68.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▍ | 2780/3304 [02:40<00:07, 66.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|████████▉ | 2970/3304 [02:40<00:04, 68.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▍ | 2788/3304 [02:40<00:07, 67.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|█████████ | 2978/3304 [02:40<00:04, 69.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▍ | 2796/3304 [02:40<00:07, 66.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|█████████ | 2986/3304 [02:40<00:04, 69.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▍ | 2804/3304 [02:40<00:07, 67.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 2994/3304 [02:40<00:04, 69.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▌ | 2812/3304 [02:40<00:07, 68.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▌ | 2820/3304 [02:40<00:07, 67.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▌ | 2828/3304 [02:40<00:06, 68.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▌ | 2835/3304 [02:41<00:07, 66.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▌ | 2843/3304 [02:41<00:06, 68.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▋ | 2850/3304 [02:41<00:06, 65.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 2858/3304 [02:41<00:06, 67.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 2865/3304 [02:41<00:06, 66.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 2873/3304 [02:41<00:06, 67.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 2881/3304 [02:41<00:06, 69.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 2889/3304 [02:41<00:05, 71.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 2897/3304 [02:41<00:05, 71.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 2905/3304 [02:42<00:05, 71.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 2916/3304 [02:42<00:05, 69.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 2924/3304 [02:42<00:05, 69.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▊ | 2932/3304 [02:42<00:05, 70.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▉ | 2942/3304 [02:42<00:05, 66.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▉ | 2950/3304 [02:42<00:05, 68.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|████████▉ | 2958/3304 [02:42<00:04, 69.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|████████▉ | 2966/3304 [02:42<00:04, 69.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|█████████ | 2974/3304 [02:43<00:04, 70.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|█████████ | 2982/3304 [02:43<00:04, 69.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|█████████ | 2990/3304 [02:43<00:04, 70.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 2998/3304 [02:43<00:04, 69.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 2999/3304 [02:49<00:04, 64.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 2997/3304 [02:49<00:04, 64.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 2999/3304 [02:49<00:04, 63.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 2999/3304 [02:49<00:04, 73.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 2998/3304 [02:59<00:04, 66.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 2998/3304 [02:59<00:04, 69.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 2998/3304 [02:59<00:04, 69.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 3000/3304 [03:13<12:49,  2.53s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 3007/3304 [03:13<08:12,  1.66s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████▏| 3015/3304 [03:13<05:06,  1.06s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████▏| 3023/3304 [03:13<03:17,  1.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 3031/3304 [03:13<02:10,  2.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 3039/3304 [03:13<01:27,  3.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 3048/3304 [03:13<00:56,  4.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 3056/3304 [03:14<00:39,  6.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  93%|█████████▎| 3064/3304 [03:14<00:27,  8.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  93%|█████████▎| 3072/3304 [03:14<00:19, 11.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  93%|█████████▎| 3080/3304 [03:14<00:14, 15.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▎| 3090/3304 [03:14<00:09, 21.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▍| 3098/3304 [03:14<00:07, 27.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▍| 3108/3304 [03:14<00:05, 35.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▍| 3116/3304 [03:14<00:04, 41.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▍| 3125/3304 [03:14<00:03, 48.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▍| 3133/3304 [03:15<00:03, 53.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▌| 3141/3304 [03:15<00:02, 57.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▌| 3149/3304 [03:15<00:02, 62.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▌| 3157/3304 [03:15<00:02, 64.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▌| 3165/3304 [03:15<00:02, 66.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▌| 3174/3304 [03:15<00:01, 68.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▋| 3182/3304 [03:15<00:01, 69.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 3190/3304 [03:15<00:01, 68.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 3198/3304 [03:15<00:01, 67.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 3206/3304 [03:16<00:01, 67.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 3214/3304 [03:16<00:01, 69.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 3222/3304 [03:16<00:01, 69.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 3230/3304 [03:16<00:01, 70.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 3241/3304 [03:16<00:00, 68.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 3249/3304 [03:16<00:00, 67.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▊| 3257/3304 [03:16<00:00, 66.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▉| 3264/3304 [03:16<00:00, 65.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▉| 3272/3304 [03:17<00:00, 67.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▉| 3280/3304 [03:17<00:00, 68.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|█████████▉| 3288/3304 [03:17<00:00, 70.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|█████████▉| 3296/3304 [03:17<00:00, 68.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 3304/3304 [03:17<00:00, 68.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 3000/3304 [03:26<12:49,  2.53s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 3007/3304 [03:26<08:26,  1.71s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████▏| 3015/3304 [03:26<05:22,  1.12s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████▏| 3023/3304 [03:26<03:30,  1.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 3031/3304 [03:26<02:19,  1.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 3039/3304 [03:26<01:34,  2.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 3048/3304 [03:26<01:01,  4.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 3056/3304 [03:26<00:42,  5.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  93%|█████████▎| 3064/3304 [03:26<00:29,  8.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  93%|█████████▎| 3073/3304 [03:27<00:20, 11.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  93%|█████████▎| 3081/3304 [03:27<00:14, 15.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  93%|█████████▎| 3089/3304 [03:27<00:10, 19.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▎| 3097/3304 [03:27<00:08, 25.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▍| 3106/3304 [03:27<00:06, 32.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▍| 3115/3304 [03:27<00:04, 39.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 3000/3304 [03:27<11:44,  2.32s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▍| 3124/3304 [03:27<00:03, 46.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 3007/3304 [03:27<07:56,  1.60s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▍| 3132/3304 [03:27<00:03, 52.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████▏| 3015/3304 [03:27<05:09,  1.07s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▌| 3140/3304 [03:27<00:02, 56.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████▏| 3023/3304 [03:28<03:24,  1.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▌| 3149/3304 [03:28<00:02, 62.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 3031/3304 [03:28<02:17,  1.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▌| 3157/3304 [03:28<00:02, 64.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 3038/3304 [03:28<01:36,  2.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▌| 3165/3304 [03:28<00:02, 65.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 3046/3304 [03:28<01:05,  3.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▌| 3174/3304 [03:28<00:01, 68.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 3054/3304 [03:28<00:44,  5.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▋| 3182/3304 [03:28<00:01, 70.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  93%|█████████▎| 3062/3304 [03:28<00:31,  7.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 3190/3304 [03:28<00:01, 70.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  93%|█████████▎| 3070/3304 [03:28<00:21, 10.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 3198/3304 [03:28<00:01, 70.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  93%|█████████▎| 3078/3304 [03:28<00:15, 14.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 3206/3304 [03:28<00:01, 70.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 3000/3304 [03:28<10:38,  2.10s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  93%|█████████▎| 3086/3304 [03:28<00:11, 19.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 3214/3304 [03:28<00:01, 71.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 3007/3304 [03:28<07:25,  1.50s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▎| 3097/3304 [03:29<00:07, 26.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 3223/3304 [03:29<00:01, 72.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████▏| 3015/3304 [03:29<04:56,  1.03s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▍| 3105/3304 [03:29<00:06, 31.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 3231/3304 [03:29<00:00, 74.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████▏| 3023/3304 [03:29<03:19,  1.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▍| 3113/3304 [03:29<00:05, 38.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 3239/3304 [03:29<00:00, 73.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 3031/3304 [03:29<02:14,  2.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▍| 3121/3304 [03:29<00:04, 43.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 3247/3304 [03:29<00:00, 71.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 3038/3304 [03:29<01:35,  2.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 3304/3304 [03:29<00:00, 68.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▍| 3129/3304 [03:29<00:03, 49.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▊| 3255/3304 [03:29<00:00, 70.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 3046/3304 [03:29<01:05,  3.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▍| 3137/3304 [03:29<00:03, 53.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▉| 3263/3304 [03:29<00:00, 68.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 3054/3304 [03:29<00:44,  5.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▌| 3145/3304 [03:29<00:02, 57.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▉| 3271/3304 [03:29<00:00, 70.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  93%|█████████▎| 3062/3304 [03:29<00:31,  7.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▉| 3279/3304 [03:29<00:00, 71.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▌| 3153/3304 [03:29<00:02, 60.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  93%|█████████▎| 3070/3304 [03:29<00:21, 10.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▉| 3287/3304 [03:29<00:00, 73.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▌| 3161/3304 [03:29<00:02, 61.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  93%|█████████▎| 3078/3304 [03:30<00:15, 14.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|█████████▉| 3295/3304 [03:30<00:00, 71.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▌| 3169/3304 [03:30<00:02, 62.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  93%|█████████▎| 3086/3304 [03:30<00:11, 18.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|█████████▉| 3303/3304 [03:30<00:00, 71.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▌| 3177/3304 [03:30<00:01, 65.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▎| 3097/3304 [03:30<00:08, 25.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▋| 3185/3304 [03:30<00:01, 66.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▍| 3105/3304 [03:30<00:06, 31.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 3192/3304 [03:30<00:01, 64.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▍| 3113/3304 [03:30<00:05, 37.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 3200/3304 [03:30<00:01, 64.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▍| 3121/3304 [03:30<00:04, 43.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 3208/3304 [03:30<00:01, 64.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▍| 3129/3304 [03:30<00:03, 49.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 3216/3304 [03:30<00:01, 66.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▍| 3137/3304 [03:30<00:03, 52.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 3224/3304 [03:30<00:01, 66.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▌| 3145/3304 [03:30<00:02, 56.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 3232/3304 [03:31<00:01, 67.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▌| 3153/3304 [03:31<00:02, 59.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 3239/3304 [03:31<00:00, 66.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▌| 3161/3304 [03:31<00:02, 60.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 3246/3304 [03:31<00:00, 65.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 3000/3304 [03:31<11:52,  2.34s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▌| 3169/3304 [03:31<00:02, 62.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 3254/3304 [03:31<00:00, 63.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 3007/3304 [03:31<08:03,  1.63s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▌| 3177/3304 [03:31<00:01, 64.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▊| 3261/3304 [03:31<00:00, 63.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████▏| 3015/3304 [03:31<05:14,  1.09s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▋| 3185/3304 [03:31<00:01, 65.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▉| 3269/3304 [03:31<00:00, 65.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████▏| 3023/3304 [03:31<03:28,  1.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 3000/3304 [03:32<12:59,  2.56s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 3192/3304 [03:31<00:01, 63.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▉| 3277/3304 [03:31<00:00, 66.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 3031/3304 [03:31<02:19,  1.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 3007/3304 [03:32<08:34,  1.73s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 3200/3304 [03:31<00:01, 63.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▉| 3285/3304 [03:31<00:00, 68.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 3038/3304 [03:31<01:38,  2.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████▏| 3015/3304 [03:32<05:27,  1.13s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 3208/3304 [03:31<00:01, 64.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|█████████▉| 3293/3304 [03:31<00:00, 67.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 3046/3304 [03:32<01:06,  3.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████▏| 3023/3304 [03:32<03:34,  1.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 3216/3304 [03:32<00:01, 65.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|█████████▉| 3301/3304 [03:32<00:00, 66.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 3304/3304 [03:32<00:00, 15.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 3054/3304 [03:32<00:45,  5.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 3223/3304 [03:32<00:01, 65.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 3031/3304 [03:32<02:22,  1.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  93%|█████████▎| 3062/3304 [03:32<00:31,  7.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 3231/3304 [03:32<00:01, 66.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 3038/3304 [03:32<01:40,  2.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  93%|█████████▎| 3070/3304 [03:32<00:22, 10.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 3046/3304 [03:32<01:07,  3.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 3239/3304 [03:32<00:00, 66.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  93%|█████████▎| 3078/3304 [03:32<00:16, 14.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 3054/3304 [03:32<00:45,  5.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 3246/3304 [03:32<00:00, 64.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  93%|█████████▎| 3086/3304 [03:32<00:11, 18.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  93%|█████████▎| 3062/3304 [03:33<00:31,  7.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 3254/3304 [03:32<00:00, 63.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▎| 3093/3304 [03:32<00:09, 22.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  93%|█████████▎| 3070/3304 [03:33<00:22, 10.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▊| 3261/3304 [03:32<00:00, 63.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▍| 3101/3304 [03:32<00:06, 29.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  93%|█████████▎| 3078/3304 [03:33<00:16, 14.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▉| 3269/3304 [03:32<00:00, 66.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 0/835 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▍| 3109/3304 [03:32<00:05, 35.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  93%|█████████▎| 3086/3304 [03:33<00:11, 18.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▉| 3277/3304 [03:32<00:00, 67.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|          | 8/835 [00:00<00:11, 72.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▍| 3117/3304 [03:33<00:04, 41.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▎| 3093/3304 [03:33<00:09, 23.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▉| 3285/3304 [03:33<00:00, 69.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 16/835 [00:00<00:11, 73.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▍| 3125/3304 [03:33<00:03, 47.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▍| 3101/3304 [03:33<00:06, 29.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|█████████▉| 3293/3304 [03:33<00:00, 69.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 24/835 [00:00<00:11, 72.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▍| 3133/3304 [03:33<00:03, 52.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▍| 3109/3304 [03:33<00:05, 36.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|█████████▉| 3301/3304 [03:33<00:00, 67.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▍         | 33/835 [00:00<00:10, 73.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▍| 3117/3304 [03:33<00:04, 42.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▌| 3141/3304 [03:33<00:02, 55.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▍         | 41/835 [00:00<00:10, 73.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▍| 3125/3304 [03:33<00:03, 48.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▌| 3149/3304 [03:33<00:02, 59.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▌         | 49/835 [00:00<00:10, 73.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▍| 3133/3304 [03:34<00:03, 53.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▌| 3157/3304 [03:33<00:02, 61.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 57/835 [00:00<00:11, 69.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▌| 3141/3304 [03:34<00:02, 56.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▌| 3165/3304 [03:33<00:02, 62.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 65/835 [00:00<00:11, 69.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▌| 3149/3304 [03:34<00:02, 60.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▌| 3173/3304 [03:33<00:02, 64.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▊         | 73/835 [00:01<00:10, 69.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▌| 3157/3304 [03:34<00:02, 62.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▋| 3181/3304 [03:34<00:01, 66.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|▉         | 82/835 [00:01<00:10, 72.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▌| 3165/3304 [03:34<00:02, 63.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 3189/3304 [03:34<00:01, 65.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█         | 90/835 [00:01<00:10, 74.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▌| 3173/3304 [03:34<00:02, 65.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 3196/3304 [03:34<00:01, 65.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 3000/3304 [03:34<11:07,  2.20s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 101/835 [00:01<00:10, 72.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▋| 3181/3304 [03:34<00:01, 66.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 3204/3304 [03:34<00:01, 64.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 3007/3304 [03:34<07:44,  1.57s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 109/835 [00:01<00:09, 73.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 3189/3304 [03:34<00:01, 66.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 3212/3304 [03:34<00:01, 65.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████▏| 3015/3304 [03:34<05:08,  1.07s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▍        | 117/835 [00:01<00:09, 71.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 3196/3304 [03:34<00:01, 65.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 3220/3304 [03:34<00:01, 67.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████▏| 3023/3304 [03:34<03:27,  1.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▍        | 125/835 [00:01<00:09, 72.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 3204/3304 [03:35<00:01, 64.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 3227/3304 [03:34<00:01, 66.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 3031/3304 [03:34<02:20,  1.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▌        | 134/835 [00:01<00:09, 73.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 3212/3304 [03:35<00:01, 66.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 3235/3304 [03:34<00:01, 66.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 3038/3304 [03:34<01:39,  2.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 145/835 [00:02<00:09, 72.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 3220/3304 [03:35<00:01, 67.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 3242/3304 [03:34<00:00, 65.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 3046/3304 [03:34<01:07,  3.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 3228/3304 [03:35<00:01, 67.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 3250/3304 [03:35<00:00, 63.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▊        | 155/835 [00:02<00:09, 68.89 examples/s]#015Map:  92%|█████████▏| 3054/3304 [03:35<00:46,  5.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 3236/3304 [03:35<00:01, 67.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▊| 3258/3304 [03:35<00:00, 64.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|█▉        | 163/835 [00:02<00:09, 69.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  93%|█████████▎| 3062/3304 [03:35<00:32,  7.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 3244/3304 [03:35<00:00, 65.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▉| 3265/3304 [03:35<00:00, 63.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██        | 172/835 [00:02<00:09, 72.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  93%|█████████▎| 3070/3304 [03:35<00:22, 10.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 3251/3304 [03:35<00:00, 64.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▉| 3273/3304 [03:35<00:00, 65.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 181/835 [00:02<00:08, 74.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  93%|█████████▎| 3078/3304 [03:35<00:16, 13.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▊| 3258/3304 [03:35<00:00, 64.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▉| 3281/3304 [03:35<00:00, 67.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 190/835 [00:02<00:08, 75.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  93%|█████████▎| 3086/3304 [03:35<00:11, 18.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▉| 3265/3304 [03:36<00:00, 63.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|█████████▉| 3289/3304 [03:35<00:00, 68.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▍       | 199/835 [00:02<00:08, 76.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▎| 3093/3304 [03:35<00:09, 22.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▉| 3273/3304 [03:36<00:00, 66.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|█████████▉| 3297/3304 [03:35<00:00, 67.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▍| 3101/3304 [03:35<00:06, 29.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▌       | 209/835 [00:02<00:08, 76.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▉| 3281/3304 [03:36<00:00, 68.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▍| 3109/3304 [03:35<00:05, 35.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▌       | 218/835 [00:02<00:07, 77.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|█████████▉| 3289/3304 [03:36<00:00, 70.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▍| 3117/3304 [03:35<00:04, 41.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 226/835 [00:03<00:07, 76.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|█████████▉| 3297/3304 [03:36<00:00, 68.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▍| 3125/3304 [03:36<00:03, 48.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 235/835 [00:03<00:08, 75.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▍| 3133/3304 [03:36<00:03, 53.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▉       | 243/835 [00:03<00:08, 71.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▌| 3141/3304 [03:36<00:02, 57.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|███       | 252/835 [00:03<00:07, 73.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▌| 3150/3304 [03:36<00:02, 61.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 260/835 [00:03<00:07, 74.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▌| 3158/3304 [03:36<00:02, 63.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 268/835 [00:03<00:07, 73.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▌| 3166/3304 [03:36<00:02, 66.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 276/835 [00:03<00:07, 73.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▌| 3174/3304 [03:36<00:01, 68.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▍      | 284/835 [00:03<00:07, 73.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▋| 3182/3304 [03:36<00:01, 69.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▍      | 292/835 [00:04<00:07, 71.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 3190/3304 [03:36<00:01, 69.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▋      | 303/835 [00:04<00:07, 69.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 3000/3304 [03:37<13:07,  2.59s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 3198/3304 [03:37<00:01, 68.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 311/835 [00:04<00:07, 69.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 3007/3304 [03:37<08:41,  1.76s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 3206/3304 [03:37<00:01, 68.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 319/835 [00:04<00:07, 69.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████▏| 3015/3304 [03:37<05:33,  1.15s/ examples]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 3214/3304 [03:37<00:01, 68.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▉      | 327/835 [00:04<00:07, 71.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████▏| 3023/3304 [03:37<03:38,  1.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 3222/3304 [03:37<00:01, 69.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|████      | 335/835 [00:04<00:06, 72.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 3031/3304 [03:37<02:25,  1.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 3230/3304 [03:37<00:01, 69.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████      | 343/835 [00:04<00:06, 73.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 3038/3304 [03:37<01:42,  2.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 3241/3304 [03:37<00:00, 67.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 354/835 [00:04<00:06, 71.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 3046/3304 [03:37<01:08,  3.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 3249/3304 [03:37<00:00, 67.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 363/835 [00:04<00:06, 73.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 3054/3304 [03:37<00:46,  5.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▊| 3257/3304 [03:37<00:00, 66.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  93%|█████████▎| 3062/3304 [03:38<00:32,  7.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▍     | 375/835 [00:05<00:06, 72.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▉| 3264/3304 [03:38<00:00, 66.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  93%|█████████▎| 3070/3304 [03:38<00:22, 10.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▌     | 384/835 [00:05<00:06, 74.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▉| 3272/3304 [03:38<00:00, 68.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  93%|█████████▎| 3078/3304 [03:38<00:16, 13.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 392/835 [00:05<00:05, 75.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▉| 3280/3304 [03:38<00:00, 69.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  93%|█████████▎| 3086/3304 [03:38<00:11, 18.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 401/835 [00:05<00:05, 76.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|█████████▉| 3288/3304 [03:38<00:00, 71.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▎| 3093/3304 [03:38<00:09, 22.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▉     | 409/835 [00:05<00:05, 75.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|█████████▉| 3296/3304 [03:38<00:00, 69.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▍| 3101/3304 [03:38<00:07, 28.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|████▉     | 417/835 [00:05<00:05, 74.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 3304/3304 [03:38<00:00, 69.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▍| 3109/3304 [03:38<00:05, 35.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████     | 425/835 [00:05<00:05, 74.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▍| 3117/3304 [03:38<00:04, 41.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 433/835 [00:05<00:05, 74.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▍| 3125/3304 [03:38<00:03, 48.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 441/835 [00:06<00:05, 73.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▍| 3133/3304 [03:39<00:03, 52.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▍    | 450/835 [00:06<00:05, 74.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▌| 3141/3304 [03:39<00:02, 56.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▍    | 459/835 [00:06<00:05, 74.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▌| 3149/3304 [03:39<00:02, 60.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▌    | 467/835 [00:06<00:05, 72.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▌| 3157/3304 [03:39<00:02, 62.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 475/835 [00:06<00:05, 69.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▌| 3165/3304 [03:39<00:02, 63.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 483/835 [00:06<00:05, 69.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▌| 3173/3304 [03:39<00:02, 65.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▉    | 491/835 [00:06<00:04, 69.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▋| 3181/3304 [03:39<00:01, 66.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|█████▉    | 499/835 [00:06<00:04, 69.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 3189/3304 [03:39<00:01, 66.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 508/835 [00:06<00:04, 70.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 3196/3304 [03:39<00:01, 66.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 517/835 [00:07<00:04, 70.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 3204/3304 [03:40<00:01, 65.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 525/835 [00:07<00:04, 71.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 3212/3304 [03:40<00:01, 67.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▍   | 533/835 [00:07<00:04, 70.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 3220/3304 [03:40<00:01, 68.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▍   | 541/835 [00:07<00:04, 71.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 3228/3304 [03:40<00:01, 68.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▌   | 550/835 [00:07<00:03, 72.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 3235/3304 [03:40<00:01, 68.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 558/835 [00:07<00:03, 70.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 3243/3304 [03:40<00:00, 67.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 567/835 [00:07<00:03, 71.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 3250/3304 [03:40<00:00, 65.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▉   | 575/835 [00:07<00:03, 73.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▊| 3258/3304 [03:40<00:00, 66.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|██████▉   | 584/835 [00:08<00:03, 73.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▉| 3265/3304 [03:41<00:00, 65.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████   | 592/835 [00:08<00:03, 74.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▉| 3273/3304 [03:41<00:00, 68.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 601/835 [00:08<00:03, 75.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▉| 3281/3304 [03:41<00:00, 70.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 609/835 [00:08<00:03, 74.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|█████████▉| 3289/3304 [03:41<00:00, 72.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▍  | 618/835 [00:08<00:02, 73.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|█████████▉| 3297/3304 [03:41<00:00, 70.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▌  | 628/835 [00:08<00:02, 76.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▋  | 637/835 [00:08<00:02, 77.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 646/835 [00:08<00:02, 77.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 654/835 [00:08<00:02, 75.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▉  | 662/835 [00:09<00:02, 75.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|████████  | 670/835 [00:09<00:02, 74.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████▏ | 679/835 [00:09<00:02, 75.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 687/835 [00:09<00:01, 76.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 696/835 [00:09<00:01, 76.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▍ | 706/835 [00:09<00:01, 76.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▌ | 714/835 [00:09<00:01, 75.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 723/835 [00:09<00:01, 76.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 732/835 [00:09<00:01, 77.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▊ | 741/835 [00:10<00:01, 77.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|█████████ | 752/835 [00:10<00:01, 74.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 760/835 [00:10<00:01, 74.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 769/835 [00:10<00:00, 74.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  93%|█████████▎| 777/835 [00:10<00:00, 71.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▍| 785/835 [00:10<00:00, 71.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▍| 793/835 [00:10<00:00, 71.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▌| 801/835 [00:10<00:00, 70.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 812/835 [00:11<00:00, 67.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 820/835 [00:11<00:00, 68.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▉| 827/835 [00:11<00:00, 65.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 835/835 [00:11<00:00, 66.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 3304/3304 [03:46<00:00, 14.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 0/835 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|          | 8/835 [00:00<00:11, 73.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 16/835 [00:00<00:10, 74.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 25/835 [00:00<00:11, 72.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▍         | 35/835 [00:00<00:10, 76.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▌         | 43/835 [00:00<00:10, 76.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▌         | 51/835 [00:00<00:10, 74.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 59/835 [00:00<00:10, 74.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 67/835 [00:00<00:10, 73.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 3304/3304 [03:48<00:00, 14.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▉         | 76/835 [00:01<00:10, 73.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|█         | 84/835 [00:01<00:10, 74.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█         | 93/835 [00:01<00:09, 74.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 103/835 [00:01<00:09, 75.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 111/835 [00:01<00:09, 75.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▍        | 119/835 [00:01<00:09, 75.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▌        | 127/835 [00:01<00:09, 76.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 0/835 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▋        | 136/835 [00:01<00:09, 75.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|          | 8/835 [00:00<00:12, 67.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|█████████▉| 3301/3304 [03:49<00:00, 68.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 144/835 [00:01<00:09, 75.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 16/835 [00:00<00:12, 67.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 152/835 [00:02<00:09, 73.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|█████████▉| 3301/3304 [03:49<00:00, 67.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 23/835 [00:00<00:12, 66.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▉        | 160/835 [00:02<00:09, 72.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▎         | 31/835 [00:00<00:12, 66.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 3304/3304 [03:49<00:00,  1.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 3304/3304 [03:49<00:00, 14.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|██        | 169/835 [00:02<00:08, 74.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▍         | 39/835 [00:00<00:11, 68.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██▏       | 179/835 [00:02<00:08, 78.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|█████████▉| 3301/3304 [03:49<00:00, 67.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▌         | 47/835 [00:00<00:11, 67.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 188/835 [00:02<00:08, 79.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 55/835 [00:00<00:11, 66.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 3304/3304 [03:49<00:00, 69.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▎       | 198/835 [00:02<00:07, 79.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 62/835 [00:00<00:11, 64.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▍       | 207/835 [00:02<00:07, 79.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 70/835 [00:01<00:11, 65.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▌       | 216/835 [00:02<00:07, 80.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▉         | 78/835 [00:01<00:11, 66.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 225/835 [00:02<00:07, 80.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|█         | 86/835 [00:01<00:11, 67.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 234/835 [00:03<00:07, 77.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 0/835 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█         | 93/835 [00:01<00:11, 66.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▉       | 242/835 [00:03<00:07, 75.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|          | 8/835 [00:00<00:12, 67.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 101/835 [00:01<00:11, 66.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|██▉       | 250/835 [00:03<00:07, 74.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 16/835 [00:00<00:12, 66.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 109/835 [00:01<00:10, 66.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 259/835 [00:03<00:07, 75.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 23/835 [00:00<00:12, 64.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 268/835 [00:03<00:07, 76.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▍        | 119/835 [00:01<00:11, 64.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▎         | 31/835 [00:00<00:12, 65.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 277/835 [00:03<00:07, 75.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▌        | 127/835 [00:01<00:10, 64.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▍         | 39/835 [00:00<00:11, 66.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▍      | 286/835 [00:03<00:07, 76.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▌        | 135/835 [00:02<00:10, 65.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▌         | 46/835 [00:00<00:12, 65.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▌      | 294/835 [00:03<00:07, 74.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 142/835 [00:02<00:10, 63.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▋         | 54/835 [00:00<00:11, 65.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▌      | 302/835 [00:03<00:07, 72.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 150/835 [00:02<00:10, 64.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 61/835 [00:00<00:11, 65.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 311/835 [00:04<00:07, 73.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 68/835 [00:01<00:11, 65.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▉        | 157/835 [00:02<00:10, 62.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 320/835 [00:04<00:06, 74.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▉         | 75/835 [00:01<00:11, 65.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|█▉        | 165/835 [00:02<00:10, 62.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▉      | 328/835 [00:04<00:06, 74.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|▉         | 83/835 [00:01<00:11, 66.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██        | 173/835 [00:02<00:10, 65.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|████      | 338/835 [00:04<00:06, 75.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█         | 91/835 [00:01<00:11, 67.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 181/835 [00:02<00:09, 66.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 347/835 [00:04<00:06, 74.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 98/835 [00:01<00:11, 64.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 189/835 [00:02<00:09, 67.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 356/835 [00:04<00:06, 76.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 106/835 [00:01<00:11, 65.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▎       | 197/835 [00:02<00:09, 68.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▎     | 364/835 [00:04<00:06, 76.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▎        | 114/835 [00:01<00:10, 65.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▍       | 204/835 [00:03<00:09, 66.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▍     | 372/835 [00:04<00:06, 74.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▌       | 212/835 [00:03<00:09, 68.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▍        | 122/835 [00:01<00:11, 64.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 3304/3304 [03:52<00:00,  1.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 3304/3304 [03:52<00:00, 14.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▌     | 382/835 [00:05<00:05, 76.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▋       | 220/835 [00:03<00:08, 68.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▌        | 130/835 [00:01<00:10, 65.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 391/835 [00:05<00:05, 76.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 228/835 [00:03<00:08, 68.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▋        | 137/835 [00:02<00:10, 65.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 401/835 [00:05<00:05, 77.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 235/835 [00:03<00:09, 66.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 145/835 [00:02<00:10, 65.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▉     | 409/835 [00:05<00:05, 75.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 3304/3304 [03:53<00:00,  1.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 3304/3304 [03:53<00:00, 14.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▉       | 242/835 [00:03<00:09, 64.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 152/835 [00:02<00:10, 63.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|████▉     | 417/835 [00:05<00:05, 74.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|██▉       | 249/835 [00:03<00:09, 64.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▉        | 159/835 [00:02<00:10, 63.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████     | 426/835 [00:05<00:05, 74.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 257/835 [00:03<00:08, 65.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|██        | 167/835 [00:02<00:10, 64.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 434/835 [00:05<00:05, 74.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 265/835 [00:04<00:08, 66.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██        | 175/835 [00:02<00:09, 66.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 442/835 [00:05<00:05, 74.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 0/835 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 273/835 [00:04<00:08, 66.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 183/835 [00:02<00:09, 67.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▍    | 450/835 [00:05<00:05, 74.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|          | 8/835 [00:00<00:12, 68.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▎      | 281/835 [00:04<00:08, 66.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 191/835 [00:02<00:09, 68.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▍    | 459/835 [00:06<00:05, 74.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▍      | 288/835 [00:04<00:08, 65.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 16/835 [00:00<00:12, 67.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▍       | 199/835 [00:03<00:09, 67.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▌    | 467/835 [00:06<00:05, 72.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 23/835 [00:00<00:12, 66.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▍       | 206/835 [00:03<00:09, 67.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▌      | 295/835 [00:04<00:08, 63.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 0/835 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 475/835 [00:06<00:05, 69.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▎         | 31/835 [00:00<00:12, 66.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▌      | 302/835 [00:04<00:08, 63.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▌       | 214/835 [00:03<00:09, 67.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|          | 8/835 [00:00<00:12, 68.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 483/835 [00:06<00:05, 70.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▍         | 39/835 [00:00<00:11, 67.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 222/835 [00:03<00:09, 67.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 310/835 [00:04<00:08, 62.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 16/835 [00:00<00:12, 67.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▉    | 491/835 [00:06<00:04, 70.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▌         | 46/835 [00:00<00:11, 66.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 230/835 [00:03<00:08, 67.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 317/835 [00:04<00:08, 62.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 23/835 [00:00<00:12, 65.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|█████▉    | 499/835 [00:06<00:04, 69.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▋         | 54/835 [00:00<00:11, 65.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▉      | 325/835 [00:04<00:07, 63.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▎         | 31/835 [00:00<00:12, 66.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▊       | 239/835 [00:03<00:09, 63.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 508/835 [00:06<00:04, 70.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 61/835 [00:00<00:11, 65.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|███▉      | 333/835 [00:05<00:07, 65.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▍         | 39/835 [00:00<00:11, 67.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|██▉       | 249/835 [00:03<00:09, 63.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 517/835 [00:06<00:04, 71.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 68/835 [00:01<00:11, 65.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████      | 340/835 [00:05<00:07, 65.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▌         | 46/835 [00:00<00:11, 66.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 525/835 [00:07<00:04, 72.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▉         | 75/835 [00:01<00:11, 64.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 257/835 [00:03<00:09, 63.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 347/835 [00:05<00:07, 63.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▋         | 54/835 [00:00<00:11, 65.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|▉         | 83/835 [00:01<00:11, 66.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▍   | 533/835 [00:07<00:04, 71.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 265/835 [00:04<00:08, 64.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 355/835 [00:05<00:07, 64.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 61/835 [00:00<00:11, 65.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▍   | 541/835 [00:07<00:04, 71.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█         | 91/835 [00:01<00:11, 67.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 272/835 [00:04<00:08, 64.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 363/835 [00:05<00:07, 65.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 68/835 [00:01<00:11, 64.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▌   | 550/835 [00:07<00:03, 72.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 98/835 [00:01<00:11, 64.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▎      | 280/835 [00:04<00:08, 64.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▍     | 370/835 [00:05<00:07, 63.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▉         | 75/835 [00:01<00:11, 64.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 558/835 [00:07<00:03, 71.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 106/835 [00:01<00:11, 65.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▍      | 288/835 [00:04<00:08, 64.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▌     | 378/835 [00:05<00:07, 65.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|▉         | 83/835 [00:01<00:11, 66.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▎        | 113/835 [00:01<00:11, 65.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 567/835 [00:07<00:03, 71.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▌      | 295/835 [00:04<00:08, 62.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▌     | 386/835 [00:05<00:06, 65.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█         | 91/835 [00:01<00:11, 67.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▍        | 120/835 [00:01<00:11, 64.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▉   | 575/835 [00:07<00:03, 73.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▌      | 302/835 [00:04<00:08, 62.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 394/835 [00:06<00:06, 66.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 98/835 [00:01<00:11, 64.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|██████▉   | 584/835 [00:07<00:03, 74.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▌        | 128/835 [00:01<00:10, 64.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 310/835 [00:04<00:08, 62.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 106/835 [00:01<00:11, 65.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 402/835 [00:06<00:06, 65.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████   | 592/835 [00:07<00:03, 75.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▋        | 136/835 [00:02<00:10, 64.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 317/835 [00:04<00:08, 62.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▉     | 410/835 [00:06<00:06, 66.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▎        | 114/835 [00:01<00:11, 65.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 601/835 [00:08<00:03, 75.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 144/835 [00:02<00:10, 64.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▉      | 325/835 [00:04<00:07, 64.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|████▉     | 417/835 [00:06<00:06, 65.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▍        | 122/835 [00:01<00:11, 64.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 610/835 [00:08<00:02, 75.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 151/835 [00:02<00:10, 63.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|███▉      | 333/835 [00:05<00:07, 65.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████     | 424/835 [00:06<00:06, 65.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▌        | 130/835 [00:01<00:10, 65.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 3304/3304 [03:55<00:00, 14.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▍  | 618/835 [00:08<00:02, 73.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▉        | 158/835 [00:02<00:10, 62.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████      | 341/835 [00:05<00:07, 65.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 432/835 [00:06<00:06, 64.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▋        | 137/835 [00:02<00:10, 64.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▌  | 628/835 [00:08<00:02, 77.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|█▉        | 166/835 [00:02<00:10, 63.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 348/835 [00:05<00:07, 63.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 440/835 [00:06<00:06, 64.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 145/835 [00:02<00:10, 65.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▋  | 637/835 [00:08<00:02, 77.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██        | 174/835 [00:02<00:10, 65.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 356/835 [00:05<00:07, 65.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▎    | 447/835 [00:06<00:06, 64.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 646/835 [00:08<00:02, 78.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 154/835 [00:02<00:10, 62.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 182/835 [00:02<00:09, 66.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▎     | 364/835 [00:05<00:07, 66.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▍    | 455/835 [00:06<00:05, 65.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 654/835 [00:08<00:02, 76.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▉        | 162/835 [00:02<00:10, 62.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 190/835 [00:02<00:09, 68.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▍     | 371/835 [00:05<00:07, 64.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▌    | 462/835 [00:07<00:05, 64.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▉  | 662/835 [00:08<00:02, 76.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|██        | 170/835 [00:02<00:10, 64.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▎       | 198/835 [00:03<00:09, 67.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▌     | 379/835 [00:05<00:06, 65.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▌    | 469/835 [00:07<00:05, 61.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|████████  | 670/835 [00:08<00:02, 75.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██▏       | 178/835 [00:02<00:09, 67.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▍       | 205/835 [00:03<00:09, 66.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▋     | 387/835 [00:05<00:06, 65.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████▏ | 679/835 [00:09<00:02, 76.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 186/835 [00:02<00:09, 67.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 479/835 [00:07<00:05, 60.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▌       | 213/835 [00:03<00:09, 66.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 395/835 [00:06<00:06, 67.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 0/835 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 687/835 [00:09<00:01, 76.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 194/835 [00:02<00:09, 68.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 486/835 [00:07<00:05, 59.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▋       | 221/835 [00:03<00:09, 67.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 402/835 [00:06<00:06, 65.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|          | 8/835 [00:00<00:12, 65.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 696/835 [00:09<00:01, 76.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▍       | 202/835 [00:03<00:09, 68.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 229/835 [00:03<00:09, 66.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▉    | 494/835 [00:07<00:05, 60.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▉     | 410/835 [00:06<00:06, 66.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 16/835 [00:00<00:12, 65.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▍ | 706/835 [00:09<00:01, 77.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▌       | 209/835 [00:03<00:09, 67.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|████▉     | 417/835 [00:06<00:06, 64.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 23/835 [00:00<00:12, 63.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▊       | 239/835 [00:03<00:09, 64.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▌ | 714/835 [00:09<00:01, 75.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|██████    | 504/835 [00:07<00:05, 59.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▌       | 217/835 [00:03<00:09, 68.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████     | 424/835 [00:06<00:06, 64.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▎         | 30/835 [00:00<00:12, 63.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 723/835 [00:09<00:01, 77.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 511/835 [00:07<00:05, 59.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 225/835 [00:03<00:08, 68.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|██▉       | 249/835 [00:03<00:09, 63.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 432/835 [00:06<00:06, 63.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▍         | 38/835 [00:00<00:12, 65.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 732/835 [00:09<00:01, 78.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 519/835 [00:08<00:05, 61.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 233/835 [00:03<00:08, 67.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 257/835 [00:03<00:08, 64.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 440/835 [00:06<00:06, 64.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▌         | 45/835 [00:00<00:12, 63.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▊ | 741/835 [00:09<00:01, 78.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 526/835 [00:08<00:05, 61.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▉       | 241/835 [00:03<00:09, 65.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 265/835 [00:04<00:08, 65.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▎    | 447/835 [00:06<00:06, 63.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▌         | 52/835 [00:00<00:12, 63.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|████████▉ | 749/835 [00:09<00:01, 76.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▍   | 533/835 [00:08<00:05, 60.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 272/835 [00:04<00:08, 64.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|██▉       | 248/835 [00:03<00:09, 64.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▍    | 455/835 [00:06<00:05, 65.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 757/835 [00:10<00:01, 74.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 60/835 [00:00<00:12, 62.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▍   | 540/835 [00:08<00:04, 60.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▎      | 280/835 [00:04<00:08, 64.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 256/835 [00:03<00:08, 64.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▌    | 462/835 [00:07<00:05, 64.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 67/835 [00:01<00:12, 62.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 766/835 [00:10<00:00, 74.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▌   | 547/835 [00:08<00:04, 61.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 264/835 [00:03<00:08, 66.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▍      | 288/835 [00:04<00:08, 64.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▌    | 469/835 [00:07<00:05, 61.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  93%|█████████▎| 775/835 [00:10<00:00, 74.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▋   | 555/835 [00:08<00:04, 63.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▉         | 77/835 [00:01<00:12, 62.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 272/835 [00:04<00:08, 65.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▌      | 295/835 [00:04<00:08, 62.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▍| 783/835 [00:10<00:00, 72.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 479/835 [00:07<00:05, 60.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|█         | 85/835 [00:01<00:11, 63.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▌      | 302/835 [00:04<00:08, 63.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 565/835 [00:08<00:04, 62.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▎      | 280/835 [00:04<00:08, 66.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▍| 791/835 [00:10<00:00, 72.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█         | 92/835 [00:01<00:11, 63.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 486/835 [00:07<00:05, 60.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▊   | 573/835 [00:08<00:04, 63.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 310/835 [00:04<00:08, 63.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▍      | 288/835 [00:04<00:08, 66.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▌| 800/835 [00:10<00:00, 72.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 99/835 [00:01<00:11, 61.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▉    | 494/835 [00:07<00:05, 61.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 317/835 [00:04<00:08, 64.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▌      | 295/835 [00:04<00:08, 64.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|██████▉   | 581/835 [00:09<00:04, 63.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 808/835 [00:10<00:00, 69.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 107/835 [00:01<00:11, 62.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▉      | 325/835 [00:04<00:07, 65.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▌      | 302/835 [00:04<00:08, 64.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████   | 589/835 [00:09<00:03, 65.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|██████    | 504/835 [00:07<00:05, 60.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 817/835 [00:10<00:00, 70.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|███▉      | 333/835 [00:05<00:07, 66.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▍        | 115/835 [00:01<00:11, 61.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 310/835 [00:04<00:08, 64.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████▏  | 597/835 [00:09<00:03, 66.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 511/835 [00:07<00:05, 59.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▉| 825/835 [00:11<00:00, 68.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████      | 340/835 [00:05<00:07, 66.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 317/835 [00:04<00:08, 64.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▍        | 123/835 [00:01<00:11, 62.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 604/835 [00:09<00:03, 64.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 519/835 [00:08<00:05, 62.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|█████████▉| 833/835 [00:11<00:00, 69.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 347/835 [00:05<00:07, 63.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▉      | 325/835 [00:04<00:07, 65.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 611/835 [00:09<00:03, 63.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▌        | 131/835 [00:02<00:11, 63.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 526/835 [00:08<00:04, 62.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 3304/3304 [03:58<00:00, 13.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 355/835 [00:05<00:07, 65.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|███▉      | 333/835 [00:05<00:07, 67.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▍  | 618/835 [00:09<00:03, 63.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 138/835 [00:02<00:11, 61.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▍   | 533/835 [00:08<00:04, 60.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 363/835 [00:05<00:07, 66.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████      | 341/835 [00:05<00:07, 67.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▍  | 626/835 [00:09<00:03, 65.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 145/835 [00:02<00:11, 62.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▍   | 540/835 [00:08<00:04, 61.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▍     | 370/835 [00:05<00:07, 64.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 348/835 [00:05<00:07, 65.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▌  | 634/835 [00:09<00:03, 66.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▌   | 547/835 [00:08<00:04, 61.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 154/835 [00:02<00:11, 60.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▌     | 378/835 [00:05<00:06, 66.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 356/835 [00:05<00:07, 67.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 642/835 [00:09<00:02, 66.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▋   | 555/835 [00:08<00:04, 62.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▉        | 161/835 [00:02<00:11, 60.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▌     | 386/835 [00:05<00:06, 66.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▎     | 364/835 [00:05<00:06, 67.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 650/835 [00:10<00:02, 65.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|██        | 168/835 [00:02<00:10, 61.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 565/835 [00:08<00:04, 61.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 394/835 [00:06<00:06, 67.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▍     | 372/835 [00:05<00:07, 65.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▊  | 657/835 [00:10<00:02, 64.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██        | 176/835 [00:02<00:10, 63.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▊   | 572/835 [00:08<00:04, 62.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 402/835 [00:06<00:06, 65.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▌     | 380/835 [00:05<00:06, 67.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|███████▉  | 665/835 [00:10<00:02, 63.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 184/835 [00:02<00:10, 64.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▉   | 579/835 [00:09<00:04, 61.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▉     | 410/835 [00:06<00:06, 66.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▋     | 388/835 [00:05<00:06, 67.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 0/835 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████  | 673/835 [00:10<00:02, 64.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 835/835 [00:26<00:00, 66.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 192/835 [00:03<00:09, 65.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|███████   | 587/835 [00:09<00:03, 63.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|████▉     | 417/835 [00:06<00:06, 64.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 396/835 [00:05<00:06, 68.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   1%|          | 8/835 [00:00<00:12, 64.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 681/835 [00:10<00:02, 64.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▍       | 200/835 [00:03<00:09, 65.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████▏  | 595/835 [00:09<00:03, 64.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████     | 424/835 [00:06<00:06, 64.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 403/835 [00:06<00:06, 67.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   2%|▏         | 16/835 [00:00<00:12, 64.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 688/835 [00:10<00:02, 63.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▍       | 208/835 [00:03<00:09, 64.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 602/835 [00:09<00:03, 62.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▉     | 411/835 [00:06<00:06, 67.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 432/835 [00:06<00:06, 64.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   3%|▎         | 23/835 [00:00<00:12, 62.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 696/835 [00:10<00:02, 64.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▌       | 216/835 [00:03<00:09, 65.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 610/835 [00:09<00:03, 63.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|█████     | 418/835 [00:06<00:06, 66.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 440/835 [00:06<00:06, 65.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   4%|▎         | 30/835 [00:00<00:12, 63.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▍ | 704/835 [00:10<00:02, 65.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 224/835 [00:03<00:09, 65.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▍  | 617/835 [00:09<00:03, 62.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████     | 426/835 [00:06<00:06, 66.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▎    | 448/835 [00:06<00:05, 65.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▍         | 38/835 [00:00<00:12, 64.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▌ | 712/835 [00:11<00:01, 64.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 232/835 [00:03<00:09, 64.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▍  | 625/835 [00:09<00:03, 64.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 434/835 [00:06<00:06, 66.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▍    | 456/835 [00:06<00:05, 65.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   5%|▌         | 45/835 [00:00<00:12, 62.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▌ | 719/835 [00:11<00:01, 63.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▊       | 239/835 [00:03<00:09, 62.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▌  | 633/835 [00:09<00:03, 65.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 442/835 [00:06<00:05, 65.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   6%|▌         | 52/835 [00:00<00:12, 63.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▌    | 464/835 [00:07<00:05, 65.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 727/835 [00:11<00:01, 64.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 641/835 [00:09<00:02, 65.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▍    | 450/835 [00:06<00:05, 66.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|██▉       | 249/835 [00:03<00:09, 62.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   7%|▋         | 60/835 [00:00<00:12, 62.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▋    | 471/835 [00:07<00:05, 60.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 735/835 [00:11<00:01, 65.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 649/835 [00:10<00:02, 65.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▍    | 458/835 [00:06<00:05, 65.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   8%|▊         | 67/835 [00:01<00:12, 62.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 257/835 [00:04<00:09, 63.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▉ | 742/835 [00:11<00:01, 63.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 480/835 [00:07<00:05, 59.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▊  | 656/835 [00:10<00:02, 64.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▌    | 466/835 [00:07<00:05, 65.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 265/835 [00:04<00:08, 64.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|████████▉ | 749/835 [00:11<00:01, 63.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   9%|▉         | 77/835 [00:01<00:12, 62.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 488/835 [00:07<00:05, 59.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|███████▉  | 664/835 [00:10<00:02, 64.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 272/835 [00:04<00:08, 63.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 756/835 [00:11<00:01, 62.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 475/835 [00:07<00:05, 61.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  10%|█         | 85/835 [00:01<00:11, 63.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▉    | 495/835 [00:07<00:05, 60.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|████████  | 671/835 [00:10<00:02, 63.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▎      | 280/835 [00:04<00:08, 64.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 482/835 [00:07<00:05, 62.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  11%|█         | 92/835 [00:01<00:11, 62.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|██████    | 502/835 [00:07<00:05, 60.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 766/835 [00:11<00:01, 61.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████▏ | 679/835 [00:10<00:02, 63.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▍      | 288/835 [00:04<00:08, 64.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▊    | 490/835 [00:07<00:05, 61.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  12%|█▏        | 99/835 [00:01<00:11, 61.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  93%|█████████▎| 773/835 [00:11<00:00, 62.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 510/835 [00:07<00:05, 61.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 687/835 [00:10<00:02, 64.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▌      | 295/835 [00:04<00:08, 62.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|█████▉    | 497/835 [00:07<00:05, 62.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  13%|█▎        | 107/835 [00:01<00:11, 62.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 518/835 [00:07<00:05, 62.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 694/835 [00:10<00:02, 64.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▎| 782/835 [00:12<00:00, 59.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▌      | 302/835 [00:04<00:08, 62.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|██████    | 504/835 [00:07<00:05, 62.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 525/835 [00:08<00:04, 62.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  14%|█▍        | 115/835 [00:01<00:11, 60.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▍ | 702/835 [00:10<00:02, 65.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▍| 790/835 [00:12<00:00, 60.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 310/835 [00:04<00:08, 62.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 511/835 [00:07<00:05, 61.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  15%|█▍        | 122/835 [00:01<00:11, 61.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▍   | 533/835 [00:08<00:04, 60.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▌ | 710/835 [00:11<00:01, 64.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▌| 797/835 [00:12<00:00, 60.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 317/835 [00:05<00:08, 62.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 519/835 [00:07<00:04, 64.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▌        | 130/835 [00:02<00:11, 62.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▍   | 540/835 [00:08<00:04, 61.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▌ | 718/835 [00:11<00:01, 63.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▋| 804/835 [00:12<00:00, 60.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▉      | 325/835 [00:05<00:07, 63.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 527/835 [00:08<00:04, 64.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  16%|█▋        | 137/835 [00:02<00:11, 61.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▌   | 547/835 [00:08<00:04, 61.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 726/835 [00:11<00:01, 64.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|███▉      | 333/835 [00:05<00:07, 65.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▍   | 534/835 [00:08<00:04, 62.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 813/835 [00:12<00:00, 57.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  17%|█▋        | 144/835 [00:02<00:11, 61.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▋   | 555/835 [00:08<00:04, 63.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 734/835 [00:11<00:01, 65.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████      | 340/835 [00:05<00:07, 65.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▍   | 542/835 [00:08<00:04, 63.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 821/835 [00:12<00:00, 57.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  18%|█▊        | 151/835 [00:02<00:11, 59.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 347/835 [00:05<00:07, 63.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 565/835 [00:08<00:04, 62.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▉ | 742/835 [00:11<00:01, 63.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▌   | 549/835 [00:08<00:04, 63.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▉| 827/835 [00:12<00:00, 56.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  19%|█▉        | 157/835 [00:02<00:11, 59.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 355/835 [00:05<00:07, 64.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▊   | 573/835 [00:08<00:04, 63.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|████████▉ | 750/835 [00:11<00:01, 64.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 556/835 [00:08<00:04, 63.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|█████████▉| 834/835 [00:13<00:00, 58.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  20%|█▉        | 164/835 [00:02<00:11, 59.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 363/835 [00:05<00:07, 65.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▉   | 580/835 [00:08<00:04, 62.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 757/835 [00:11<00:01, 62.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  21%|██        | 172/835 [00:02<00:10, 62.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 566/835 [00:08<00:04, 63.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▍     | 370/835 [00:05<00:07, 63.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|███████   | 588/835 [00:09<00:03, 64.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████▏| 764/835 [00:11<00:01, 62.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 180/835 [00:02<00:10, 64.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▊   | 574/835 [00:08<00:04, 64.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▌     | 378/835 [00:05<00:06, 65.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 772/835 [00:12<00:00, 64.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████▏  | 596/835 [00:09<00:03, 64.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  22%|██▏       | 187/835 [00:02<00:10, 64.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|██████▉   | 582/835 [00:08<00:03, 64.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▌     | 386/835 [00:06<00:06, 65.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 603/835 [00:09<00:03, 62.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  23%|██▎       | 195/835 [00:03<00:09, 65.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▎| 781/835 [00:12<00:00, 60.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████   | 590/835 [00:09<00:03, 65.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 394/835 [00:06<00:06, 67.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 611/835 [00:09<00:03, 63.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  24%|██▍       | 203/835 [00:03<00:09, 66.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▍| 789/835 [00:12<00:00, 62.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 598/835 [00:09<00:03, 67.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 402/835 [00:06<00:06, 66.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▍  | 619/835 [00:09<00:03, 64.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  25%|██▌       | 210/835 [00:03<00:09, 66.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▌| 797/835 [00:12<00:00, 62.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 606/835 [00:09<00:03, 65.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▉     | 410/835 [00:06<00:06, 67.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▌  | 627/835 [00:09<00:03, 66.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  26%|██▌       | 218/835 [00:03<00:09, 67.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▋| 804/835 [00:12<00:00, 62.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 613/835 [00:09<00:03, 64.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|████▉     | 417/835 [00:06<00:06, 66.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▌  | 635/835 [00:09<00:02, 67.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  27%|██▋       | 226/835 [00:03<00:09, 67.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▍  | 621/835 [00:09<00:03, 66.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████     | 425/835 [00:06<00:06, 66.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 814/835 [00:12<00:00, 61.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 643/835 [00:09<00:02, 68.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  28%|██▊       | 233/835 [00:03<00:09, 66.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▌  | 629/835 [00:09<00:02, 68.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 433/835 [00:06<00:06, 66.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 821/835 [00:12<00:00, 60.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 651/835 [00:10<00:02, 66.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  29%|██▉       | 241/835 [00:03<00:09, 64.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▋  | 637/835 [00:09<00:02, 68.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 441/835 [00:06<00:05, 65.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▉  | 658/835 [00:10<00:02, 65.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  30%|██▉       | 248/835 [00:03<00:09, 62.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|█████████▉| 831/835 [00:12<00:00, 61.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 645/835 [00:09<00:02, 69.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▍    | 449/835 [00:07<00:05, 66.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|███████▉  | 665/835 [00:10<00:02, 64.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 652/835 [00:09<00:02, 66.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  31%|███       | 256/835 [00:04<00:09, 63.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▍    | 457/835 [00:07<00:05, 67.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████  | 673/835 [00:10<00:02, 65.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▉  | 660/835 [00:10<00:02, 67.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 264/835 [00:04<00:08, 64.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▌    | 465/835 [00:07<00:05, 67.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 681/835 [00:10<00:02, 66.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|███████▉  | 667/835 [00:10<00:02, 66.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  32%|███▏      | 271/835 [00:04<00:08, 64.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 472/835 [00:07<00:05, 63.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 689/835 [00:10<00:02, 66.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████  | 675/835 [00:10<00:02, 67.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  33%|███▎      | 279/835 [00:04<00:08, 64.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 479/835 [00:07<00:05, 63.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 697/835 [00:10<00:02, 67.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 683/835 [00:10<00:02, 67.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  34%|███▍      | 287/835 [00:04<00:08, 65.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 486/835 [00:07<00:05, 62.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▍ | 705/835 [00:10<00:01, 69.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 691/835 [00:10<00:02, 67.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  35%|███▌      | 295/835 [00:04<00:08, 62.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▉    | 494/835 [00:07<00:05, 64.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▌ | 713/835 [00:10<00:01, 67.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▎ | 699/835 [00:10<00:01, 68.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  36%|███▌      | 302/835 [00:04<00:08, 62.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▌ | 720/835 [00:11<00:01, 66.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▍ | 707/835 [00:10<00:01, 68.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|██████    | 504/835 [00:07<00:05, 63.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  37%|███▋      | 310/835 [00:04<00:08, 63.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 728/835 [00:11<00:01, 67.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▌ | 715/835 [00:10<00:01, 67.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 511/835 [00:07<00:05, 63.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  38%|███▊      | 317/835 [00:05<00:08, 63.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 736/835 [00:11<00:01, 67.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 723/835 [00:10<00:01, 68.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 519/835 [00:08<00:04, 66.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  39%|███▉      | 325/835 [00:05<00:07, 64.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 731/835 [00:11<00:01, 69.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 527/835 [00:08<00:04, 65.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▉ | 746/835 [00:11<00:01, 65.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  40%|███▉      | 333/835 [00:05<00:07, 66.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▊ | 739/835 [00:11<00:01, 69.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▍   | 534/835 [00:08<00:04, 64.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|█████████ | 754/835 [00:11<00:01, 66.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  41%|████      | 341/835 [00:05<00:07, 66.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▉ | 746/835 [00:11<00:01, 67.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 761/835 [00:11<00:01, 66.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▍   | 542/835 [00:08<00:04, 65.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  42%|████▏     | 348/835 [00:05<00:07, 64.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|█████████ | 754/835 [00:11<00:01, 67.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 768/835 [00:11<00:01, 65.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▌   | 549/835 [00:08<00:04, 65.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  43%|████▎     | 356/835 [00:05<00:07, 65.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 761/835 [00:11<00:01, 67.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 556/835 [00:08<00:04, 65.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  93%|█████████▎| 775/835 [00:11<00:00, 64.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  44%|████▎     | 364/835 [00:05<00:07, 66.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 768/835 [00:11<00:01, 66.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 563/835 [00:08<00:04, 63.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▍| 785/835 [00:12<00:00, 62.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  45%|████▍     | 372/835 [00:05<00:07, 64.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  93%|█████████▎| 775/835 [00:11<00:00, 65.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 571/835 [00:08<00:04, 65.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▌     | 380/835 [00:05<00:06, 66.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▍| 793/835 [00:12<00:00, 62.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▎| 782/835 [00:11<00:00, 64.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▉   | 579/835 [00:09<00:03, 65.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  46%|████▋     | 388/835 [00:06<00:06, 66.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▌| 800/835 [00:12<00:00, 62.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▍| 790/835 [00:11<00:00, 65.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|███████   | 587/835 [00:09<00:03, 67.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  47%|████▋     | 396/835 [00:06<00:06, 67.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 807/835 [00:12<00:00, 61.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▌| 798/835 [00:12<00:00, 65.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████▏  | 595/835 [00:09<00:03, 68.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  48%|████▊     | 403/835 [00:06<00:06, 66.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 814/835 [00:12<00:00, 61.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▋| 805/835 [00:12<00:00, 65.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 602/835 [00:09<00:03, 66.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  49%|████▉     | 411/835 [00:06<00:06, 66.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 821/835 [00:12<00:00, 60.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 812/835 [00:12<00:00, 61.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 610/835 [00:09<00:03, 67.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  50%|█████     | 418/835 [00:06<00:06, 65.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▉| 828/835 [00:12<00:00, 60.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▍  | 617/835 [00:09<00:03, 66.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 820/835 [00:12<00:00, 63.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  51%|█████     | 426/835 [00:06<00:06, 64.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 835/835 [00:12<00:00, 61.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▍  | 625/835 [00:09<00:03, 68.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▉| 827/835 [00:12<00:00, 60.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  52%|█████▏    | 434/835 [00:06<00:06, 65.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▌  | 633/835 [00:09<00:02, 69.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 835/835 [00:12<00:00, 62.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  53%|█████▎    | 442/835 [00:06<00:06, 65.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 641/835 [00:09<00:02, 69.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  54%|█████▍    | 450/835 [00:07<00:05, 65.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 649/835 [00:10<00:02, 69.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▊  | 656/835 [00:10<00:02, 67.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  55%|█████▍    | 458/835 [00:07<00:05, 65.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|███████▉  | 664/835 [00:10<00:02, 68.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  56%|█████▌    | 466/835 [00:07<00:05, 65.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|████████  | 672/835 [00:10<00:02, 68.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  57%|█████▋    | 475/835 [00:07<00:05, 62.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████▏ | 680/835 [00:10<00:02, 69.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  58%|█████▊    | 482/835 [00:07<00:05, 62.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 688/835 [00:10<00:02, 69.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  59%|█████▊    | 490/835 [00:07<00:05, 62.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 696/835 [00:10<00:01, 71.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|█████▉    | 497/835 [00:07<00:05, 63.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▍ | 704/835 [00:10<00:01, 73.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  60%|██████    | 504/835 [00:07<00:05, 63.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▌ | 712/835 [00:10<00:01, 72.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  61%|██████    | 511/835 [00:07<00:05, 63.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▌ | 720/835 [00:11<00:01, 71.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  62%|██████▏   | 519/835 [00:08<00:04, 66.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 728/835 [00:11<00:01, 72.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  63%|██████▎   | 527/835 [00:08<00:04, 66.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 736/835 [00:11<00:01, 74.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  64%|██████▍   | 534/835 [00:08<00:04, 65.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▉ | 747/835 [00:11<00:01, 71.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  65%|██████▍   | 542/835 [00:08<00:04, 66.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|█████████ | 755/835 [00:11<00:01, 71.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  66%|██████▌   | 550/835 [00:08<00:04, 67.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████▏| 763/835 [00:11<00:01, 69.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  67%|██████▋   | 557/835 [00:08<00:04, 66.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 772/835 [00:11<00:00, 72.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  68%|██████▊   | 565/835 [00:08<00:03, 67.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  69%|██████▊   | 573/835 [00:08<00:03, 67.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▎| 782/835 [00:11<00:00, 68.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  70%|██████▉   | 581/835 [00:09<00:03, 67.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▍| 790/835 [00:12<00:00, 69.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████   | 589/835 [00:09<00:03, 68.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▌| 798/835 [00:12<00:00, 69.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  71%|███████▏  | 597/835 [00:09<00:03, 69.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 808/835 [00:12<00:00, 66.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  72%|███████▏  | 604/835 [00:09<00:03, 66.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 816/835 [00:12<00:00, 67.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  73%|███████▎  | 612/835 [00:09<00:03, 67.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▊| 823/835 [00:12<00:00, 65.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  74%|███████▍  | 620/835 [00:09<00:03, 67.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|█████████▉| 831/835 [00:12<00:00, 66.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  75%|███████▌  | 628/835 [00:09<00:02, 69.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  76%|███████▌  | 636/835 [00:09<00:02, 70.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  77%|███████▋  | 644/835 [00:09<00:02, 72.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  78%|███████▊  | 652/835 [00:10<00:02, 70.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  79%|███████▉  | 660/835 [00:10<00:02, 71.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  80%|████████  | 668/835 [00:10<00:02, 71.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  81%|████████  | 676/835 [00:10<00:02, 71.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  82%|████████▏ | 684/835 [00:10<00:02, 72.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  83%|████████▎ | 692/835 [00:10<00:01, 73.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|█████████▉| 833/835 [00:22<00:00, 69.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  84%|████████▍ | 700/835 [00:10<00:01, 74.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  85%|████████▍ | 708/835 [00:10<00:01, 74.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  86%|████████▌ | 716/835 [00:10<00:01, 72.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  87%|████████▋ | 724/835 [00:11<00:01, 73.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  88%|████████▊ | 733/835 [00:11<00:01, 75.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  89%|████████▊ | 741/835 [00:11<00:01, 74.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  90%|█████████ | 752/835 [00:11<00:01, 72.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  91%|█████████ | 760/835 [00:11<00:01, 71.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  92%|█████████▏| 772/835 [00:11<00:00, 72.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  94%|█████████▎| 782/835 [00:11<00:00, 68.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  95%|█████████▍| 790/835 [00:11<00:00, 69.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  96%|█████████▌| 798/835 [00:12<00:00, 69.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 806/835 [00:12<00:00, 69.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  97%|█████████▋| 813/835 [00:12<00:00, 66.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  98%|█████████▊| 821/835 [00:12<00:00, 65.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap:  99%|█████████▉| 828/835 [00:12<00:00, 65.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 835/835 [00:25<00:00, 62.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|█████████▉| 834/835 [00:30<00:00, 58.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|█████████▉| 834/835 [00:29<00:00, 61.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 835/835 [00:26<00:00, 61.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 835/835 [00:23<00:00, 66.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 835/835 [00:50<00:00, 16.47 examples/s]\u001b[0m\n",
      "\u001b[34mFilter:   0%|          | 0/3304 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mFilter: 100%|██████████| 3304/3304 [00:00<00:00, 121499.42 examples/s]\u001b[0m\n",
      "\u001b[34mFilter:   0%|          | 0/835 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mFilter: 100%|██████████| 835/835 [00:00<00:00, 110568.08 examples/s]\u001b[0m\n",
      "\u001b[34mDATASET PREPARATION COMPLETED\u001b[0m\n",
      "\u001b[34mDownloading builder script:   0%|          | 0.00/5.60k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading builder script: 100%|██████████| 5.60k/5.60k [00:00<00:00, 31.2MB/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|█████████▉| 832/835 [00:30<00:00, 65.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 835/835 [00:53<00:00,  2.00s/ examples]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 835/835 [00:53<00:00, 15.57 examples/s]\u001b[0m\n",
      "\u001b[34mDATASET PREPARATION COMPLETED\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 835/835 [00:55<00:00,  2.36s/ examples]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 835/835 [00:55<00:00, 15.12 examples/s]\u001b[0m\n",
      "\u001b[34mDATASET PREPARATION COMPLETED\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 835/835 [00:56<00:00,  1.80s/ examples]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 835/835 [00:56<00:00, 14.90 examples/s]\u001b[0m\n",
      "\u001b[34mDATASET PREPARATION COMPLETED\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 835/835 [00:56<00:00, 14.89 examples/s]\u001b[0m\n",
      "\u001b[34mDATASET PREPARATION COMPLETED\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 835/835 [00:56<00:00, 14.78 examples/s]\u001b[0m\n",
      "\u001b[34mDATASET PREPARATION COMPLETED\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 835/835 [00:56<00:00,  1.94s/ examples]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 835/835 [00:56<00:00, 14.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 835/835 [00:56<00:00,  1.77s/ examples]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 835/835 [00:56<00:00, 14.73 examples/s]\u001b[0m\n",
      "\u001b[34mDATASET PREPARATION COMPLETED\u001b[0m\n",
      "\u001b[34mDATASET PREPARATION COMPLETED\u001b[0m\n",
      "\u001b[34mmax_steps is given, it will override any value given in num_train_epochs\u001b[0m\n",
      "\u001b[34mmax_steps is given, it will override any value given in num_train_epochs\u001b[0m\n",
      "\u001b[34mTRAINING IN PROGRESS...\u001b[0m\n",
      "\u001b[34mmax_steps is given, it will override any value given in num_train_epochs\u001b[0m\n",
      "\u001b[34mmax_steps is given, it will override any value given in num_train_epochs\u001b[0m\n",
      "\u001b[34mmax_steps is given, it will override any value given in num_train_epochs\u001b[0m\n",
      "\u001b[34mmax_steps is given, it will override any value given in num_train_epochs\u001b[0m\n",
      "\u001b[34mmax_steps is given, it will override any value given in num_train_epochs\u001b[0m\n",
      "\u001b[34mmax_steps is given, it will override any value given in num_train_epochs\u001b[0m\n",
      "\u001b[34mmax_steps is given, it will override any value given in num_train_epochs\u001b[0m\n",
      "\u001b[34mmax_steps is given, it will override any value given in num_train_epochs\u001b[0m\n",
      "\u001b[34mmax_steps is given, it will override any value given in num_train_epochs\u001b[0m\n",
      "\u001b[34mmax_steps is given, it will override any value given in num_train_epochs\u001b[0m\n",
      "\u001b[34mTRAINING IN PROGRESS...\u001b[0m\n",
      "\u001b[34mmax_steps is given, it will override any value given in num_train_epochs\u001b[0m\n",
      "\u001b[34mmax_steps is given, it will override any value given in num_train_epochs\u001b[0m\n",
      "\u001b[34mTRAINING IN PROGRESS...\u001b[0m\n",
      "\u001b[34mTRAINING IN PROGRESS...\u001b[0m\n",
      "\u001b[34mmax_steps is given, it will override any value given in num_train_epochs\u001b[0m\n",
      "\u001b[34mmax_steps is given, it will override any value given in num_train_epochs\u001b[0m\n",
      "\u001b[34mTRAINING IN PROGRESS...\u001b[0m\n",
      "\u001b[34mTRAINING IN PROGRESS...\u001b[0m\n",
      "\u001b[34mTRAINING IN PROGRESS...\u001b[0m\n",
      "\u001b[34mTRAINING IN PROGRESS...\u001b[0m\n",
      "\u001b[34m0%|          | 0/500 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m0%|          | 1/500 [00:04<37:02,  4.45s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 2/500 [00:06<26:13,  3.16s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 3/500 [00:08<22:39,  2.74s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 4/500 [00:11<21:40,  2.62s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 5/500 [00:13<20:52,  2.53s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 6/500 [00:16<20:21,  2.47s/it]\u001b[0m\n",
      "\u001b[34m1%|▏         | 7/500 [00:18<20:00,  2.44s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 8/500 [00:20<19:47,  2.41s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 9/500 [00:23<19:35,  2.39s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 10/500 [00:25<19:27,  2.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.683, 'grad_norm': 14.800297737121582, 'learning_rate': 3.5e-06, 'epoch': 0.19}\u001b[0m\n",
      "\u001b[34m2%|▏         | 10/500 [00:25<19:27,  2.38s/it]\u001b[0m\n",
      "\u001b[34mDue to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\u001b[0m\n",
      "\u001b[34mDue to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\u001b[0m\n",
      "\u001b[34mDue to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\u001b[0m\n",
      "\u001b[34mDue to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\u001b[0m\n",
      "\u001b[34mDue to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\u001b[0m\n",
      "\u001b[34mDue to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\u001b[0m\n",
      "\u001b[34mThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\u001b[0m\n",
      "\u001b[34mThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\u001b[0m\n",
      "\u001b[34mDue to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\u001b[0m\n",
      "\u001b[34mDue to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\u001b[0m\n",
      "\u001b[34mDue to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\u001b[0m\n",
      "\u001b[34mDue to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\u001b[0m\n",
      "\u001b[34mDue to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\u001b[0m\n",
      "\u001b[34mDue to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\u001b[0m\n",
      "\u001b[34mDue to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\u001b[0m\n",
      "\u001b[34mDue to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\u001b[0m\n",
      "\u001b[34mThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\u001b[0m\n",
      "\u001b[34mThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\u001b[0m\n",
      "\u001b[34mThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\u001b[0m\n",
      "\u001b[34mThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\u001b[0m\n",
      "\u001b[34mThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\u001b[0m\n",
      "\u001b[34mThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\u001b[0m\n",
      "\u001b[34mThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\u001b[0m\n",
      "\u001b[34mThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\u001b[0m\n",
      "\u001b[34mDue to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\u001b[0m\n",
      "\u001b[34mDue to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\u001b[0m\n",
      "\u001b[34mThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\u001b[0m\n",
      "\u001b[34mThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\u001b[0m\n",
      "\u001b[34mThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\u001b[0m\n",
      "\u001b[34mThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\u001b[0m\n",
      "\u001b[34mThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\u001b[0m\n",
      "\u001b[34mThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\u001b[0m\n",
      "\u001b[34m0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 2/14 [00:04<00:29,  2.44s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██▏       | 3/14 [00:08<00:33,  3.01s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 4/14 [00:13<00:35,  3.50s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 5/14 [00:16<00:32,  3.56s/it]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 6/14 [00:21<00:30,  3.85s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 7/14 [00:25<00:27,  3.97s/it]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 8/14 [00:29<00:23,  3.91s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 9/14 [00:33<00:19,  3.95s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 10/14 [00:36<00:15,  3.84s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 11/14 [00:40<00:11,  3.86s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 12/14 [00:44<00:07,  3.82s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 13/14 [00:48<00:03,  3.86s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [00:50<00:00,  3.44s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 1.8185961246490479, 'eval_cer': 48.52670349907919, 'eval_runtime': 408.0103, 'eval_samples_per_second': 2.047, 'eval_steps_per_second': 0.034, 'epoch': 0.19}\u001b[0m\n",
      "\u001b[34m2%|▏         | 10/500 [07:13<19:27,  2.38s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [06:42<00:00,  3.44s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m2%|▏         | 11/500 [07:29<17:51:17, 131.45s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 12/500 [07:31<12:29:40, 92.17s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 13/500 [07:34<8:47:17, 64.96s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 14/500 [07:36<6:13:06, 46.06s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 15/500 [07:39<4:25:51, 32.89s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 16/500 [07:41<3:11:07, 23.69s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 17/500 [07:43<2:19:04, 17.28s/it]\u001b[0m\n",
      "\u001b[34m4%|▎         | 18/500 [07:46<1:42:45, 12.79s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 19/500 [07:48<1:17:25,  9.66s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 20/500 [07:50<59:42,  7.46s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.2666, 'grad_norm': 5.5729780197143555, 'learning_rate': 4.928571428571429e-06, 'epoch': 0.38}\u001b[0m\n",
      "\u001b[34m4%|▍         | 20/500 [07:50<59:42,  7.46s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 2/14 [00:03<00:23,  1.92s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██▏       | 3/14 [00:07<00:29,  2.72s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 4/14 [00:12<00:33,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 5/14 [00:15<00:31,  3.47s/it]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 6/14 [00:20<00:30,  3.87s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 7/14 [00:24<00:27,  3.93s/it]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 8/14 [00:34<00:35,  5.85s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 9/14 [00:38<00:26,  5.29s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 10/14 [00:42<00:19,  4.78s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 11/14 [00:45<00:13,  4.42s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 12/14 [00:49<00:08,  4.27s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 13/14 [00:53<00:04,  4.17s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [00:56<00:00,  3.65s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.9496588110923767, 'eval_cer': 27.769008155748487, 'eval_runtime': 414.6521, 'eval_samples_per_second': 2.014, 'eval_steps_per_second': 0.034, 'epoch': 0.38}\u001b[0m\n",
      "\u001b[34m4%|▍         | 20/500 [14:45<59:42,  7.46s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [06:49<00:00,  3.65s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m4%|▍         | 21/500 [15:03<17:57:48, 135.01s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 22/500 [15:05<12:38:23, 95.20s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 23/500 [15:07<8:55:20, 67.34s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 24/500 [15:10<6:19:32, 47.84s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 25/500 [15:12<4:30:43, 34.20s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 26/500 [15:15<3:14:41, 24.65s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 27/500 [15:17<2:21:23, 17.93s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 28/500 [15:19<1:44:06, 13.23s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 29/500 [15:21<1:18:02,  9.94s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 30/500 [15:24<59:51,  7.64s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7162, 'grad_norm': 6.379298686981201, 'learning_rate': 4.826530612244898e-06, 'epoch': 0.58}\u001b[0m\n",
      "\u001b[34m6%|▌         | 30/500 [15:24<59:51,  7.64s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 2/14 [00:03<00:20,  1.75s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██▏       | 3/14 [00:07<00:28,  2.62s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 4/14 [00:11<00:32,  3.27s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 5/14 [00:15<00:30,  3.41s/it]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 6/14 [00:20<00:30,  3.83s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 7/14 [00:24<00:28,  4.01s/it]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 8/14 [00:28<00:23,  3.93s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 9/14 [00:31<00:19,  3.86s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 10/14 [00:35<00:15,  3.84s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 11/14 [00:39<00:11,  3.76s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 12/14 [00:43<00:07,  3.81s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 13/14 [00:47<00:03,  3.87s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [00:49<00:00,  3.48s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.43849414587020874, 'eval_cer': 16.666666666666664, 'eval_runtime': 403.7406, 'eval_samples_per_second': 2.068, 'eval_steps_per_second': 0.035, 'epoch': 0.58}\u001b[0m\n",
      "\u001b[34m6%|▌         | 30/500 [22:07<59:51,  7.64s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [06:38<00:00,  3.48s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m6%|▌         | 31/500 [22:31<17:24:27, 133.62s/it]\u001b[0m\n",
      "\u001b[34m6%|▋         | 32/500 [22:33<12:14:46, 94.20s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 33/500 [22:36<8:38:39, 66.64s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 34/500 [22:38<6:07:41, 47.34s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 35/500 [22:40<4:22:13, 33.84s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 36/500 [22:43<3:08:32, 24.38s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 37/500 [22:45<2:16:58, 17.75s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 38/500 [22:47<1:40:56, 13.11s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 39/500 [22:49<1:15:43,  9.86s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 40/500 [22:52<58:06,  7.58s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.3496, 'grad_norm': 3.840390205383301, 'learning_rate': 4.724489795918368e-06, 'epoch': 0.77}\u001b[0m\n",
      "\u001b[34m8%|▊         | 40/500 [22:52<58:06,  7.58s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 2/14 [00:03<00:21,  1.75s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██▏       | 3/14 [00:07<00:28,  2.63s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 4/14 [00:11<00:32,  3.27s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 5/14 [00:15<00:30,  3.41s/it]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 6/14 [00:20<00:30,  3.84s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 7/14 [00:24<00:28,  4.02s/it]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 8/14 [00:28<00:23,  3.90s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 9/14 [00:38<00:28,  5.78s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 10/14 [00:41<00:20,  5.13s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 11/14 [00:45<00:13,  4.66s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 12/14 [00:49<00:08,  4.44s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 13/14 [00:53<00:04,  4.28s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [00:55<00:00,  3.75s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.33496275544166565, 'eval_cer': 17.048145224940807, 'eval_runtime': 412.0812, 'eval_samples_per_second': 2.026, 'eval_steps_per_second': 0.034, 'epoch': 0.77}\u001b[0m\n",
      "\u001b[34m8%|▊         | 40/500 [29:44<58:06,  7.58s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [06:46<00:00,  3.75s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m8%|▊         | 41/500 [30:04<17:12:18, 134.94s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 42/500 [30:06<12:06:11, 95.13s/it]\u001b[0m\n",
      "\u001b[34m9%|▊         | 43/500 [30:08<8:32:27, 67.28s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 44/500 [30:11<6:03:03, 47.77s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 45/500 [30:13<4:18:43, 34.12s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 46/500 [30:15<3:05:48, 24.56s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 47/500 [30:17<2:14:51, 17.86s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 48/500 [30:20<1:39:15, 13.17s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 49/500 [30:22<1:14:25,  9.90s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 50/500 [30:24<57:02,  7.61s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.314, 'grad_norm': 2.281874179840088, 'learning_rate': 4.622448979591837e-06, 'epoch': 0.96}\u001b[0m\n",
      "\u001b[34m10%|█         | 50/500 [30:24<57:02,  7.61s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 2/14 [00:03<00:21,  1.76s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██▏       | 3/14 [00:07<00:28,  2.63s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 4/14 [00:11<00:32,  3.26s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 5/14 [00:15<00:30,  3.41s/it]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 6/14 [00:20<00:30,  3.83s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 7/14 [00:24<00:28,  4.02s/it]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 8/14 [00:28<00:23,  3.91s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 9/14 [00:31<00:19,  3.87s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 10/14 [00:35<00:15,  3.81s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 11/14 [00:39<00:11,  3.75s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 12/14 [00:43<00:07,  3.84s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 13/14 [00:47<00:03,  3.87s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [00:49<00:00,  3.44s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.30414995551109314, 'eval_cer': 15.285451197053407, 'eval_runtime': 406.9441, 'eval_samples_per_second': 2.052, 'eval_steps_per_second': 0.034, 'epoch': 0.96}\u001b[0m\n",
      "\u001b[34m10%|█         | 50/500 [37:11<57:02,  7.61s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [06:41<00:00,  3.44s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m10%|█         | 51/500 [37:34<16:44:35, 134.24s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 52/500 [37:35<11:43:49, 94.26s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 53/500 [37:38<8:19:32, 67.05s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 54/500 [37:41<5:54:01, 47.63s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 55/500 [37:43<4:12:21, 34.03s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 56/500 [37:45<3:01:18, 24.50s/it]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 57/500 [37:48<2:11:39, 17.83s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 58/500 [37:50<1:36:55, 13.16s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 59/500 [37:52<1:12:39,  9.89s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 60/500 [37:54<55:41,  7.59s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.2271, 'grad_norm': 2.3348140716552734, 'learning_rate': 4.520408163265306e-06, 'epoch': 1.15}\u001b[0m\n",
      "\u001b[34m12%|█▏        | 60/500 [37:54<55:41,  7.59s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 2/14 [00:03<00:21,  1.78s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██▏       | 3/14 [00:07<00:29,  2.65s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 4/14 [00:11<00:32,  3.27s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 5/14 [00:15<00:30,  3.41s/it]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 6/14 [00:20<00:30,  3.83s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 7/14 [00:24<00:28,  4.01s/it]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 8/14 [00:28<00:23,  3.91s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 9/14 [00:31<00:19,  3.86s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 10/14 [00:35<00:15,  3.81s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 11/14 [00:39<00:11,  3.75s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 12/14 [00:43<00:07,  3.83s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 13/14 [00:47<00:03,  3.86s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [00:49<00:00,  3.44s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.2632479965686798, 'eval_cer': 15.745856353591158, 'eval_runtime': 404.6651, 'eval_samples_per_second': 2.063, 'eval_steps_per_second': 0.035, 'epoch': 1.15}\u001b[0m\n",
      "\u001b[34m12%|█▏        | 60/500 [44:39<55:41,  7.59s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [06:39<00:00,  3.44s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m12%|█▏        | 61/500 [45:00<16:14:19, 133.16s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 62/500 [45:03<11:25:23, 93.89s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 63/500 [45:05<8:04:03, 66.46s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 64/500 [45:07<5:42:54, 47.19s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 65/500 [45:10<4:04:24, 33.71s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 66/500 [45:12<2:55:35, 24.28s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 67/500 [45:14<2:07:41, 17.69s/it]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 68/500 [45:16<1:33:55, 13.05s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 69/500 [45:19<1:10:30,  9.82s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 70/500 [45:21<54:06,  7.55s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.1791, 'grad_norm': 114.73780059814453, 'learning_rate': 4.428571428571429e-06, 'epoch': 1.35}\u001b[0m\n",
      "\u001b[34m14%|█▍        | 70/500 [45:21<54:06,  7.55s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 2/14 [00:09<00:59,  4.92s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██▏       | 3/14 [00:19<01:16,  6.98s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 4/14 [00:29<01:20,  8.06s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 5/14 [00:39<01:18,  8.73s/it]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 6/14 [00:49<01:12,  9.11s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 7/14 [00:55<00:57,  8.22s/it]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 8/14 [01:05<00:51,  8.66s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 9/14 [01:15<00:45,  9.01s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 10/14 [01:25<00:37,  9.34s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 11/14 [01:35<00:28,  9.56s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 12/14 [01:45<00:19,  9.70s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 13/14 [01:51<00:08,  8.59s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [02:00<00:00,  8.65s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.2472444474697113, 'eval_cer': 74.57248092607209, 'eval_runtime': 467.6175, 'eval_samples_per_second': 1.786, 'eval_steps_per_second': 0.03, 'epoch': 1.35}\u001b[0m\n",
      "\u001b[34m14%|█▍        | 70/500 [53:09<54:06,  7.55s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [07:36<00:00,  8.65s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m14%|█▍        | 71/500 [53:32<18:10:23, 152.50s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 72/500 [53:34<12:46:19, 107.43s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 73/500 [53:36<8:59:56, 75.87s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 74/500 [53:38<6:21:50, 53.78s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 75/500 [53:41<4:31:26, 38.32s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 76/500 [53:43<3:14:18, 27.50s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 77/500 [53:45<2:20:26, 19.92s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 78/500 [53:47<1:42:47, 14.62s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 79/500 [53:50<1:16:30, 10.90s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 80/500 [53:52<58:07,  8.30s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.1404, 'grad_norm': 2.317758083343506, 'learning_rate': 4.326530612244899e-06, 'epoch': 1.54}\u001b[0m\n",
      "\u001b[34m16%|█▌        | 80/500 [53:52<58:07,  8.30s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 2/14 [00:09<00:59,  4.93s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██▏       | 3/14 [00:19<01:16,  6.97s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 4/14 [00:29<01:20,  8.04s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 5/14 [00:39<01:17,  8.66s/it]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 6/14 [00:49<01:13,  9.13s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 7/14 [00:59<01:05,  9.35s/it]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 8/14 [01:09<00:57,  9.51s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 9/14 [01:18<00:48,  9.61s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 10/14 [01:28<00:38,  9.69s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 11/14 [01:38<00:29,  9.80s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 12/14 [01:48<00:19,  9.87s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 13/14 [01:58<00:09,  9.93s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [02:07<00:00,  9.54s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.23196396231651306, 'eval_cer': 65.48276769271244, 'eval_runtime': 477.6628, 'eval_samples_per_second': 1.748, 'eval_steps_per_second': 0.029, 'epoch': 1.54}\u001b[0m\n",
      "\u001b[34m16%|█▌        | 80/500 [1:01:50<58:07,  8.30s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [07:46<00:00,  9.54s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m16%|█▌        | 81/500 [1:02:07<17:57:13, 154.26s/it]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 82/500 [1:02:09<12:36:58, 108.66s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 83/500 [1:02:11<8:53:17, 76.73s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 84/500 [1:02:13<6:17:04, 54.39s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 85/500 [1:02:16<4:27:57, 38.74s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 86/500 [1:02:18<3:11:45, 27.79s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 87/500 [1:02:20<2:18:31, 20.12s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 88/500 [1:02:22<1:41:18, 14.75s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 89/500 [1:02:25<1:15:21, 11.00s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 90/500 [1:02:27<57:11,  8.37s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.1322, 'grad_norm': 1.7785333395004272, 'learning_rate': 4.224489795918368e-06, 'epoch': 1.73}\u001b[0m\n",
      "\u001b[34m18%|█▊        | 90/500 [1:02:27<57:11,  8.37s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 2/14 [00:03<00:20,  1.73s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██▏       | 3/14 [00:07<00:28,  2.58s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 4/14 [00:11<00:32,  3.22s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 5/14 [00:15<00:30,  3.37s/it]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 6/14 [00:19<00:30,  3.81s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 7/14 [00:24<00:27,  3.99s/it]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 8/14 [00:34<00:34,  5.83s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 9/14 [00:37<00:26,  5.23s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 10/14 [00:41<00:18,  4.75s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 11/14 [00:45<00:13,  4.39s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 12/14 [00:49<00:08,  4.22s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 13/14 [00:53<00:04,  4.14s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [01:01<00:00,  5.50s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.2249501794576645, 'eval_cer': 18.639831623257038, 'eval_runtime': 422.9128, 'eval_samples_per_second': 1.974, 'eval_steps_per_second': 0.033, 'epoch': 1.73}\u001b[0m\n",
      "\u001b[34m18%|█▊        | 90/500 [1:09:30<57:11,  8.37s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [06:51<00:00,  5.50s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m18%|█▊        | 91/500 [1:09:53<15:51:24, 139.57s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 92/500 [1:09:55<11:08:53, 98.37s/it]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 93/500 [1:09:57<7:51:37, 69.53s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 94/500 [1:09:59<5:33:52, 49.34s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 95/500 [1:10:02<3:57:39, 35.21s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 96/500 [1:10:04<2:50:29, 25.32s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 97/500 [1:10:06<2:03:32, 18.39s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 98/500 [1:10:08<1:30:47, 13.55s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 99/500 [1:10:10<1:07:52, 10.16s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 100/500 [1:10:13<51:51,  7.78s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.1426, 'grad_norm': 1.9997718334197998, 'learning_rate': 4.122448979591837e-06, 'epoch': 1.92}\u001b[0m\n",
      "\u001b[34m20%|██        | 100/500 [1:10:13<51:51,  7.78s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 2/14 [00:03<00:20,  1.74s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██▏       | 3/14 [00:07<00:28,  2.59s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 4/14 [00:11<00:32,  3.23s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 5/14 [00:15<00:30,  3.38s/it]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 6/14 [00:19<00:30,  3.82s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 7/14 [00:24<00:27,  4.00s/it]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 8/14 [00:28<00:23,  3.91s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 9/14 [00:31<00:19,  3.86s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 10/14 [00:35<00:15,  3.81s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 11/14 [00:39<00:11,  3.74s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 12/14 [00:42<00:07,  3.77s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 13/14 [00:46<00:03,  3.82s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [00:49<00:00,  3.43s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.2186306267976761, 'eval_cer': 15.167061299657986, 'eval_runtime': 409.735, 'eval_samples_per_second': 2.038, 'eval_steps_per_second': 0.034, 'epoch': 1.92}\u001b[0m\n",
      "\u001b[34m20%|██        | 100/500 [1:17:02<51:51,  7.78s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [06:44<00:00,  3.43s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m20%|██        | 101/500 [1:17:19<14:47:17, 133.43s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 102/500 [1:17:22<10:24:01, 94.07s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 103/500 [1:17:24<7:20:14, 66.53s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 104/500 [1:17:25<5:09:17, 46.86s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 105/500 [1:17:28<3:42:58, 33.87s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 106/500 [1:17:31<2:40:10, 24.39s/it]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 107/500 [1:17:33<1:56:14, 17.75s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 108/500 [1:17:35<1:25:33, 13.10s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 109/500 [1:17:37<1:04:06,  9.84s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 110/500 [1:17:40<49:05,  7.55s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.1093, 'grad_norm': 1.4374715089797974, 'learning_rate': 4.0204081632653065e-06, 'epoch': 2.12}\u001b[0m\n",
      "\u001b[34m22%|██▏       | 110/500 [1:17:40<49:05,  7.55s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 2/14 [00:03<00:20,  1.72s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██▏       | 3/14 [00:07<00:28,  2.58s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 4/14 [00:11<00:32,  3.22s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 5/14 [00:15<00:30,  3.36s/it]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 6/14 [00:19<00:30,  3.80s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 7/14 [00:24<00:27,  3.97s/it]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 8/14 [00:27<00:23,  3.90s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 9/14 [00:31<00:19,  3.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 10/14 [00:35<00:15,  3.84s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 11/14 [00:39<00:11,  3.77s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 12/14 [00:42<00:07,  3.80s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 13/14 [00:46<00:03,  3.85s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [00:49<00:00,  3.44s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.22070755064487457, 'eval_cer': 15.206524598789791, 'eval_runtime': 407.9127, 'eval_samples_per_second': 2.047, 'eval_steps_per_second': 0.034, 'epoch': 2.12}\u001b[0m\n",
      "\u001b[34m22%|██▏       | 110/500 [1:24:28<49:05,  7.55s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [06:42<00:00,  3.44s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m22%|██▏       | 111/500 [1:24:46<14:23:34, 133.20s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 112/500 [1:24:48<10:07:18, 93.91s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 113/500 [1:24:50<7:08:21, 66.41s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 114/500 [1:24:53<5:03:23, 47.16s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 115/500 [1:24:55<3:36:07, 33.68s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 116/500 [1:24:57<2:35:11, 24.25s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 117/500 [1:24:59<1:52:36, 17.64s/it]\u001b[0m\n",
      "\u001b[34m24%|██▎       | 118/500 [1:25:02<1:22:52, 13.02s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 119/500 [1:25:04<1:02:05,  9.78s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 120/500 [1:25:06<47:35,  7.52s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0791, 'grad_norm': 1.7283713817596436, 'learning_rate': 3.9183673469387755e-06, 'epoch': 2.31}\u001b[0m\n",
      "\u001b[34m24%|██▍       | 120/500 [1:25:06<47:35,  7.52s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 2/14 [00:03<00:20,  1.72s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██▏       | 3/14 [00:07<00:28,  2.58s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 4/14 [00:11<00:32,  3.21s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 5/14 [00:15<00:30,  3.36s/it]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 6/14 [00:19<00:30,  3.80s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 7/14 [00:24<00:27,  3.99s/it]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 8/14 [00:27<00:23,  3.87s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 9/14 [00:37<00:28,  5.72s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 10/14 [00:41<00:20,  5.08s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 11/14 [00:44<00:13,  4.63s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 12/14 [00:48<00:08,  4.38s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 13/14 [00:52<00:04,  4.25s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [00:55<00:00,  3.71s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.21993418037891388, 'eval_cer': 17.298079452775585, 'eval_runtime': 412.4723, 'eval_samples_per_second': 2.024, 'eval_steps_per_second': 0.034, 'epoch': 2.31}\u001b[0m\n",
      "\u001b[34m24%|██▍       | 120/500 [1:31:59<47:35,  7.52s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [06:47<00:00,  3.71s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m24%|██▍       | 121/500 [1:32:17<14:09:55, 134.55s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 122/500 [1:32:19<9:57:34, 94.85s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 123/500 [1:32:21<7:01:21, 67.06s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 124/500 [1:32:24<4:58:19, 47.61s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 125/500 [1:32:26<3:32:27, 33.99s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 126/500 [1:32:28<2:32:30, 24.47s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 127/500 [1:32:30<1:50:36, 17.79s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 128/500 [1:32:33<1:21:22, 13.12s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 129/500 [1:32:35<1:00:56,  9.86s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 130/500 [1:32:37<46:39,  7.57s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0647, 'grad_norm': 1.2087057828903198, 'learning_rate': 3.816326530612245e-06, 'epoch': 2.5}\u001b[0m\n",
      "\u001b[34m26%|██▌       | 130/500 [1:32:37<46:39,  7.57s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 2/14 [00:03<00:21,  1.78s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██▏       | 3/14 [00:07<00:28,  2.62s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 4/14 [00:12<00:33,  3.38s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 5/14 [00:15<00:31,  3.47s/it]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 6/14 [00:20<00:30,  3.87s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 7/14 [00:24<00:28,  4.03s/it]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 8/14 [00:28<00:23,  3.90s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 9/14 [00:32<00:19,  3.86s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 10/14 [00:35<00:15,  3.79s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 11/14 [00:39<00:11,  3.73s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 12/14 [00:43<00:07,  3.75s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 13/14 [00:47<00:03,  3.81s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [00:49<00:00,  3.46s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.21988001465797424, 'eval_cer': 15.982636148382005, 'eval_runtime': 408.9815, 'eval_samples_per_second': 2.042, 'eval_steps_per_second': 0.034, 'epoch': 2.5}\u001b[0m\n",
      "\u001b[34m26%|██▌       | 130/500 [1:39:26<46:39,  7.57s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [06:43<00:00,  3.46s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m26%|██▌       | 131/500 [1:39:45<13:42:06, 133.68s/it]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 132/500 [1:39:47<9:38:01, 94.24s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 133/500 [1:39:49<6:47:39, 66.65s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 134/500 [1:39:52<4:48:39, 47.32s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 135/500 [1:39:54<3:25:34, 33.79s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 136/500 [1:39:56<2:27:33, 24.32s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 137/500 [1:39:58<1:47:02, 17.69s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 138/500 [1:40:01<1:18:44, 13.05s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 139/500 [1:40:03<58:57,  9.80s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 140/500 [1:40:05<45:10,  7.53s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0791, 'grad_norm': 1.6892935037612915, 'learning_rate': 3.7142857142857146e-06, 'epoch': 2.69}\u001b[0m\n",
      "\u001b[34m28%|██▊       | 140/500 [1:40:05<45:10,  7.53s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 2/14 [00:03<00:20,  1.72s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██▏       | 3/14 [00:07<00:28,  2.58s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 4/14 [00:11<00:31,  3.20s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 5/14 [00:15<00:30,  3.35s/it]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 6/14 [00:19<00:30,  3.80s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 7/14 [00:24<00:27,  3.98s/it]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 8/14 [00:27<00:23,  3.86s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 9/14 [00:31<00:19,  3.82s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 10/14 [00:35<00:15,  3.76s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 11/14 [00:38<00:11,  3.70s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 12/14 [00:42<00:07,  3.74s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 13/14 [00:52<00:05,  5.64s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [00:55<00:00,  4.68s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.22226248681545258, 'eval_cer': 20.3893712181005, 'eval_runtime': 412.3873, 'eval_samples_per_second': 2.025, 'eval_steps_per_second': 0.034, 'epoch': 2.69}\u001b[0m\n",
      "\u001b[34m28%|██▊       | 140/500 [1:46:57<45:10,  7.53s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [06:47<00:00,  4.68s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m28%|██▊       | 141/500 [1:47:15<13:23:47, 134.34s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 142/500 [1:47:17<9:25:02, 94.70s/it]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 143/500 [1:47:20<6:38:23, 66.96s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 144/500 [1:47:22<4:42:02, 47.53s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 145/500 [1:47:24<3:20:48, 33.94s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 146/500 [1:47:26<2:24:05, 24.42s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 147/500 [1:47:29<1:44:29, 17.76s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 148/500 [1:47:31<1:16:49, 13.10s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 149/500 [1:47:33<57:30,  9.83s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 150/500 [1:47:35<44:02,  7.55s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0778, 'grad_norm': 1.310274362564087, 'learning_rate': 3.612244897959184e-06, 'epoch': 2.88}\u001b[0m\n",
      "\u001b[34m30%|███       | 150/500 [1:47:35<44:02,  7.55s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 2/14 [00:03<00:20,  1.71s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██▏       | 3/14 [00:07<00:28,  2.57s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 4/14 [00:11<00:31,  3.20s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 5/14 [00:15<00:29,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 6/14 [00:19<00:30,  3.78s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 7/14 [00:24<00:27,  3.96s/it]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 8/14 [00:27<00:23,  3.84s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 9/14 [00:31<00:18,  3.79s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 10/14 [00:41<00:22,  5.64s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 11/14 [00:44<00:15,  5.01s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 12/14 [00:48<00:09,  4.65s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 13/14 [00:58<00:06,  6.28s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [01:01<00:00,  5.13s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.21909795701503754, 'eval_cer': 19.455406471981057, 'eval_runtime': 419.7447, 'eval_samples_per_second': 1.989, 'eval_steps_per_second': 0.033, 'epoch': 2.88}\u001b[0m\n",
      "\u001b[34m30%|███       | 150/500 [1:54:35<44:02,  7.55s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [06:54<00:00,  5.13s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m30%|███       | 151/500 [1:54:58<13:22:57, 138.04s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 152/500 [1:55:00<9:24:20, 97.30s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 153/500 [1:55:02<6:37:46, 68.78s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 154/500 [1:55:04<4:41:29, 48.81s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 155/500 [1:55:07<3:20:19, 34.84s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 156/500 [1:55:08<2:21:29, 24.68s/it]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 157/500 [1:55:11<1:44:43, 18.32s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 158/500 [1:55:13<1:16:55, 13.50s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 159/500 [1:55:16<57:28, 10.11s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 160/500 [1:55:18<43:52,  7.74s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0613, 'grad_norm': 0.9937024116516113, 'learning_rate': 3.5102040816326533e-06, 'epoch': 3.08}\u001b[0m\n",
      "\u001b[34m32%|███▏      | 160/500 [1:55:18<43:52,  7.74s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 2/14 [00:03<00:20,  1.71s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██▏       | 3/14 [00:07<00:28,  2.57s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 4/14 [00:11<00:32,  3.20s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 5/14 [00:15<00:29,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 6/14 [00:19<00:30,  3.78s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 7/14 [00:24<00:27,  3.96s/it]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 8/14 [00:33<00:34,  5.80s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 9/14 [00:43<00:35,  7.03s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 10/14 [00:47<00:23,  5.98s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 11/14 [00:50<00:15,  5.25s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 12/14 [00:54<00:09,  4.81s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 13/14 [00:58<00:04,  4.54s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [01:01<00:00,  3.92s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.2211594432592392, 'eval_cer': 18.28466193107077, 'eval_runtime': 422.426, 'eval_samples_per_second': 1.977, 'eval_steps_per_second': 0.033, 'epoch': 3.08}\u001b[0m\n",
      "\u001b[34m32%|███▏      | 160/500 [2:02:20<43:52,  7.74s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [06:57<00:00,  3.92s/it]#033[A\u001b[0m\n",
      "\u001b[34m#015                                               #033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m32%|███▏      | 161/500 [2:02:36<12:52:58, 136.81s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 162/500 [2:02:38<9:03:15, 96.43s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 163/500 [2:02:40<6:22:52, 68.17s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 164/500 [2:02:42<4:30:57, 48.38s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 165/500 [2:02:45<3:12:49, 34.53s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 166/500 [2:02:47<2:18:17, 24.84s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 167/500 [2:02:49<1:40:16, 18.07s/it]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 168/500 [2:02:51<1:13:38, 13.31s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 169/500 [2:02:54<55:02,  9.98s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 170/500 [2:02:56<42:02,  7.64s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0424, 'grad_norm': 1.03254234790802, 'learning_rate': 3.4081632653061227e-06, 'epoch': 3.27}\u001b[0m\n",
      "\u001b[34m34%|███▍      | 170/500 [2:02:56<42:02,  7.64s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 2/14 [00:03<00:20,  1.70s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██▏       | 3/14 [00:07<00:28,  2.55s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 4/14 [00:11<00:31,  3.19s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 5/14 [00:14<00:29,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 6/14 [00:19<00:30,  3.78s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 7/14 [00:24<00:27,  3.96s/it]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 8/14 [00:27<00:23,  3.83s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 9/14 [00:37<00:28,  5.69s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 10/14 [00:41<00:20,  5.06s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 11/14 [00:44<00:13,  4.60s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 12/14 [00:48<00:08,  4.35s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 13/14 [00:52<00:04,  4.23s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [00:54<00:00,  3.70s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.2284592092037201, 'eval_cer': 18.679294922388845, 'eval_runtime': 414.107, 'eval_samples_per_second': 2.016, 'eval_steps_per_second': 0.034, 'epoch': 3.27}\u001b[0m\n",
      "\u001b[34m34%|███▍      | 170/500 [2:09:50<42:02,  7.64s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [06:49<00:00,  3.70s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m34%|███▍      | 171/500 [2:10:07<12:19:20, 134.83s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 172/500 [2:10:10<8:39:41, 95.07s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 173/500 [2:10:12<6:06:19, 67.21s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 174/500 [2:10:14<4:19:15, 47.72s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 175/500 [2:10:16<3:04:30, 34.06s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 176/500 [2:10:18<2:12:21, 24.51s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 177/500 [2:10:21<1:35:56, 17.82s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 178/500 [2:10:23<1:10:31, 13.14s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 179/500 [2:10:25<52:46,  9.87s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 180/500 [2:10:27<40:22,  7.57s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0418, 'grad_norm': 1.3547298908233643, 'learning_rate': 3.3061224489795924e-06, 'epoch': 3.46}\u001b[0m\n",
      "\u001b[34m36%|███▌      | 180/500 [2:10:27<40:22,  7.57s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 2/14 [00:03<00:20,  1.71s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██▏       | 3/14 [00:07<00:28,  2.57s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 4/14 [00:11<00:31,  3.19s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 5/14 [00:15<00:30,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 6/14 [00:19<00:30,  3.78s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 7/14 [00:24<00:27,  3.97s/it]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 8/14 [00:27<00:23,  3.86s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 9/14 [00:31<00:19,  3.81s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 10/14 [00:35<00:15,  3.76s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 11/14 [00:38<00:11,  3.69s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 12/14 [00:42<00:07,  3.75s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 13/14 [00:46<00:03,  3.81s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [00:48<00:00,  3.39s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.22506798803806305, 'eval_cer': 14.798737174427782, 'eval_runtime': 406.3066, 'eval_samples_per_second': 2.055, 'eval_steps_per_second': 0.034, 'epoch': 3.46}\u001b[0m\n",
      "\u001b[34m36%|███▌      | 180/500 [2:17:14<40:22,  7.57s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [06:41<00:00,  3.39s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m36%|███▌      | 181/500 [2:17:37<11:53:14, 134.15s/it]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 182/500 [2:17:39<8:21:14, 94.57s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 183/500 [2:17:41<5:53:19, 66.87s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 184/500 [2:17:44<4:10:05, 47.49s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 185/500 [2:17:46<2:58:05, 33.92s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 186/500 [2:17:48<2:07:45, 24.41s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 187/500 [2:17:50<1:32:38, 17.76s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 188/500 [2:17:53<1:08:06, 13.10s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 189/500 [2:17:55<50:59,  9.84s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 190/500 [2:17:57<38:59,  7.55s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.043, 'grad_norm': 1.0914276838302612, 'learning_rate': 3.204081632653062e-06, 'epoch': 3.65}\u001b[0m\n",
      "\u001b[34m38%|███▊      | 190/500 [2:17:57<38:59,  7.55s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 2/14 [00:03<00:20,  1.71s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██▏       | 3/14 [00:07<00:28,  2.57s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 4/14 [00:11<00:31,  3.19s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 5/14 [00:15<00:30,  3.34s/it]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 6/14 [00:19<00:30,  3.78s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 7/14 [00:24<00:27,  3.97s/it]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 8/14 [00:33<00:34,  5.81s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 9/14 [00:43<00:35,  7.05s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 10/14 [00:47<00:23,  6.00s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 11/14 [00:50<00:15,  5.26s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 12/14 [00:54<00:09,  4.84s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 13/14 [00:58<00:04,  4.57s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [01:01<00:00,  3.92s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.22171178460121155, 'eval_cer': 18.35043409629045, 'eval_runtime': 417.8127, 'eval_samples_per_second': 1.999, 'eval_steps_per_second': 0.034, 'epoch': 3.65}\u001b[0m\n",
      "\u001b[34m38%|███▊      | 190/500 [2:24:55<38:59,  7.55s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [06:52<00:00,  3.92s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m38%|███▊      | 191/500 [2:25:14<11:41:55, 136.30s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 192/500 [2:25:16<8:13:10, 96.07s/it]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 193/500 [2:25:18<5:47:30, 67.92s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 194/500 [2:25:20<4:05:49, 48.20s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 195/500 [2:25:23<2:54:52, 34.40s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 196/500 [2:25:25<2:05:22, 24.74s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 197/500 [2:25:27<1:30:49, 17.98s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 198/500 [2:25:29<1:06:43, 13.26s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 199/500 [2:25:31<49:50,  9.94s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 200/500 [2:25:34<38:03,  7.61s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0451, 'grad_norm': 1.0367082357406616, 'learning_rate': 3.1020408163265307e-06, 'epoch': 3.85}\u001b[0m\n",
      "\u001b[34m40%|████      | 200/500 [2:25:34<38:03,  7.61s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 2/14 [00:03<00:20,  1.70s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██▏       | 3/14 [00:07<00:28,  2.56s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 4/14 [00:17<00:52,  5.28s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 5/14 [00:20<00:42,  4.69s/it]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 6/14 [00:25<00:37,  4.68s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 7/14 [00:29<00:32,  4.58s/it]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 8/14 [00:39<00:37,  6.23s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 9/14 [00:49<00:36,  7.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 10/14 [00:52<00:24,  6.19s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 11/14 [00:56<00:16,  5.39s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 12/14 [01:00<00:09,  4.93s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 13/14 [01:10<00:06,  6.46s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [01:12<00:00,  5.26s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.21910111606121063, 'eval_cer': 21.888976585109184, 'eval_runtime': 434.4022, 'eval_samples_per_second': 1.922, 'eval_steps_per_second': 0.032, 'epoch': 3.85}\u001b[0m\n",
      "\u001b[34m40%|████      | 200/500 [2:32:48<38:03,  7.61s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [07:09<00:00,  5.26s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m40%|████      | 201/500 [2:33:05<11:40:57, 140.66s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 202/500 [2:33:07<8:12:22, 99.13s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 203/500 [2:33:09<5:46:46, 70.06s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 204/500 [2:33:11<4:05:12, 49.71s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 205/500 [2:33:14<2:54:22, 35.47s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 206/500 [2:33:16<2:05:00, 25.51s/it]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 207/500 [2:33:18<1:30:28, 18.53s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 208/500 [2:33:19<1:04:31, 13.26s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 209/500 [2:33:23<50:05, 10.33s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 210/500 [2:33:25<38:07,  7.89s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0317, 'grad_norm': 1.0754718780517578, 'learning_rate': 3e-06, 'epoch': 4.04}\u001b[0m\n",
      "\u001b[34m42%|████▏     | 210/500 [2:33:25<38:07,  7.89s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 2/14 [00:03<00:20,  1.71s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██▏       | 3/14 [00:13<00:56,  5.09s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 4/14 [00:23<01:08,  6.86s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 5/14 [00:26<00:51,  5.72s/it]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 6/14 [00:31<00:43,  5.39s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 7/14 [00:35<00:35,  5.05s/it]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 8/14 [00:45<00:39,  6.55s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 9/14 [00:55<00:37,  7.55s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 10/14 [00:58<00:25,  6.34s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 11/14 [01:02<00:16,  5.49s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 12/14 [01:06<00:10,  5.00s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 13/14 [01:16<00:06,  6.51s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [01:18<00:00,  5.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.22065208852291107, 'eval_cer': 22.822941331228623, 'eval_runtime': 436.0113, 'eval_samples_per_second': 1.915, 'eval_steps_per_second': 0.032, 'epoch': 4.04}\u001b[0m\n",
      "\u001b[34m42%|████▏     | 210/500 [2:40:41<38:07,  7.89s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [07:11<00:00,  5.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m#015                                               #033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m42%|████▏     | 211/500 [2:40:59<11:23:06, 141.82s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 212/500 [2:41:01<7:59:44, 99.95s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 213/500 [2:41:04<5:37:50, 70.63s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 214/500 [2:41:06<3:58:49, 50.10s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 215/500 [2:41:08<2:49:45, 35.74s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 216/500 [2:41:10<2:01:34, 25.68s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 217/500 [2:41:12<1:28:00, 18.66s/it]\u001b[0m\n",
      "\u001b[34m44%|████▎     | 218/500 [2:41:15<1:04:35, 13.74s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 219/500 [2:41:17<48:30, 10.36s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 220/500 [2:41:19<36:59,  7.93s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0249, 'grad_norm': 0.6881209015846252, 'learning_rate': 2.8979591836734694e-06, 'epoch': 4.23}\u001b[0m\n",
      "\u001b[34m44%|████▍     | 220/500 [2:41:19<36:59,  7.93s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 2/14 [00:03<00:20,  1.72s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██▏       | 3/14 [00:07<00:28,  2.57s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 4/14 [00:11<00:32,  3.22s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 5/14 [00:15<00:30,  3.35s/it]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 6/14 [00:19<00:30,  3.79s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 7/14 [00:24<00:27,  3.97s/it]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 8/14 [00:33<00:34,  5.81s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 9/14 [00:37<00:25,  5.15s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 10/14 [00:41<00:18,  4.68s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 11/14 [00:44<00:13,  4.34s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 12/14 [00:48<00:08,  4.20s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 13/14 [00:58<00:05,  5.97s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [01:01<00:00,  4.92s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.2252298891544342, 'eval_cer': 17.876874506708763, 'eval_runtime': 423.1936, 'eval_samples_per_second': 1.973, 'eval_steps_per_second': 0.033, 'epoch': 4.23}\u001b[0m\n",
      "\u001b[34m44%|████▍     | 220/500 [2:48:23<36:59,  7.93s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [06:58<00:00,  4.92s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m44%|████▍     | 221/500 [2:48:39<10:39:35, 137.55s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 222/500 [2:48:42<7:29:15, 96.96s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 223/500 [2:48:44<5:16:25, 68.54s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 224/500 [2:48:46<3:43:45, 48.64s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 225/500 [2:48:48<2:39:05, 34.71s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 226/500 [2:48:51<1:54:00, 24.96s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 227/500 [2:48:53<1:22:32, 18.14s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 228/500 [2:48:55<1:00:46, 13.41s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 229/500 [2:48:57<45:24, 10.05s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 230/500 [2:49:00<34:38,  7.70s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.025, 'grad_norm': 0.786461591720581, 'learning_rate': 2.795918367346939e-06, 'epoch': 4.42}\u001b[0m\n",
      "\u001b[34m46%|████▌     | 230/500 [2:49:00<34:38,  7.70s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 2/14 [00:03<00:20,  1.73s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██▏       | 3/14 [00:07<00:28,  2.58s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 4/14 [00:11<00:32,  3.23s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 5/14 [00:15<00:30,  3.36s/it]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 6/14 [00:19<00:30,  3.79s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 7/14 [00:24<00:27,  3.96s/it]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 8/14 [00:27<00:22,  3.83s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 9/14 [00:31<00:18,  3.78s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 10/14 [00:34<00:14,  3.73s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 11/14 [00:38<00:11,  3.69s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 12/14 [00:42<00:07,  3.75s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 13/14 [00:46<00:03,  3.82s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [00:48<00:00,  3.42s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.2308848798274994, 'eval_cer': 14.811891607471717, 'eval_runtime': 409.1851, 'eval_samples_per_second': 2.041, 'eval_steps_per_second': 0.034, 'epoch': 4.42}\u001b[0m\n",
      "\u001b[34m46%|████▌     | 230/500 [2:55:49<34:38,  7.70s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [06:44<00:00,  3.42s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m46%|████▌     | 231/500 [2:56:10<10:03:08, 134.53s/it]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 232/500 [2:56:12<7:03:37, 94.84s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 233/500 [2:56:15<4:58:34, 67.10s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 234/500 [2:56:17<3:31:11, 47.64s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 235/500 [2:56:19<2:30:25, 34.06s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 236/500 [2:56:22<1:48:02, 24.55s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 237/500 [2:56:24<1:18:14, 17.85s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 238/500 [2:56:26<57:26, 13.16s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 239/500 [2:56:28<42:55,  9.87s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 240/500 [2:56:30<32:48,  7.57s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0243, 'grad_norm': 0.7087457180023193, 'learning_rate': 2.6938775510204086e-06, 'epoch': 4.62}\u001b[0m\n",
      "\u001b[34m48%|████▊     | 240/500 [2:56:30<32:48,  7.57s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 2/14 [00:03<00:20,  1.70s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██▏       | 3/14 [00:07<00:27,  2.54s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 4/14 [00:11<00:32,  3.20s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 5/14 [00:15<00:30,  3.34s/it]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 6/14 [00:19<00:30,  3.76s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 7/14 [00:23<00:27,  3.94s/it]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 8/14 [00:27<00:22,  3.81s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 9/14 [00:31<00:18,  3.77s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 10/14 [00:34<00:14,  3.73s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 11/14 [00:38<00:11,  3.68s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 12/14 [00:42<00:07,  3.74s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 13/14 [00:46<00:03,  3.80s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [00:48<00:00,  3.39s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.2298326939344406, 'eval_cer': 14.693501710076296, 'eval_runtime': 412.2192, 'eval_samples_per_second': 2.026, 'eval_steps_per_second': 0.034, 'epoch': 4.62}\u001b[0m\n",
      "\u001b[34m48%|████▊     | 240/500 [3:03:23<32:48,  7.57s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [06:47<00:00,  3.39s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m48%|████▊     | 241/500 [3:03:37<9:35:45, 133.38s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 242/500 [3:03:40<6:44:22, 94.04s/it]\u001b[0m\n",
      "\u001b[34m49%|████▊     | 243/500 [3:03:42<4:44:49, 66.50s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 244/500 [3:03:44<3:21:49, 47.30s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 245/500 [3:03:47<2:23:34, 33.78s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 246/500 [3:03:49<1:42:57, 24.32s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 247/500 [3:03:51<1:14:36, 17.70s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 248/500 [3:03:53<54:50, 13.06s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 249/500 [3:03:56<41:00,  9.80s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 250/500 [3:03:58<31:23,  7.53s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0291, 'grad_norm': 0.9196205139160156, 'learning_rate': 2.591836734693878e-06, 'epoch': 4.81}\u001b[0m\n",
      "\u001b[34m50%|█████     | 250/500 [3:03:58<31:23,  7.53s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 2/14 [00:03<00:20,  1.71s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██▏       | 3/14 [00:07<00:28,  2.56s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 4/14 [00:11<00:32,  3.22s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 5/14 [00:21<00:49,  5.51s/it]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 6/14 [00:25<00:41,  5.23s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 7/14 [00:30<00:34,  4.95s/it]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 8/14 [00:40<00:38,  6.48s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 9/14 [00:43<00:28,  5.61s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 10/14 [00:52<00:26,  6.63s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 11/14 [00:56<00:17,  5.70s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 12/14 [01:00<00:10,  5.15s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 13/14 [01:10<00:06,  6.60s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [01:12<00:00,  5.35s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.22513249516487122, 'eval_cer': 23.283346487766376, 'eval_runtime': 434.0124, 'eval_samples_per_second': 1.924, 'eval_steps_per_second': 0.032, 'epoch': 4.81}\u001b[0m\n",
      "\u001b[34m50%|█████     | 250/500 [3:11:12<31:23,  7.53s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [07:09<00:00,  5.35s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m50%|█████     | 251/500 [3:11:27<9:41:13, 140.06s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 252/500 [3:11:29<6:48:02, 98.72s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 253/500 [3:11:32<4:47:13, 69.77s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 254/500 [3:11:34<3:23:00, 49.51s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 255/500 [3:11:36<2:24:15, 35.33s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 256/500 [3:11:38<1:43:17, 25.40s/it]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 257/500 [3:11:40<1:14:41, 18.44s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 258/500 [3:11:43<54:46, 13.58s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 259/500 [3:11:45<40:52, 10.17s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 260/500 [3:11:46<29:38,  7.41s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0205, 'grad_norm': 0.6768463850021362, 'learning_rate': 2.489795918367347e-06, 'epoch': 5.0}\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 260/500 [3:11:46<29:38,  7.41s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 2/14 [00:03<00:20,  1.71s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██▏       | 3/14 [00:07<00:28,  2.57s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 4/14 [00:11<00:32,  3.21s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 5/14 [00:15<00:29,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 6/14 [00:19<00:30,  3.77s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 7/14 [00:24<00:27,  3.95s/it]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 8/14 [00:33<00:34,  5.81s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 9/14 [00:37<00:25,  5.15s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 10/14 [00:46<00:25,  6.26s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 11/14 [00:49<00:16,  5.44s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 12/14 [00:53<00:09,  4.93s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 13/14 [00:57<00:04,  4.62s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [01:00<00:00,  3.96s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.22463200986385345, 'eval_cer': 19.021310181531177, 'eval_runtime': 417.588, 'eval_samples_per_second': 2.0, 'eval_steps_per_second': 0.034, 'epoch': 5.0}\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 260/500 [3:18:43<29:38,  7.41s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [06:52<00:00,  3.96s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 261/500 [3:19:06<9:06:31, 137.20s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 262/500 [3:19:08<6:23:35, 96.70s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 263/500 [3:19:10<4:30:00, 68.36s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 264/500 [3:19:13<3:10:49, 48.52s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 265/500 [3:19:15<2:15:39, 34.64s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 266/500 [3:19:17<1:37:11, 24.92s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 267/500 [3:19:19<1:10:20, 18.11s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 268/500 [3:19:21<51:35, 13.34s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 269/500 [3:19:24<38:32, 10.01s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 270/500 [3:19:26<29:24,  7.67s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0146, 'grad_norm': 0.38181212544441223, 'learning_rate': 2.3877551020408166e-06, 'epoch': 5.19}\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 270/500 [3:19:26<29:24,  7.67s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 2/14 [00:03<00:20,  1.72s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██▏       | 3/14 [00:07<00:28,  2.58s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 4/14 [00:11<00:32,  3.22s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 5/14 [00:15<00:30,  3.37s/it]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 6/14 [00:19<00:30,  3.80s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 7/14 [00:24<00:27,  3.97s/it]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 8/14 [00:27<00:23,  3.87s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 9/14 [00:31<00:19,  3.82s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 10/14 [00:41<00:22,  5.62s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 11/14 [00:44<00:14,  5.00s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 12/14 [00:48<00:09,  4.65s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 13/14 [00:52<00:04,  4.45s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [00:55<00:00,  3.84s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.22635337710380554, 'eval_cer': 17.298079452775585, 'eval_runtime': 415.2914, 'eval_samples_per_second': 2.011, 'eval_steps_per_second': 0.034, 'epoch': 5.19}\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 270/500 [3:26:21<29:24,  7.67s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [06:50<00:00,  3.84s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 271/500 [3:26:41<8:38:06, 135.75s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 272/500 [3:26:43<6:03:36, 95.69s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 273/500 [3:26:45<4:15:55, 67.65s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 274/500 [3:26:47<3:00:51, 48.01s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 275/500 [3:26:49<2:08:33, 34.28s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 276/500 [3:26:52<1:32:05, 24.67s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 277/500 [3:26:54<1:06:37, 17.93s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 278/500 [3:26:56<48:52, 13.21s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 279/500 [3:26:58<36:29,  9.91s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 280/500 [3:27:00<27:51,  7.60s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0204, 'grad_norm': 1.3479516506195068, 'learning_rate': 2.285714285714286e-06, 'epoch': 5.38}\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 280/500 [3:27:00<27:51,  7.60s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 2/14 [00:03<00:20,  1.71s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██▏       | 3/14 [00:07<00:28,  2.57s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 4/14 [00:11<00:32,  3.20s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 5/14 [00:15<00:30,  3.34s/it]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 6/14 [00:19<00:30,  3.78s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 7/14 [00:24<00:27,  3.96s/it]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 8/14 [00:27<00:22,  3.83s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 9/14 [00:31<00:18,  3.79s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 10/14 [00:40<00:21,  5.37s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 11/14 [00:43<00:14,  4.82s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 12/14 [00:47<00:09,  4.53s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 13/14 [00:51<00:04,  4.36s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [00:54<00:00,  3.78s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.22886991500854492, 'eval_cer': 17.1928439884241, 'eval_runtime': 414.6924, 'eval_samples_per_second': 2.014, 'eval_steps_per_second': 0.034, 'epoch': 5.38}\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 280/500 [3:33:55<27:51,  7.60s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [06:49<00:00,  3.78s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 281/500 [3:34:12<8:12:17, 134.88s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 282/500 [3:34:15<5:45:28, 95.09s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 283/500 [3:34:17<4:03:07, 67.22s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 284/500 [3:34:19<2:51:48, 47.72s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 285/500 [3:34:21<2:02:04, 34.07s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 286/500 [3:34:23<1:27:25, 24.51s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 287/500 [3:34:26<1:03:15, 17.82s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 288/500 [3:34:28<46:25, 13.14s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 289/500 [3:34:30<34:41,  9.86s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 290/500 [3:34:32<26:29,  7.57s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0137, 'grad_norm': 0.8745166063308716, 'learning_rate': 2.1836734693877553e-06, 'epoch': 5.58}\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 290/500 [3:34:32<26:29,  7.57s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 2/14 [00:03<00:20,  1.70s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██▏       | 3/14 [00:07<00:28,  2.55s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 4/14 [00:11<00:31,  3.19s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 5/14 [00:14<00:29,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 6/14 [00:19<00:30,  3.76s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 7/14 [00:23<00:27,  3.95s/it]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 8/14 [00:33<00:34,  5.78s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 9/14 [00:37<00:25,  5.14s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 10/14 [00:46<00:24,  6.22s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 11/14 [00:49<00:16,  5.41s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 12/14 [00:53<00:09,  4.94s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 13/14 [00:57<00:04,  4.64s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [01:00<00:00,  4.00s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.23129676282405853, 'eval_cer': 18.652986056300975, 'eval_runtime': 419.1494, 'eval_samples_per_second': 1.992, 'eval_steps_per_second': 0.033, 'epoch': 5.58}\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 290/500 [3:41:31<26:29,  7.57s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [06:54<00:00,  4.00s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 291/500 [3:41:52<7:57:56, 137.21s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 292/500 [3:41:54<5:35:16, 96.71s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 293/500 [3:41:56<3:55:51, 68.36s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 294/500 [3:41:59<2:46:35, 48.52s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 295/500 [3:42:01<1:58:18, 34.63s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 296/500 [3:42:03<1:24:41, 24.91s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 297/500 [3:42:05<1:01:14, 18.10s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 298/500 [3:42:08<44:54, 13.34s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 299/500 [3:42:10<33:30, 10.00s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 300/500 [3:42:12<25:32,  7.66s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0131, 'grad_norm': 0.6439105272293091, 'learning_rate': 2.0816326530612247e-06, 'epoch': 5.77}\u001b[0m\n",
      "\u001b[34m60%|██████    | 300/500 [3:42:12<25:32,  7.66s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 2/14 [00:03<00:20,  1.70s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██▏       | 3/14 [00:07<00:28,  2.56s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 4/14 [00:11<00:31,  3.20s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 5/14 [00:15<00:29,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 6/14 [00:19<00:30,  3.77s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 7/14 [00:24<00:27,  3.96s/it]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 8/14 [00:27<00:22,  3.83s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 9/14 [00:31<00:19,  3.80s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 10/14 [00:40<00:21,  5.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 11/14 [00:43<00:14,  4.78s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 12/14 [00:47<00:09,  4.50s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 13/14 [00:51<00:04,  4.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [00:53<00:00,  3.76s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.23118196427822113, 'eval_cer': 17.324388318863456, 'eval_runtime': 411.8314, 'eval_samples_per_second': 2.028, 'eval_steps_per_second': 0.034, 'epoch': 5.77}\u001b[0m\n",
      "\u001b[34m60%|██████    | 300/500 [3:49:04<25:32,  7.66s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [06:46<00:00,  3.76s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m60%|██████    | 301/500 [3:49:26<7:29:53, 135.65s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 302/500 [3:49:28<5:15:32, 95.62s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 303/500 [3:49:31<3:41:57, 67.60s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 304/500 [3:49:33<2:36:45, 47.99s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 305/500 [3:49:35<1:51:19, 34.25s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 306/500 [3:49:37<1:19:40, 24.64s/it]\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 307/500 [3:49:40<57:38, 17.92s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 308/500 [3:49:42<42:16, 13.21s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 309/500 [3:49:44<31:33,  9.91s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 310/500 [3:49:46<24:04,  7.60s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.017, 'grad_norm': 1.0434707403182983, 'learning_rate': 1.979591836734694e-06, 'epoch': 5.96}\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 310/500 [3:49:46<24:04,  7.60s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 2/14 [00:03<00:20,  1.70s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██▏       | 3/14 [00:07<00:28,  2.55s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 4/14 [00:11<00:31,  3.19s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 5/14 [00:15<00:29,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 6/14 [00:19<00:30,  3.77s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 7/14 [00:24<00:27,  3.96s/it]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 8/14 [00:27<00:22,  3.83s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 9/14 [00:31<00:18,  3.79s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 10/14 [00:34<00:14,  3.75s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 11/14 [00:38<00:11,  3.69s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 12/14 [00:42<00:07,  3.75s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 13/14 [00:46<00:03,  3.82s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [00:48<00:00,  3.40s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.23290666937828064, 'eval_cer': 14.86450933964746, 'eval_runtime': 405.6536, 'eval_samples_per_second': 2.058, 'eval_steps_per_second': 0.035, 'epoch': 5.96}\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 310/500 [3:56:32<24:04,  7.60s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [06:40<00:00,  3.40s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 311/500 [3:56:55<7:01:45, 133.89s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 312/500 [3:56:56<4:54:33, 94.01s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 313/500 [3:56:59<3:28:20, 66.85s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 314/500 [3:57:01<2:27:07, 47.46s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 315/500 [3:57:04<1:44:28, 33.88s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 316/500 [3:57:06<1:14:45, 24.38s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 317/500 [3:57:08<54:04, 17.73s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 318/500 [3:57:10<39:38, 13.07s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 319/500 [3:57:12<29:36,  9.81s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 320/500 [3:57:15<22:36,  7.53s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0129, 'grad_norm': 0.6959790587425232, 'learning_rate': 1.8775510204081634e-06, 'epoch': 6.15}\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 320/500 [3:57:15<22:36,  7.53s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 2/14 [00:03<00:20,  1.70s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██▏       | 3/14 [00:07<00:28,  2.56s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 4/14 [00:11<00:31,  3.20s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 5/14 [00:15<00:30,  3.34s/it]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 6/14 [00:19<00:30,  3.78s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 7/14 [00:24<00:27,  3.97s/it]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 8/14 [00:27<00:22,  3.83s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 9/14 [00:31<00:18,  3.79s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 10/14 [00:34<00:14,  3.72s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 11/14 [00:38<00:11,  3.67s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 12/14 [00:42<00:07,  3.74s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 13/14 [00:46<00:03,  3.80s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [00:48<00:00,  3.39s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.2355898767709732, 'eval_cer': 14.654038410944489, 'eval_runtime': 408.2155, 'eval_samples_per_second': 2.045, 'eval_steps_per_second': 0.034, 'epoch': 6.15}\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 320/500 [4:04:03<22:36,  7.53s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [06:43<00:00,  3.39s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 321/500 [4:04:27<6:42:57, 135.07s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 322/500 [4:04:30<4:42:27, 95.21s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 323/500 [4:04:32<3:18:35, 67.32s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 324/500 [4:04:34<2:20:10, 47.79s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 325/500 [4:04:36<1:39:31, 34.12s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 326/500 [4:04:38<1:11:13, 24.56s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 327/500 [4:04:41<51:29, 17.86s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 328/500 [4:04:43<37:44, 13.16s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 329/500 [4:04:45<28:09,  9.88s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 330/500 [4:04:47<21:28,  7.58s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0111, 'grad_norm': 0.49702808260917664, 'learning_rate': 1.7755102040816327e-06, 'epoch': 6.35}\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 330/500 [4:04:47<21:28,  7.58s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 2/14 [00:03<00:20,  1.70s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██▏       | 3/14 [00:07<00:28,  2.55s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 4/14 [00:11<00:31,  3.19s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 5/14 [00:14<00:29,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 6/14 [00:19<00:30,  3.78s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 7/14 [00:24<00:27,  3.98s/it]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 8/14 [00:33<00:34,  5.80s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 9/14 [00:37<00:25,  5.15s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 10/14 [00:46<00:25,  6.34s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 11/14 [00:50<00:16,  5.49s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 12/14 [00:53<00:10,  5.00s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 13/14 [00:58<00:04,  4.71s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [01:00<00:00,  4.05s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.2354041486978531, 'eval_cer': 17.903183372796633, 'eval_runtime': 419.2654, 'eval_samples_per_second': 1.992, 'eval_steps_per_second': 0.033, 'epoch': 6.35}\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 330/500 [4:11:47<21:28,  7.58s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [06:54<00:00,  4.05s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 331/500 [4:12:06<6:25:51, 136.99s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 332/500 [4:12:08<4:30:23, 96.57s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 333/500 [4:12:11<3:10:01, 68.27s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 334/500 [4:12:13<2:14:02, 48.45s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 335/500 [4:12:15<1:35:05, 34.58s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 336/500 [4:12:17<1:07:58, 24.87s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 337/500 [4:12:20<49:06, 18.07s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 338/500 [4:12:22<35:57, 13.32s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 339/500 [4:12:24<26:49, 10.00s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 340/500 [4:12:26<20:25,  7.66s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0117, 'grad_norm': 0.6349603533744812, 'learning_rate': 1.6734693877551023e-06, 'epoch': 6.54}\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 340/500 [4:12:26<20:25,  7.66s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 2/14 [00:03<00:20,  1.72s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██▏       | 3/14 [00:07<00:28,  2.57s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 4/14 [00:11<00:32,  3.21s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 5/14 [00:15<00:29,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 6/14 [00:19<00:30,  3.77s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 7/14 [00:24<00:27,  3.96s/it]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 8/14 [00:33<00:34,  5.76s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 9/14 [00:37<00:25,  5.12s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 10/14 [00:47<00:26,  6.55s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 11/14 [00:50<00:16,  5.64s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 12/14 [00:54<00:10,  5.08s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 13/14 [00:58<00:04,  4.78s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [01:01<00:00,  4.10s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.23412461578845978, 'eval_cer': 18.652986056300975, 'eval_runtime': 420.1059, 'eval_samples_per_second': 1.988, 'eval_steps_per_second': 0.033, 'epoch': 6.54}\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 340/500 [4:19:26<20:25,  7.66s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [06:55<00:00,  4.10s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 341/500 [4:19:45<6:03:20, 137.11s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 342/500 [4:19:48<4:14:30, 96.65s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▊   | 343/500 [4:19:50<2:58:46, 68.32s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 344/500 [4:19:52<2:06:05, 48.49s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 345/500 [4:19:54<1:29:25, 34.61s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 346/500 [4:19:57<1:03:53, 24.89s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 347/500 [4:19:59<46:08, 18.10s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 348/500 [4:20:01<33:46, 13.33s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 349/500 [4:20:03<25:10, 10.00s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 350/500 [4:20:05<19:10,  7.67s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0094, 'grad_norm': 0.2960285246372223, 'learning_rate': 1.5714285714285714e-06, 'epoch': 6.73}\u001b[0m\n",
      "\u001b[34m70%|███████   | 350/500 [4:20:05<19:10,  7.67s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 2/14 [00:03<00:20,  1.70s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██▏       | 3/14 [00:07<00:28,  2.55s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 4/14 [00:11<00:31,  3.19s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 5/14 [00:14<00:29,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 6/14 [00:19<00:30,  3.77s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 7/14 [00:23<00:27,  3.93s/it]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 8/14 [00:33<00:34,  5.75s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 9/14 [00:37<00:25,  5.13s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 10/14 [00:47<00:26,  6.55s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 11/14 [00:50<00:16,  5.64s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 12/14 [00:54<00:10,  5.10s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 13/14 [00:58<00:04,  4.79s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [01:06<00:00,  5.78s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.23467016220092773, 'eval_cer': 20.284135753749013, 'eval_runtime': 430.0937, 'eval_samples_per_second': 1.941, 'eval_steps_per_second': 0.033, 'epoch': 6.73}\u001b[0m\n",
      "\u001b[34m70%|███████   | 350/500 [4:27:16<19:10,  7.67s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [06:59<00:00,  5.78s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m70%|███████   | 351/500 [4:27:39<5:50:50, 141.28s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 352/500 [4:27:41<4:05:35, 99.56s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 353/500 [4:27:43<2:52:23, 70.36s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 354/500 [4:27:45<2:01:28, 49.92s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 355/500 [4:27:47<1:26:02, 35.60s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 356/500 [4:27:50<1:01:24, 25.59s/it]\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 357/500 [4:27:52<44:16, 18.58s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 358/500 [4:27:54<32:20, 13.67s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 359/500 [4:27:56<24:02, 10.23s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 360/500 [4:27:58<18:15,  7.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0106, 'grad_norm': 0.30945226550102234, 'learning_rate': 1.469387755102041e-06, 'epoch': 6.92}\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 360/500 [4:27:58<18:15,  7.83s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 2/14 [00:03<00:20,  1.71s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██▏       | 3/14 [00:13<00:55,  5.09s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 4/14 [00:17<00:47,  4.77s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 5/14 [00:27<00:58,  6.50s/it]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 6/14 [00:31<00:47,  5.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 7/14 [00:36<00:37,  5.37s/it]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 8/14 [00:46<00:40,  6.82s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 9/14 [00:49<00:29,  5.85s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 10/14 [00:58<00:26,  6.62s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 11/14 [01:01<00:17,  5.69s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 12/14 [01:11<00:13,  6.95s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 13/14 [01:21<00:07,  7.87s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [01:30<00:00,  8.09s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.23650622367858887, 'eval_cer': 29.99210734017364, 'eval_runtime': 451.5599, 'eval_samples_per_second': 1.849, 'eval_steps_per_second': 0.031, 'epoch': 6.92}\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 360/500 [4:35:30<18:15,  7.83s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [07:20<00:00,  8.09s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 361/500 [4:35:50<5:40:17, 146.89s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 362/500 [4:35:52<3:58:00, 103.48s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 363/500 [4:35:54<2:46:55, 73.10s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 364/500 [4:35:55<1:56:39, 51.47s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 365/500 [4:35:59<1:23:22, 37.06s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 366/500 [4:36:01<59:24, 26.60s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 367/500 [4:36:03<42:45, 19.29s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▎  | 368/500 [4:36:05<31:09, 14.16s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 369/500 [4:36:08<23:06, 10.58s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 370/500 [4:36:10<17:28,  8.06s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0089, 'grad_norm': 0.2889311909675598, 'learning_rate': 1.3673469387755104e-06, 'epoch': 7.12}\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 370/500 [4:36:10<17:28,  8.06s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 2/14 [00:03<00:20,  1.70s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██▏       | 3/14 [00:13<00:55,  5.06s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 4/14 [00:22<01:08,  6.82s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 5/14 [00:31<01:05,  7.25s/it]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 6/14 [00:35<00:50,  6.36s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 7/14 [00:39<00:39,  5.69s/it]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 8/14 [00:49<00:41,  6.97s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 9/14 [00:59<00:39,  7.85s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 10/14 [01:07<00:31,  7.97s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 11/14 [01:17<00:25,  8.52s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 12/14 [01:27<00:17,  8.93s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 13/14 [01:37<00:09,  9.24s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [01:45<00:00,  9.05s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.23813578486442566, 'eval_cer': 34.7934754012102, 'eval_runtime': 465.3537, 'eval_samples_per_second': 1.794, 'eval_steps_per_second': 0.03, 'epoch': 7.12}\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 370/500 [4:43:55<17:28,  8.06s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 14/14 [07:34<00:00,  9.05s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 371/500 [4:44:13<5:23:38, 150.53s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 372/500 [4:44:15<3:46:14, 106.05s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 373/500 [4:44:17<2:38:31, 74.90s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 374/500 [4:44:19<1:51:29, 53.09s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 375/500 [4:44:22<1:18:48, 37.83s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 376/500 [4:44:24<56:06, 27.15s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 377/500 [4:44:26<40:18, 19.66s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 378/500 [4:44:28<29:19, 14.42s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 379/500 [4:44:30<21:41, 10.76s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 380/500 [4:44:33<16:22,  8.19s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0081, 'grad_norm': 0.30062130093574524, 'learning_rate': 1.2653061224489795e-06, 'epoch': 7.31}\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 380/500 [4:44:33<16:22,  8.19s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/14 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 2/14 [00:03<00:20,  1.70s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██▏       | 3/14 [00:13<00:55,  5.07s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▊       | 4/14 [00:21<01:03,  6.39s/it]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 5/14 [00:29<01:02,  6.97s/it]#033[A\u001b[0m\n",
      "\u001b[34m43%|████▎     | 6/14 [00:34<00:49,  6.18s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 7/14 [00:38<00:38,  5.57s/it]#033[A\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 8/14 [00:48<00:41,  6.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 9/14 [00:52<00:29,  5.89s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 10/14 [01:01<00:27,  6.86s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 11/14 [01:04<00:17,  5.85s/it]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 12/14 [01:14<00:14,  7.06s/it]#033[A\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 13/14 [01:24<00:07,  7.95s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 14/14 [01:27<00:00,  6.31s/it]#033[A\u001b[0m\n",
      "\n",
      "2024-06-20 12:49:38 Stopping - Stopping the training job\n",
      "2024-06-20 12:49:38 Uploading - Uploading generated training model\n",
      "2024-06-20 12:49:38 Stopped - Training job stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:Job ended with status 'Stopped' rather than 'Completed'. This could mean the job timed out or stopped early for some other reason: Consider checking whether it completed as you expect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training seconds: 18107\n",
      "Billable seconds: 18107\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "region = sagemaker_session.boto_session.region_name\n",
    "\n",
    "image_uri = f'763104351884.dkr.ecr.{region}.amazonaws.com/pytorch-training:2.3.0-gpu-py311-cu121-ubuntu20.04-sagemaker'\n",
    "\n",
    "instance_count = 1\n",
    "# instance_type = 'ml.g5.48xlarge'\n",
    "instance_type = 'ml.p4d.24xlarge' # 8xA100 40G\n",
    "\n",
    "checkpoint_s3_uri = f's3://{bucket}/checkpoints/whisper_checkpoint_v0'\n",
    "checkpoint_local_path = \"/opt/ml/checkpoints\"\n",
    "\n",
    "environment = {\n",
    "    'NODE_NUMBER': str(instance_count),\n",
    "    'TRAIN_DATA_PATH': f's3://{bucket}/{prefix_data}/train/',\n",
    "    'VALID_DATA_PATH': f's3://{bucket}/{prefix_data}/valid/',\n",
    "    'PRETRAINED_MODEL_S3_PATH': f\"{input_model}/\",\n",
    "    'OUTPUT_MODEL_S3_PATH': checkpoint_s3_uri, # destination\n",
    "}\n",
    "\n",
    "estimator = Estimator(role=role,\n",
    "                      entry_point='entry.py',\n",
    "                      source_dir='./sm_scripts',\n",
    "                      base_job_name='whisper-launch',\n",
    "                      instance_count=instance_count,\n",
    "                      instance_type=instance_type,\n",
    "                      volume_size=1024, # in GB\n",
    "                      image_uri=image_uri,\n",
    "                      environment=environment,\n",
    "                      max_run=3*24*3600, #任务最大存续时间，默认2day，需要提交ticket提升quota最大28天\n",
    "                      disable_profiler=True,\n",
    "                      debugger_hook_config=False,\n",
    "                      checkpoint_s3_uri=checkpoint_s3_uri,\n",
    "                      checkpoint_local_path=checkpoint_local_path)\n",
    "\n",
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4124e1c3-9f2f-4c6f-8f49-43311180565a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba8b48e-fa8b-45f1-8b33-4b597d36420e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_whisper",
   "language": "python",
   "name": "conda_whisper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
