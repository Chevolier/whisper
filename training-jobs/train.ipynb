{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a473fe8-ef6b-49a4-b7d2-d96600d9163d",
   "metadata": {},
   "source": [
    "## 1. Upload data to S3\n",
    "Here I use pokeman dataset as an example, which is composed of 833 image-text pairs. To scale up, you can just process your data into the same format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60a3ee2c-be39-46cf-ae76-1ecfc52e0e24",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f972fb3-9c30-4c5c-adea-36ed78e38d4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import datetime\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d4023f7-0ad4-460d-96f1-db5710f05d87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44e6697e-5363-4614-9371-284ec1b65fd4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-west-2-452145973879/datasets/midea_data/custom_data_v1\n"
     ]
    }
   ],
   "source": [
    "prefix_data = 'datasets/midea_data/custom_data_v1'\n",
    "\n",
    "local_data_path = \"../data/custom_data_v1\"\n",
    "input_data = sagemaker_session.upload_data(path=local_data_path, key_prefix=prefix_data)\n",
    "print(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc31ccb1-e849-43e0-85eb-9dd8b8984fa5",
   "metadata": {},
   "source": [
    "## 2. Upload pretrained models to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35dcff89-e473-497b-bc7a-4e333fbcc706",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3\n"
     ]
    }
   ],
   "source": [
    "prefix_model = 'models/whisper-large-v3'\n",
    "\n",
    "local_model_path = \"/home/ec2-user/SageMaker/efs/Models/whisper-large-v3\"\n",
    "input_model = sagemaker_session.upload_data(path=local_model_path, key_prefix=prefix_model)\n",
    "print(input_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417bb61d-6527-4707-9cbb-185c89b51008",
   "metadata": {},
   "source": [
    "## 3. Start a training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a06ebc-ab38-48b6-9e9e-9c3f0145440e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: whisper-launch-2024-06-07-13-25-38-949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-07 13:25:41 Starting - Starting the training job...\n",
      "2024-06-07 13:25:49 Pending - Training job waiting for capacity...................................................................................................................................................................................................\n",
      "2024-06-07 13:58:48 Pending - Preparing the instances for training...........................\n",
      "2024-06-07 14:03:10 Downloading - Downloading input data...\n",
      "2024-06-07 14:03:40 Downloading - Downloading the training image...............\n",
      "2024-06-07 14:06:06 Training - Training image download completed. Training in progress......\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2024-06-07 14:07:06,648 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-06-07 14:07:06,747 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-06-07 14:07:06,755 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-06-07 14:07:06,756 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-06-07 14:07:08,416 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.11 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numba in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (0.59.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (1.26.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (2.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (4.66.4)\u001b[0m\n",
      "\u001b[34mCollecting more-itertools (from -r requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34mDownloading more_itertools-10.2.0-py3-none-any.whl.metadata (34 kB)\u001b[0m\n",
      "\u001b[34mCollecting tiktoken (from -r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: triton<3,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (2.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (2.2.2)\u001b[0m\n",
      "\u001b[34mCollecting jiwer (from -r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading jiwer-3.0.4-py3-none-any.whl.metadata (2.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting evaluate (from -r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\u001b[0m\n",
      "\u001b[34mCollecting tensorboardX (from -r requirements.txt (line 11))\u001b[0m\n",
      "\u001b[34mDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting bitsandbytes (from -r requirements.txt (line 12))\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /opt/conda/lib/python3.11/site-packages (from numba->-r requirements.txt (line 1)) (0.42.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 3)) (3.14.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 3)) (4.11.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 3)) (1.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 3)) (3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 3)) (3.1.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 3)) (2024.5.0)\u001b[0m\n",
      "\u001b[34mCollecting regex>=2022.1.18 (from tiktoken->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading regex-2024.5.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.9/40.9 kB 4.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.11/site-packages (from tiktoken->-r requirements.txt (line 6)) (2.32.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 8)) (2.9.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 8)) (2024.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 8)) (2024.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click<9.0.0,>=8.1.3 in /opt/conda/lib/python3.11/site-packages (from jiwer->-r requirements.txt (line 9)) (8.1.7)\u001b[0m\n",
      "\u001b[34mCollecting rapidfuzz<4,>=3 (from jiwer->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading rapidfuzz-3.9.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mCollecting datasets>=2.0.0 (from evaluate->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading datasets-2.19.2-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill in /opt/conda/lib/python3.11/site-packages (from evaluate->-r requirements.txt (line 10)) (0.3.8)\u001b[0m\n",
      "\u001b[34mCollecting xxhash (from evaluate->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading xxhash-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from evaluate->-r requirements.txt (line 10)) (0.70.16)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from evaluate->-r requirements.txt (line 10)) (0.23.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from evaluate->-r requirements.txt (line 10)) (23.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.20 in /opt/conda/lib/python3.11/site-packages (from tensorboardX->-r requirements.txt (line 11)) (3.20.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate->-r requirements.txt (line 10)) (16.1.0)\u001b[0m\n",
      "\u001b[34mCollecting pyarrow-hotfix (from datasets>=2.0.0->evaluate->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting fsspec (from torch->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiohttp (from datasets>=2.0.0->evaluate->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading aiohttp-3.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate->-r requirements.txt (line 10)) (6.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 8)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->-r requirements.txt (line 6)) (3.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->-r requirements.txt (line 6)) (3.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->-r requirements.txt (line 6)) (1.26.18)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->-r requirements.txt (line 6)) (2024.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->-r requirements.txt (line 3)) (2.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch->-r requirements.txt (line 3)) (1.3.0)\u001b[0m\n",
      "\u001b[34mCollecting aiosignal>=1.1.2 (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 10)) (23.2.0)\u001b[0m\n",
      "\u001b[34mCollecting frozenlist>=1.1.1 (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mCollecting multidict<7.0,>=4.5 (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting yarl<2.0,>=1.0 (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\u001b[0m\n",
      "\u001b[34mDownloading more_itertools-10.2.0-py3-none-any.whl (57 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.0/57.0 kB 9.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 32.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading jiwer-3.0.4-py3-none-any.whl (21 kB)\u001b[0m\n",
      "\u001b[34mDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.1/84.1 kB 14.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 101.7/101.7 kB 20.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 119.8/119.8 MB 24.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading datasets-2.19.2-py3-none-any.whl (542 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 542.1/542.1 kB 60.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 172.0/172.0 kB 31.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading rapidfuzz-3.9.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.4/3.4 MB 124.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading regex-2024.5.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 785.0/785.0 kB 74.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading xxhash-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 194.8/194.8 kB 31.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading aiohttp-3.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 88.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\u001b[0m\n",
      "\u001b[34mDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\u001b[0m\n",
      "\u001b[34mDownloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 272.3/272.3 kB 39.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (128 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 128.7/128.7 kB 22.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (328 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 328.1/328.1 kB 47.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mInstalling collected packages: xxhash, tensorboardX, regex, rapidfuzz, pyarrow-hotfix, multidict, more-itertools, fsspec, frozenlist, yarl, tiktoken, jiwer, aiosignal, bitsandbytes, aiohttp, datasets, evaluate\u001b[0m\n",
      "\u001b[34mAttempting uninstall: fsspec\u001b[0m\n",
      "\u001b[34mFound existing installation: fsspec 2024.5.0\u001b[0m\n",
      "\u001b[34mUninstalling fsspec-2024.5.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled fsspec-2024.5.0\u001b[0m\n",
      "\u001b[34mSuccessfully installed aiohttp-3.9.5 aiosignal-1.3.1 bitsandbytes-0.43.1 datasets-2.19.2 evaluate-0.4.2 frozenlist-1.4.1 fsspec-2024.3.1 jiwer-3.0.4 more-itertools-10.2.0 multidict-6.0.5 pyarrow-hotfix-0.6 rapidfuzz-3.9.3 regex-2024.5.15 tensorboardX-2.6.2.2 tiktoken-0.7.0 xxhash-3.4.1 yarl-1.9.4\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2024-06-07 14:07:17,543 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-06-07 14:07:17,543 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-06-07 14:07:17,669 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-06-07 14:07:17,772 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-06-07 14:07:17,877 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-06-07 14:07:17,886 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.p4d.24xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.p4d.24xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": true,\n",
      "    \"job_name\": \"whisper-launch-2024-06-07-13-25-38-949\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-452145973879/whisper-launch-2024-06-07-13-25-38-949/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"entry\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 96,\n",
      "    \"num_gpus\": 8,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p4d.24xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p4d.24xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"entry.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=entry.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p4d.24xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4d.24xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.p4d.24xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4d.24xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=entry\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=96\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-452145973879/whisper-launch-2024-06-07-13-25-38-949/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.p4d.24xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4d.24xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":true,\"job_name\":\"whisper-launch-2024-06-07-13-25-38-949\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-452145973879/whisper-launch-2024-06-07-13-25-38-949/source/sourcedir.tar.gz\",\"module_name\":\"entry\",\"network_interface_name\":\"eth0\",\"num_cpus\":96,\"num_gpus\":8,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p4d.24xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4d.24xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"entry.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python311.zip:/opt/conda/lib/python3.11:/opt/conda/lib/python3.11/lib-dynload:/opt/conda/lib/python3.11/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.11 entry.py\u001b[0m\n",
      "\u001b[34m2024-06-07 14:07:17,887 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m2024-06-07 14:07:17,887 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pip in /opt/conda/lib/python3.11/site-packages (24.0)\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mCollecting git+https://github.com/huggingface/transformers.git\u001b[0m\n",
      "\u001b[34mCloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-y1pxdx2d\u001b[0m\n",
      "\u001b[34mRunning command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-y1pxdx2d\u001b[0m\n",
      "\u001b[34mResolved https://github.com/huggingface/transformers.git to commit ff689f57aa111261e6c2a506a42479d99674b123\u001b[0m\n",
      "\u001b[34mInstalling build dependencies: started\u001b[0m\n",
      "\u001b[34mInstalling build dependencies: finished with status 'done'\u001b[0m\n",
      "\u001b[34mGetting requirements to build wheel: started\u001b[0m\n",
      "\u001b[34mGetting requirements to build wheel: finished with status 'done'\u001b[0m\n",
      "\u001b[34mInstalling backend dependencies: started\u001b[0m\n",
      "\u001b[34mInstalling backend dependencies: finished with status 'done'\u001b[0m\n",
      "\u001b[34mPreparing metadata (pyproject.toml): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (pyproject.toml): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: accelerate in /opt/conda/lib/python3.11/site-packages (0.30.1)\u001b[0m\n",
      "\u001b[34mCollecting accelerate\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.31.0-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: datasets[audio] in /opt/conda/lib/python3.11/site-packages (2.19.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers==4.42.0.dev0) (3.14.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from transformers==4.42.0.dev0) (0.23.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers==4.42.0.dev0) (1.26.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers==4.42.0.dev0) (23.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers==4.42.0.dev0) (6.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers==4.42.0.dev0) (2024.5.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers==4.42.0.dev0) (2.32.2)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers<0.20,>=0.19 (from transformers==4.42.0.dev0)\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers==4.42.0.dev0) (0.4.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers==4.42.0.dev0) (4.66.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate) (5.9.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (2.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets[audio]) (16.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.11/site-packages (from datasets[audio]) (0.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets[audio]) (0.3.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets[audio]) (2.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets[audio]) (3.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from datasets[audio]) (0.70.16)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets[audio]) (2024.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets[audio]) (3.9.5)\u001b[0m\n",
      "\u001b[34mCollecting soundfile>=0.12.1 (from datasets[audio])\u001b[0m\n",
      "\u001b[34mDownloading soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl.metadata (14 kB)\u001b[0m\n",
      "\u001b[34mCollecting librosa (from datasets[audio])\u001b[0m\n",
      "\u001b[34mDownloading librosa-0.10.2.post1-py3-none-any.whl.metadata (8.6 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets[audio]) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets[audio]) (23.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets[audio]) (1.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets[audio]) (6.0.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets[audio]) (1.9.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.42.0.dev0) (4.11.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.42.0.dev0) (3.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.42.0.dev0) (3.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.42.0.dev0) (1.26.18)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.42.0.dev0) (2024.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.11/site-packages (from soundfile>=0.12.1->datasets[audio]) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\u001b[0m\n",
      "\u001b[34mCollecting audioread>=2.1.9 (from librosa->datasets[audio])\u001b[0m\n",
      "\u001b[34mDownloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from librosa->datasets[audio]) (1.13.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.11/site-packages (from librosa->datasets[audio]) (1.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.11/site-packages (from librosa->datasets[audio]) (1.4.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.11/site-packages (from librosa->datasets[audio]) (5.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numba>=0.51.0 in /opt/conda/lib/python3.11/site-packages (from librosa->datasets[audio]) (0.59.1)\u001b[0m\n",
      "\u001b[34mCollecting pooch>=1.1 (from librosa->datasets[audio])\u001b[0m\n",
      "\u001b[34mDownloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\u001b[0m\n",
      "\u001b[34mCollecting soxr>=0.3.2 (from librosa->datasets[audio])\u001b[0m\n",
      "\u001b[34mDownloading soxr-0.3.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting lazy-loader>=0.1 (from librosa->datasets[audio])\u001b[0m\n",
      "\u001b[34mDownloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting msgpack>=1.0 (from librosa->datasets[audio])\u001b[0m\n",
      "\u001b[34mDownloading msgpack-1.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets[audio]) (2.9.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets[audio]) (2024.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets[audio]) (2024.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=1.0->soundfile>=0.12.1->datasets[audio]) (2.21)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /opt/conda/lib/python3.11/site-packages (from numba>=0.51.0->librosa->datasets[audio]) (0.42.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.11/site-packages (from pooch>=1.1->librosa->datasets[audio]) (4.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets[audio]) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn>=0.20.0->librosa->datasets[audio]) (3.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.31.0-py3-none-any.whl (309 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 309.4/309.4 kB 10.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl (1.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 43.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 113.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading librosa-0.10.2.post1-py3-none-any.whl (260 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 260.1/260.1 kB 36.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading audioread-3.0.1-py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34mDownloading lazy_loader-0.4-py3-none-any.whl (12 kB)\u001b[0m\n",
      "\u001b[34mDownloading msgpack-1.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (409 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 409.3/409.3 kB 54.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading pooch-1.8.2-py3-none-any.whl (64 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 64.6/64.6 kB 13.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading soxr-0.3.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 89.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: transformers\u001b[0m\n",
      "\u001b[34mBuilding wheel for transformers (pyproject.toml): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for transformers (pyproject.toml): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for transformers: filename=transformers-4.42.0.dev0-py3-none-any.whl size=9143628 sha256=1de73e69305d199b34ae53e49b187f281377f0070ad919a3e7e3926880dd1a73\u001b[0m\n",
      "\u001b[34mStored in directory: /tmp/pip-ephem-wheel-cache-pajoph9a/wheels/32/4b/78/f195c684dd3a9ed21f3b39fe8f85b48df7918581b6437be143\u001b[0m\n",
      "\u001b[34mSuccessfully built transformers\u001b[0m\n",
      "\u001b[34mInstalling collected packages: soxr, msgpack, lazy-loader, audioread, soundfile, pooch, tokenizers, librosa, accelerate, transformers\u001b[0m\n",
      "\u001b[34mAttempting uninstall: accelerate\u001b[0m\n",
      "\u001b[34mFound existing installation: accelerate 0.30.1\u001b[0m\n",
      "\u001b[34mUninstalling accelerate-0.30.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled accelerate-0.30.1\u001b[0m\n",
      "\u001b[34mSuccessfully installed accelerate-0.31.0 audioread-3.0.1 lazy-loader-0.4 librosa-0.10.2.post1 msgpack-1.0.8 pooch-1.8.2 soundfile-0.12.1 soxr-0.3.7 tokenizers-0.19.1 transformers-4.42.0.dev0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mCollecting openai-whisper\u001b[0m\n",
      "\u001b[34mDownloading openai-whisper-20231117.tar.gz (798 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 798.6/798.6 kB 20.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mInstalling build dependencies: started\u001b[0m\n",
      "\u001b[34mInstalling build dependencies: finished with status 'done'\u001b[0m\n",
      "\u001b[34mGetting requirements to build wheel: started\u001b[0m\n",
      "\u001b[34mGetting requirements to build wheel: finished with status 'done'\u001b[0m\n",
      "\u001b[34mInstalling backend dependencies: started\u001b[0m\n",
      "\u001b[34mInstalling backend dependencies: finished with status 'done'\u001b[0m\n",
      "\u001b[34mPreparing metadata (pyproject.toml): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (pyproject.toml): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: triton<3,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from openai-whisper) (2.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numba in /opt/conda/lib/python3.11/site-packages (from openai-whisper) (0.59.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from openai-whisper) (1.26.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from openai-whisper) (2.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from openai-whisper) (4.66.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: more-itertools in /opt/conda/lib/python3.11/site-packages (from openai-whisper) (10.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tiktoken in /opt/conda/lib/python3.11/site-packages (from openai-whisper) (0.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from triton<3,>=2.0.0->openai-whisper) (3.14.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /opt/conda/lib/python3.11/site-packages (from numba->openai-whisper) (0.42.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.11/site-packages (from tiktoken->openai-whisper) (2024.5.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.11/site-packages (from tiktoken->openai-whisper) (2.32.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch->openai-whisper) (4.11.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch->openai-whisper) (1.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->openai-whisper) (3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->openai-whisper) (3.1.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch->openai-whisper) (2024.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (1.26.18)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->openai-whisper) (2.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch->openai-whisper) (1.3.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: openai-whisper\u001b[0m\n",
      "\u001b[34mBuilding wheel for openai-whisper (pyproject.toml): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for openai-whisper (pyproject.toml): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801358 sha256=4bba50c08d32a49b52867d167a4b7a5f2d0aa2cdf8d1c48a702d760ba32c1858\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/55/5d/42/c296ab046d52caa0adc0e3f159e98f011b3994a022d6282105\u001b[0m\n",
      "\u001b[34mSuccessfully built openai-whisper\u001b[0m\n",
      "\u001b[34mInstalling collected packages: openai-whisper\u001b[0m\n",
      "\u001b[34mSuccessfully installed openai-whisper-20231117\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numba in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (0.59.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (1.26.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (2.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (4.66.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: more-itertools in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (10.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tiktoken in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (0.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: triton<3,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (2.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (2.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jiwer in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (3.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: evaluate in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (0.4.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tensorboardX in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (2.6.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: bitsandbytes in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (0.43.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /opt/conda/lib/python3.11/site-packages (from numba->-r requirements.txt (line 1)) (0.42.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 3)) (3.14.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 3)) (4.11.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 3)) (1.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 3)) (3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 3)) (3.1.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 3)) (2024.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.11/site-packages (from tiktoken->-r requirements.txt (line 6)) (2024.5.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.11/site-packages (from tiktoken->-r requirements.txt (line 6)) (2.32.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 8)) (2.9.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 8)) (2024.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 8)) (2024.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click<9.0.0,>=8.1.3 in /opt/conda/lib/python3.11/site-packages (from jiwer->-r requirements.txt (line 9)) (8.1.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rapidfuzz<4,>=3 in /opt/conda/lib/python3.11/site-packages (from jiwer->-r requirements.txt (line 9)) (3.9.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from evaluate->-r requirements.txt (line 10)) (2.19.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill in /opt/conda/lib/python3.11/site-packages (from evaluate->-r requirements.txt (line 10)) (0.3.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from evaluate->-r requirements.txt (line 10)) (3.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from evaluate->-r requirements.txt (line 10)) (0.70.16)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from evaluate->-r requirements.txt (line 10)) (0.23.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from evaluate->-r requirements.txt (line 10)) (23.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.20 in /opt/conda/lib/python3.11/site-packages (from tensorboardX->-r requirements.txt (line 11)) (3.20.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate->-r requirements.txt (line 10)) (16.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate->-r requirements.txt (line 10)) (0.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate->-r requirements.txt (line 10)) (3.9.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate->-r requirements.txt (line 10)) (6.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 8)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->-r requirements.txt (line 6)) (3.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->-r requirements.txt (line 6)) (3.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->-r requirements.txt (line 6)) (1.26.18)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->-r requirements.txt (line 6)) (2024.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->-r requirements.txt (line 3)) (2.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch->-r requirements.txt (line 3)) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 10)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 10)) (23.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 10)) (1.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 10)) (6.0.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 10)) (1.9.4)\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mCollecting ffmpeg\u001b[0m\n",
      "\u001b[34mDownloading ffmpeg-1.4.tar.gz (5.1 kB)\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: ffmpeg\u001b[0m\n",
      "\u001b[34mBuilding wheel for ffmpeg (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for ffmpeg (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6080 sha256=d8d59fa856fbf03d184b7ad595ebcca52d9b2c3ab2b9d2adb30238acb74fb587\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/56/30/c5/576bdd729f3bc062d62a551be7fefd6ed2f761901568171e4e\u001b[0m\n",
      "\u001b[34mSuccessfully built ffmpeg\u001b[0m\n",
      "\u001b[34mInstalling collected packages: ffmpeg\u001b[0m\n",
      "\u001b[34mSuccessfully installed ffmpeg-1.4\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mW0607 14:07:55.421000 140152741607232 torch/distributed/run.py:757] \u001b[0m\n",
      "\u001b[34mW0607 14:07:55.421000 140152741607232 torch/distributed/run.py:757] *****************************************\u001b[0m\n",
      "\u001b[34mW0607 14:07:55.421000 140152741607232 torch/distributed/run.py:757] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \u001b[0m\n",
      "\u001b[34mW0607 14:07:55.421000 140152741607232 torch/distributed/run.py:757] *****************************************\u001b[0m\n",
      "\u001b[34m+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[34mARGUMENTS OF INTEREST:\u001b[0m\n",
      "\u001b[34m{'model_name': 'whisper-large-v3', 'language': 'Cantonese', 'sampling_rate': 16000, 'num_proc': 8, 'train_strategy': 'epoch', 'learning_rate': 0.003, 'warmup': 1000, 'train_batchsize': 4, 'eval_batchsize': 4, 'num_epochs': 5, 'num_steps': 100000, 'resume_from_ckpt': 'None', 'output_dir': '/opt/ml/checkpoints', 'train_datasets': ['data/train'], 'eval_datasets': ['data/valid']}\u001b[0m\n",
      "\u001b[34m+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[34mRunning on rank 4/8\u001b[0m\n",
      "\u001b[34m+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[34mARGUMENTS OF INTEREST:\u001b[0m\n",
      "\u001b[34m+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[34mARGUMENTS OF INTEREST:\u001b[0m\n",
      "\u001b[34m{'model_name': 'whisper-large-v3', 'language': 'Cantonese', 'sampling_rate': 16000, 'num_proc': 8, 'train_strategy': 'epoch', 'learning_rate': 0.003, 'warmup': 1000, 'train_batchsize': 4, 'eval_batchsize': 4, 'num_epochs': 5, 'num_steps': 100000, 'resume_from_ckpt': 'None', 'output_dir': '/opt/ml/checkpoints', 'train_datasets': ['data/train'], 'eval_datasets': ['data/valid']}\u001b[0m\n",
      "\u001b[34m+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[34m{'model_name': 'whisper-large-v3', 'language': 'Cantonese', 'sampling_rate': 16000, 'num_proc': 8, 'train_strategy': 'epoch', 'learning_rate': 0.003, 'warmup': 1000, 'train_batchsize': 4, 'eval_batchsize': 4, 'num_epochs': 5, 'num_steps': 100000, 'resume_from_ckpt': 'None', 'output_dir': '/opt/ml/checkpoints', 'train_datasets': ['data/train'], 'eval_datasets': ['data/valid']}\u001b[0m\n",
      "\u001b[34m+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[34mRunning on rank 0/8\u001b[0m\n",
      "\u001b[34m*****************start cp data and pretrained models*****************************\u001b[0m\n",
      "\u001b[34m+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[34mARGUMENTS OF INTEREST:\u001b[0m\n",
      "\u001b[34m{'model_name': 'whisper-large-v3', 'language': 'Cantonese', 'sampling_rate': 16000, 'num_proc': 8, 'train_strategy': 'epoch', 'learning_rate': 0.003, 'warmup': 1000, 'train_batchsize': 4, 'eval_batchsize': 4, 'num_epochs': 5, 'num_steps': 100000, 'resume_from_ckpt': 'None', 'output_dir': '/opt/ml/checkpoints', 'train_datasets': ['data/train'], 'eval_datasets': ['data/valid']}\u001b[0m\n",
      "\u001b[34m+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[34mRunning on rank 1/8\u001b[0m\n",
      "\u001b[34mRunning on rank 2/8\u001b[0m\n",
      "\u001b[34m+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[34mARGUMENTS OF INTEREST:\u001b[0m\n",
      "\u001b[34m{'model_name': 'whisper-large-v3', 'language': 'Cantonese', 'sampling_rate': 16000, 'num_proc': 8, 'train_strategy': 'epoch', 'learning_rate': 0.003, 'warmup': 1000, 'train_batchsize': 4, 'eval_batchsize': 4, 'num_epochs': 5, 'num_steps': 100000, 'resume_from_ckpt': 'None', 'output_dir': '/opt/ml/checkpoints', 'train_datasets': ['data/train'], 'eval_datasets': ['data/valid']}\u001b[0m\n",
      "\u001b[34m+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[34m+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[34mARGUMENTS OF INTEREST:\u001b[0m\n",
      "\u001b[34m{'model_name': 'whisper-large-v3', 'language': 'Cantonese', 'sampling_rate': 16000, 'num_proc': 8, 'train_strategy': 'epoch', 'learning_rate': 0.003, 'warmup': 1000, 'train_batchsize': 4, 'eval_batchsize': 4, 'num_epochs': 5, 'num_steps': 100000, 'resume_from_ckpt': 'None', 'output_dir': '/opt/ml/checkpoints', 'train_datasets': ['data/train'], 'eval_datasets': ['data/valid']}\u001b[0m\n",
      "\u001b[34m+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[34mRunning on rank 3/8\u001b[0m\n",
      "\u001b[34m+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[34mARGUMENTS OF INTEREST:\u001b[0m\n",
      "\u001b[34m{'model_name': 'whisper-large-v3', 'language': 'Cantonese', 'sampling_rate': 16000, 'num_proc': 8, 'train_strategy': 'epoch', 'learning_rate': 0.003, 'warmup': 1000, 'train_batchsize': 4, 'eval_batchsize': 4, 'num_epochs': 5, 'num_steps': 100000, 'resume_from_ckpt': 'None', 'output_dir': '/opt/ml/checkpoints', 'train_datasets': ['data/train'], 'eval_datasets': ['data/valid']}\u001b[0m\n",
      "\u001b[34m+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[34mRunning on rank 7/8\u001b[0m\n",
      "\u001b[34m+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[34mARGUMENTS OF INTEREST:\u001b[0m\n",
      "\u001b[34m{'model_name': 'whisper-large-v3', 'language': 'Cantonese', 'sampling_rate': 16000, 'num_proc': 8, 'train_strategy': 'epoch', 'learning_rate': 0.003, 'warmup': 1000, 'train_batchsize': 4, 'eval_batchsize': 4, 'num_epochs': 5, 'num_steps': 100000, 'resume_from_ckpt': 'None', 'output_dir': '/opt/ml/checkpoints', 'train_datasets': ['data/train'], 'eval_datasets': ['data/valid']}\u001b[0m\n",
      "\u001b[34m+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[0m\n",
      "\u001b[34mRunning on rank 6/8\u001b[0m\n",
      "\u001b[34mRunning on rank 5/8\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/datasets/midea_data/custom_data_v1/train/dataset_info.json data/train/dataset_info.json\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/datasets/midea_data/custom_data_v1/train/state.json data/train/state.json\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/datasets/midea_data/custom_data_v1/train/.ipynb_checkpoints/audio_paths-checkpoint data/train/.ipynb_checkpoints/audio_paths-checkpoint\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/datasets/midea_data/custom_data_v1/train/text data/train/text\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/datasets/midea_data/custom_data_v1/train/audio_paths data/train/audio_paths\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/datasets/midea_data/custom_data_v1/train/data-00001-of-00002.arrow data/train/data-00001-of-00002.arrow\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/datasets/midea_data/custom_data_v1/train/data-00000-of-00002.arrow data/train/data-00000-of-00002.arrow\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/datasets/midea_data/custom_data_v1/valid/.ipynb_checkpoints/text-checkpoint data/valid/.ipynb_checkpoints/text-checkpoint\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/datasets/midea_data/custom_data_v1/valid/state.json data/valid/state.json\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/datasets/midea_data/custom_data_v1/valid/dataset_info.json data/valid/dataset_info.json\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/datasets/midea_data/custom_data_v1/valid/text data/valid/text\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/datasets/midea_data/custom_data_v1/valid/audio_paths data/valid/audio_paths\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/datasets/midea_data/custom_data_v1/valid/data-00000-of-00001.arrow data/valid/data-00000-of-00001.arrow\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/config.json whisper-large-v3/config.json\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/.gitattributes whisper-large-v3/.gitattributes\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/preprocessor_config.json whisper-large-v3/preprocessor_config.json\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/generation_config.json whisper-large-v3/generation_config.json\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/normalizer.json whisper-large-v3/normalizer.json\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/special_tokens_map.json whisper-large-v3/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/added_tokens.json whisper-large-v3/added_tokens.json\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/README.md whisper-large-v3/README.md\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/merges.txt whisper-large-v3/merges.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/pytorch_model.bin.index.fp32.json whisper-large-v3/pytorch_model.bin.index.fp32.json\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/vocab.json whisper-large-v3/vocab.json\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/tokenizer_config.json whisper-large-v3/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/tokenizer.json whisper-large-v3/tokenizer.json\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/model.safetensors.index.fp32.json whisper-large-v3/model.safetensors.index.fp32.json\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/model.fp32-00002-of-00002.safetensors whisper-large-v3/model.fp32-00002-of-00002.safetensors\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/pytorch_model.fp32-00002-of-00002.bin whisper-large-v3/pytorch_model.fp32-00002-of-00002.bin\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/model.safetensors whisper-large-v3/model.safetensors\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/pytorch_model.bin whisper-large-v3/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/pytorch_model.fp32-00001-of-00002.bin whisper-large-v3/pytorch_model.fp32-00001-of-00002.bin\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/model.fp32-00001-of-00002.safetensors whisper-large-v3/model.fp32-00001-of-00002.safetensors\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-452145973879/models/whisper-large-v3/flax_model.msgpack whisper-large-v3/flax_model.msgpack\u001b[0m\n",
      "\u001b[34malgo-1:142:142 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34malgo-1:142:142 [0] NCCL INFO Bootstrap : Using eth0:10.0.199.68<0>\u001b[0m\n",
      "\u001b[34malgo-1:142:142 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34malgo-1:142:142 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34malgo-1:142:142 [0] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34mNCCL version 2.21.5+cuda12.1\u001b[0m\n",
      "\u001b[34malgo-1:146:146 [4] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34malgo-1:144:144 [2] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34malgo-1:149:149 [7] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34malgo-1:148:148 [6] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34malgo-1:143:143 [1] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34malgo-1:146:146 [4] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34malgo-1:144:144 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34malgo-1:147:147 [5] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34malgo-1:149:149 [7] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34malgo-1:148:148 [6] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34malgo-1:145:145 [3] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34malgo-1:143:143 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34malgo-1:147:147 [5] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34malgo-1:145:145 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34malgo-1:146:146 [4] NCCL INFO Bootstrap : Using eth0:10.0.199.68<0>\u001b[0m\n",
      "\u001b[34malgo-1:144:144 [2] NCCL INFO Bootstrap : Using eth0:10.0.199.68<0>\u001b[0m\n",
      "\u001b[34malgo-1:147:147 [5] NCCL INFO Bootstrap : Using eth0:10.0.199.68<0>\u001b[0m\n",
      "\u001b[34malgo-1:149:149 [7] NCCL INFO Bootstrap : Using eth0:10.0.199.68<0>\u001b[0m\n",
      "\u001b[34malgo-1:148:148 [6] NCCL INFO Bootstrap : Using eth0:10.0.199.68<0>\u001b[0m\n",
      "\u001b[34malgo-1:145:145 [3] NCCL INFO Bootstrap : Using eth0:10.0.199.68<0>\u001b[0m\n",
      "\u001b[34malgo-1:143:143 [1] NCCL INFO Bootstrap : Using eth0:10.0.199.68<0>\u001b[0m\n",
      "\u001b[34malgo-1:146:146 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34malgo-1:146:146 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34malgo-1:144:144 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34malgo-1:145:145 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34malgo-1:149:149 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34malgo-1:144:144 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34malgo-1:147:147 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34malgo-1:145:145 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34malgo-1:148:148 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34malgo-1:149:149 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34malgo-1:143:143 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34malgo-1:147:147 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34malgo-1:148:148 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34malgo-1:143:143 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO NET/OFI Using Libfabric version 1.21\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO NET/OFI Using CUDA driver version 12020\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO NET/OFI Running on p4d.24xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO NET/OFI Internode latency set at 75.0 us\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO NET/OFI Selected Provider is efa (found 4 nics)\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO NET/OFI Using Libfabric version 1.21\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO NET/OFI Using CUDA driver version 12020\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO NET/OFI Running on p4d.24xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO NET/OFI Internode latency set at 75.0 us\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO NET/OFI Using Libfabric version 1.21\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO NET/OFI Selected Provider is efa (found 4 nics)\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO NET/OFI Using CUDA driver version 12020\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO NET/OFI Running on p4d.24xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO NET/OFI Internode latency set at 75.0 us\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO NET/OFI Using Libfabric version 1.21\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO NET/OFI Using CUDA driver version 12020\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO NET/OFI Running on p4d.24xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO NET/OFI Internode latency set at 75.0 us\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO NET/OFI Using Libfabric version 1.21\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO NET/OFI Using CUDA driver version 12020\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO NET/OFI Running on p4d.24xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO NET/OFI Internode latency set at 75.0 us\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO NET/OFI Using Libfabric version 1.21\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO NET/OFI Using CUDA driver version 12020\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO NET/OFI Using Libfabric version 1.21\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO NET/OFI Running on p4d.24xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO NET/OFI Internode latency set at 75.0 us\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO NET/OFI Using CUDA driver version 12020\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO NET/OFI Using Libfabric version 1.21\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO NET/OFI Running on p4d.24xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO NET/OFI Internode latency set at 75.0 us\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO NET/OFI Using CUDA driver version 12020\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO NET/OFI Running on p4d.24xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO NET/OFI Internode latency set at 75.0 us\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO NET/OFI Selected Provider is efa (found 4 nics)\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO NET/OFI Selected Provider is efa (found 4 nics)\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO NET/OFI Selected Provider is efa (found 4 nics)\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO NET/OFI Selected Provider is efa (found 4 nics)\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO NET/OFI Selected Provider is efa (found 4 nics)\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO NET/OFI Selected Provider is efa (found 4 nics)\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO DMA-BUF is available on GPU device 0\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO DMA-BUF is available on GPU device 1\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO DMA-BUF is available on GPU device 4\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO DMA-BUF is available on GPU device 2\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO DMA-BUF is available on GPU device 3\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO DMA-BUF is available on GPU device 5\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO DMA-BUF is available on GPU device 7\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO DMA-BUF is available on GPU device 6\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO ncclCommInitRank comm 0x564313eb3740 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 201c0 commId 0x460e760e5639a48f - Init START\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO ncclCommInitRank comm 0x5581893f8450 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId 201d0 commId 0x460e760e5639a48f - Init START\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO ncclCommInitRank comm 0x555d86b3e0e0 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 101d0 commId 0x460e760e5639a48f - Init START\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO ncclCommInitRank comm 0x557917a7e850 rank 7 nranks 8 cudaDev 7 nvmlDev 7 busId a01d0 commId 0x460e760e5639a48f - Init START\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO ncclCommInitRank comm 0x55ef017643d0 rank 6 nranks 8 cudaDev 6 nvmlDev 6 busId a01c0 commId 0x460e760e5639a48f - Init START\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO ncclCommInitRank comm 0x559df28b4c60 rank 5 nranks 8 cudaDev 5 nvmlDev 5 busId 901d0 commId 0x460e760e5639a48f - Init START\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO ncclCommInitRank comm 0x56138551fcb0 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 101c0 commId 0x460e760e5639a48f - Init START\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO ncclCommInitRank comm 0x55fe2af510e0 rank 4 nranks 8 cudaDev 4 nvmlDev 4 busId 901c0 commId 0x460e760e5639a48f - Init START\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Setting affinity for GPU 6 to ffffff00,0000ffff,ff000000\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO NVLS multicast support is not available on dev 6\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Setting affinity for GPU 7 to ffffff00,0000ffff,ff000000\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO NVLS multicast support is not available on dev 7\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Setting affinity for GPU 5 to ffffff00,0000ffff,ff000000\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO NVLS multicast support is not available on dev 5\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Setting affinity for GPU 2 to ff,ffff0000,00ffffff\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO NVLS multicast support is not available on dev 2\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Setting affinity for GPU 3 to ff,ffff0000,00ffffff\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO NVLS multicast support is not available on dev 3\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Setting affinity for GPU 4 to ffffff00,0000ffff,ff000000\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO NVLS multicast support is not available on dev 4\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffff0000,00ffffff\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO NVLS multicast support is not available on dev 0\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Setting affinity for GPU 1 to ff,ffff0000,00ffffff\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO NVLS multicast support is not available on dev 1\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO comm 0x557917a7e850 rank 7 nRanks 8 nNodes 1 localRanks 8 localRank 7 MNNVL 0\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO comm 0x559df28b4c60 rank 5 nRanks 8 nNodes 1 localRanks 8 localRank 5 MNNVL 0\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO comm 0x55ef017643d0 rank 6 nRanks 8 nNodes 1 localRanks 8 localRank 6 MNNVL 0\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO comm 0x55fe2af510e0 rank 4 nRanks 8 nNodes 1 localRanks 8 localRank 4 MNNVL 0\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO comm 0x555d86b3e0e0 rank 1 nRanks 8 nNodes 1 localRanks 8 localRank 1 MNNVL 0\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO comm 0x5581893f8450 rank 3 nRanks 8 nNodes 1 localRanks 8 localRank 3 MNNVL 0\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO comm 0x56138551fcb0 rank 0 nRanks 8 nNodes 1 localRanks 8 localRank 0 MNNVL 0\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO comm 0x564313eb3740 rank 2 nRanks 8 nNodes 1 localRanks 8 localRank 2 MNNVL 0\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 00/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 01/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 02/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 2/-1/-1->1->0 [5] 2/-1/-1->1->0 [6] 2/-1/-1->1->0 [7] 2/-1/-1->1->0 [8] 2/-1/-1->1->0 [9] 2/-1/-1->1->0 [10] 2/-1/-1->1->0 [11] 2/-1/-1->1->0 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 2/-1/-1->1->0 [17] 2/-1/-1->1->0 [18] 2/-1/-1->1->0 [19] 2/-1/-1->1->0 [20] 2/-1/-1->1->0 [21] 2/-1/-1->1->0 [22] 2/-1/-1->1->0 [23] 2/-1/-1->1->0\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 7/-1/-1->6->5 [3] 7/-1/-1->6->5 [4] 7/-1/-1->6->5 [5] 7/-1/-1->6->5 [6] 7/-1/-1->6->5 [7] 7/-1/-1->6->5 [8] 7/-1/-1->6->5 [9] 7/-1/-1->6->5 [10] 7/-1/-1->6->5 [11] 7/-1/-1->6->5 [12] 7/-1/-1->6->5 [13] 7/-1/-1->6->5 [14] 7/-1/-1->6->5 [15] 7/-1/-1->6->5 [16] 7/-1/-1->6->5 [17] 7/-1/-1->6->5 [18] 7/-1/-1->6->5 [19] 7/-1/-1->6->5 [20] 7/-1/-1->6->5 [21] 7/-1/-1->6->5 [22] 7/-1/-1->6->5 [23] 7/-1/-1->6->5\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6 [2] -1/-1/-1->7->6 [3] -1/-1/-1->7->6 [4] -1/-1/-1->7->6 [5] -1/-1/-1->7->6 [6] -1/-1/-1->7->6 [7] -1/-1/-1->7->6 [8] -1/-1/-1->7->6 [9] -1/-1/-1->7->6 [10] -1/-1/-1->7->6 [11] -1/-1/-1->7->6 [12] -1/-1/-1->7->6 [13] -1/-1/-1->7->6 [14] -1/-1/-1->7->6 [15] -1/-1/-1->7->6 [16] -1/-1/-1->7->6 [17] -1/-1/-1->7->6 [18] -1/-1/-1->7->6 [19] -1/-1/-1->7->6 [20] -1/-1/-1->7->6 [21] -1/-1/-1->7->6 [22] -1/-1/-1->7->6 [23] -1/-1/-1->7->6\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2 [2] 4/-1/-1->3->2 [3] 4/-1/-1->3->2 [4] 4/-1/-1->3->2 [5] 4/-1/-1->3->2 [6] 4/-1/-1->3->2 [7] 4/-1/-1->3->2 [8] 4/-1/-1->3->2 [9] 4/-1/-1->3->2 [10] 4/-1/-1->3->2 [11] 4/-1/-1->3->2 [12] 4/-1/-1->3->2 [13] 4/-1/-1->3->2 [14] 4/-1/-1->3->2 [15] 4/-1/-1->3->2 [16] 4/-1/-1->3->2 [17] 4/-1/-1->3->2 [18] 4/-1/-1->3->2 [19] 4/-1/-1->3->2 [20] 4/-1/-1->3->2 [21] 4/-1/-1->3->2 [22] 4/-1/-1->3->2 [23] 4/-1/-1->3->2\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3 [2] 5/-1/-1->4->3 [3] 5/-1/-1->4->3 [4] 5/-1/-1->4->3 [5] 5/-1/-1->4->3 [6] 5/-1/-1->4->3 [7] 5/-1/-1->4->3 [8] 5/-1/-1->4->3 [9] 5/-1/-1->4->3 [10] 5/-1/-1->4->3 [11] 5/-1/-1->4->3 [12] 5/-1/-1->4->3 [13] 5/-1/-1->4->3 [14] 5/-1/-1->4->3 [15] 5/-1/-1->4->3 [16] 5/-1/-1->4->3 [17] 5/-1/-1->4->3 [18] 5/-1/-1->4->3 [19] 5/-1/-1->4->3 [20] 5/-1/-1->4->3 [21] 5/-1/-1->4->3 [22] 5/-1/-1->4->3 [23] 5/-1/-1->4->3\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4 [2] 6/-1/-1->5->4 [3] 6/-1/-1->5->4 [4] 6/-1/-1->5->4 [5] 6/-1/-1->5->4 [6] 6/-1/-1->5->4 [7] 6/-1/-1->5->4 [8] 6/-1/-1->5->4 [9] 6/-1/-1->5->4 [10] 6/-1/-1->5->4 [11] 6/-1/-1->5->4 [12] 6/-1/-1->5->4 [13] 6/-1/-1->5->4 [14] 6/-1/-1->5->4 [15] 6/-1/-1->5->4 [16] 6/-1/-1->5->4 [17] 6/-1/-1->5->4 [18] 6/-1/-1->5->4 [19] 6/-1/-1->5->4 [20] 6/-1/-1->5->4 [21] 6/-1/-1->5->4 [22] 6/-1/-1->5->4 [23] 6/-1/-1->5->4\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 03/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO P2P Chunksize set to 524288\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO P2P Chunksize set to 524288\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO P2P Chunksize set to 524288\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO P2P Chunksize set to 524288\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO P2P Chunksize set to 524288\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO P2P Chunksize set to 524288\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 04/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 05/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 06/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 07/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 08/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 3/-1/-1->2->1 [5] 3/-1/-1->2->1 [6] 3/-1/-1->2->1 [7] 3/-1/-1->2->1 [8] 3/-1/-1->2->1 [9] 3/-1/-1->2->1 [10] 3/-1/-1->2->1 [11] 3/-1/-1->2->1 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 3/-1/-1->2->1 [17] 3/-1/-1->2->1 [18] 3/-1/-1->2->1 [19] 3/-1/-1->2->1 [20] 3/-1/-1->2->1 [21] 3/-1/-1->2->1 [22] 3/-1/-1->2->1 [23] 3/-1/-1->2->1\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 09/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO P2P Chunksize set to 524288\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 10/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 11/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 12/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 13/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 14/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 15/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 16/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 17/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 18/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 19/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 20/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 21/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 22/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 23/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1 [8] 1/-1/-1->0->-1 [9] 1/-1/-1->0->-1 [10] 1/-1/-1->0->-1 [11] 1/-1/-1->0->-1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 1/-1/-1->0->-1 [17] 1/-1/-1->0->-1 [18] 1/-1/-1->0->-1 [19] 1/-1/-1->0->-1 [20] 1/-1/-1->0->-1 [21] 1/-1/-1->0->-1 [22] 1/-1/-1->0->-1 [23] 1/-1/-1->0->-1\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO P2P Chunksize set to 524288\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 00/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 01/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 01/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 02/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 02/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 03/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 03/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 04/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 05/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 05/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 06/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 07/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 07/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 08/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 08/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 02/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 09/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 09/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 03/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 01/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 10/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 04/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 11/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 11/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 05/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 03/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 12/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 13/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 04/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 13/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 14/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 05/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 14/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 08/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 15/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 15/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 09/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 07/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 16/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 10/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 17/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 17/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 11/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 09/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 18/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 19/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 10/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 19/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 20/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 11/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 20/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 14/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 21/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 21/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 15/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 13/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 22/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 16/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 23/0 : 1[1] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 23/0 : 7[7] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 17/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 15/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 16/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 00/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 00/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 17/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 00/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 01/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 20/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 01/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 01/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 02/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 21/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 02/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 19/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 02/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 03/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 22/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 03/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 03/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 04/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Channel 23/0 : 0[0] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 04/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 21/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 04/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 05/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 22/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 05/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 05/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 06/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 23/0 : 2[2] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 06/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 06/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 07/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 07/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 07/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 08/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 08/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 08/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 09/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 09/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 09/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 10/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 10/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 10/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 11/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 11/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 11/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 12/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 12/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 12/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 13/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 13/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 00/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 14/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 13/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 14/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 01/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 15/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 15/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 14/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 02/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 16/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 03/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 16/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 15/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 17/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 04/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 17/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 16/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 18/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 18/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 05/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 17/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 19/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 06/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 19/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 18/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 07/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 20/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 19/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 08/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 21/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 20/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 20/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 09/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 22/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 21/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 21/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 10/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 23/0 : 5[5] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 22/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 22/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 11/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 23/0 : 3[3] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 23/0 : 4[4] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 12/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 13/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 14/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 15/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 16/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 17/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 18/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 19/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 20/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 21/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 22/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 23/0 : 6[6] -> 7[7] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 00/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 01/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 02/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 04/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 03/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 04/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 06/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 07/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 06/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 08/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 10/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 07/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 12/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 13/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 00/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 09/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 14/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 01/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 10/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 02/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 16/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 03/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 12/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 04/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 18/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 13/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 05/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 00/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 19/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 06/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 20/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 15/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 07/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 02/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 16/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 08/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 03/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 22/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 09/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 04/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 18/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 19/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 06/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 21/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 08/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 22/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 09/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 10/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 10/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 12/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 11/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 12/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 14/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 13/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 15/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 14/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 16/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 15/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 00/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 00/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 18/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 01/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 02/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 16/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 03/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 17/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 20/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 01/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 04/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 18/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 00/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 21/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 02/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 05/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 19/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 01/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 22/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 03/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 04/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 20/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 02/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 06/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 05/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 21/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 07/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 06/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 22/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 08/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 03/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Channel 23/0 : 7[7] -> 6[6] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 09/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 04/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 07/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 05/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 10/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 06/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 08/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 11/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 07/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 12/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 08/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 13/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 09/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 09/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 14/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 10/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 10/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 11/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 15/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 12/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 11/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 16/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 12/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 17/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 13/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 13/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 18/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 14/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 14/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 19/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 20/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 15/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 15/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 21/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 16/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 16/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 22/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 17/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 17/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Channel 23/0 : 5[5] -> 4[4] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 18/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 18/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 19/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 19/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 20/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 20/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 21/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 21/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 22/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 22/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Channel 23/0 : 6[6] -> 5[5] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Channel 23/0 : 4[4] -> 3[3] via P2P/CUMEM/read\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.\u001b[0m\n",
      "\u001b[34malgo-1:147:895 [5] NCCL INFO ncclCommInitRank comm 0x559df28b4c60 rank 5 nranks 8 cudaDev 5 nvmlDev 5 busId 901d0 commId 0x460e760e5639a48f - Init COMPLETE\u001b[0m\n",
      "\u001b[34malgo-1:148:896 [6] NCCL INFO ncclCommInitRank comm 0x55ef017643d0 rank 6 nranks 8 cudaDev 6 nvmlDev 6 busId a01c0 commId 0x460e760e5639a48f - Init COMPLETE\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.\u001b[0m\n",
      "\u001b[34malgo-1:146:892 [4] NCCL INFO ncclCommInitRank comm 0x55fe2af510e0 rank 4 nranks 8 cudaDev 4 nvmlDev 4 busId 901c0 commId 0x460e760e5639a48f - Init COMPLETE\u001b[0m\n",
      "\u001b[34malgo-1:149:894 [7] NCCL INFO ncclCommInitRank comm 0x557917a7e850 rank 7 nranks 8 cudaDev 7 nvmlDev 7 busId a01d0 commId 0x460e760e5639a48f - Init COMPLETE\u001b[0m\n",
      "\u001b[34malgo-1:145:897 [3] NCCL INFO ncclCommInitRank comm 0x5581893f8450 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId 201d0 commId 0x460e760e5639a48f - Init COMPLETE\u001b[0m\n",
      "\u001b[34malgo-1:142:891 [0] NCCL INFO ncclCommInitRank comm 0x56138551fcb0 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 101c0 commId 0x460e760e5639a48f - Init COMPLETE\u001b[0m\n",
      "\u001b[34malgo-1:143:898 [1] NCCL INFO ncclCommInitRank comm 0x555d86b3e0e0 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 101d0 commId 0x460e760e5639a48f - Init COMPLETE\u001b[0m\n",
      "\u001b[34malgo-1:144:893 [2] NCCL INFO ncclCommInitRank comm 0x564313eb3740 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 201c0 commId 0x460e760e5639a48f - Init COMPLETE\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mDATASET PREPARATION IN PROGRESS...\u001b[0m\n",
      "\u001b[34mDATASET PREPARATION IN PROGRESS...\u001b[0m\n",
      "\u001b[34mDATASET PREPARATION IN PROGRESS...\u001b[0m\n",
      "\u001b[34mDATASET PREPARATION IN PROGRESS...\u001b[0m\n",
      "\u001b[34mDATASET PREPARATION IN PROGRESS...\u001b[0m\n",
      "\u001b[34mDATASET PREPARATION IN PROGRESS...\u001b[0m\n",
      "\u001b[34mDATASET PREPARATION IN PROGRESS...\u001b[0m\n",
      "\u001b[34mDATASET PREPARATION IN PROGRESS...\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   0%|          | 0/4319 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   0%|          | 0/4319 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   0%|          | 0/4319 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   0%|          | 0/4319 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   0%|          | 0/4319 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   0%|          | 0/4319 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   0%|          | 0/4319 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   0%|          | 0/4319 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   0%|          | 1/4319 [00:09<11:00:07,  9.17s/ examples]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   0%|          | 1/4319 [00:08<10:24:52,  8.68s/ examples]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   0%|          | 1/4319 [00:08<10:26:35,  8.71s/ examples]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   0%|          | 1/4319 [00:08<10:21:35,  8.64s/ examples]#015Map (num_proc=8):   0%|          | 1/4319 [00:08<10:24:13,  8.67s/ examples]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   0%|          | 1/4319 [00:08<10:28:31,  8.73s/ examples]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   0%|          | 1/4319 [00:08<10:28:22,  8.73s/ examples]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   0%|          | 1/4319 [00:08<10:31:53,  8.78s/ examples]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   0%|          | 17/4319 [00:08<26:25,  2.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   0%|          | 16/4319 [00:08<28:17,  2.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   0%|          | 16/4319 [00:08<28:14,  2.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   0%|          | 15/4319 [00:08<30:20,  2.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   1%|          | 24/4319 [00:09<19:47,  3.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   0%|          | 19/4319 [00:08<23:51,  3.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   1%|          | 22/4319 [00:08<20:33,  3.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   0%|          | 10/4319 [00:08<46:24,  1.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   1%|          | 45/4319 [00:08<07:55,  8.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   1%|          | 31/4319 [00:08<12:07,  5.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   1%|          | 39/4319 [00:08<09:21,  7.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   1%|          | 43/4319 [00:08<08:34,  8.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   1%|          | 40/4319 [00:08<09:04,  7.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   1%|▏         | 62/4319 [00:09<06:07, 11.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   1%|          | 48/4319 [00:08<07:43,  9.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   1%|          | 25/4319 [00:09<14:44,  4.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   2%|▏         | 65/4319 [00:08<04:44, 14.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   2%|▏         | 70/4319 [00:09<04:18, 16.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   2%|▏         | 66/4319 [00:09<04:30, 15.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   1%|▏         | 55/4319 [00:09<05:26, 13.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   2%|▏         | 65/4319 [00:09<04:38, 15.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   2%|▏         | 94/4319 [00:09<03:25, 20.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   2%|▏         | 66/4319 [00:09<04:53, 14.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   1%|          | 43/4319 [00:09<06:57, 10.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   2%|▏         | 90/4319 [00:09<02:49, 24.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   2%|▏         | 101/4319 [00:09<02:26, 28.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   2%|▏         | 99/4319 [00:09<02:25, 28.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   2%|▏         | 73/4319 [00:09<03:32, 20.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   2%|▏         | 88/4319 [00:09<02:53, 24.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   2%|▏         | 92/4319 [00:09<02:50, 24.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   3%|▎         | 124/4319 [00:09<02:12, 31.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   1%|▏         | 64/4319 [00:09<03:50, 18.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   3%|▎         | 115/4319 [00:09<01:51, 37.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   3%|▎         | 128/4319 [00:09<01:38, 42.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   3%|▎         | 123/4319 [00:09<01:42, 40.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   3%|▎         | 110/4319 [00:09<01:58, 35.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   2%|▏         | 99/4319 [00:09<02:06, 33.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   3%|▎         | 151/4319 [00:09<01:33, 44.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   3%|▎         | 112/4319 [00:09<02:01, 34.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   3%|▎         | 138/4319 [00:09<01:19, 52.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   2%|▏         | 84/4319 [00:09<02:28, 28.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   4%|▎         | 152/4319 [00:09<01:13, 56.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   3%|▎         | 137/4319 [00:09<01:18, 53.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   3%|▎         | 122/4319 [00:09<01:27, 47.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   4%|▎         | 158/4319 [00:09<01:06, 62.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   3%|▎         | 136/4319 [00:09<01:24, 49.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   4%|▍         | 178/4319 [00:09<01:10, 59.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   3%|▎         | 108/4319 [00:09<01:35, 44.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   4%|▍         | 169/4319 [00:09<00:54, 76.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   4%|▍         | 179/4319 [00:09<00:53, 77.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   4%|▍         | 185/4319 [00:09<00:50, 82.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   4%|▍         | 167/4319 [00:09<00:54, 75.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   3%|▎         | 147/4319 [00:09<01:02, 66.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   4%|▍         | 162/4319 [00:09<01:00, 68.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   5%|▍         | 202/4319 [00:10<00:55, 74.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   4%|▍         | 194/4319 [00:09<00:42, 97.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   3%|▎         | 129/4319 [00:09<01:10, 59.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   5%|▍         | 204/4319 [00:09<00:42, 96.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   5%|▍         | 198/4319 [00:09<00:40, 102.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   4%|▍         | 175/4319 [00:09<00:45, 91.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   5%|▍         | 213/4319 [00:09<00:39, 103.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   4%|▍         | 191/4319 [00:09<00:44, 93.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   5%|▌         | 225/4319 [00:10<00:44, 91.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   5%|▌         | 223/4319 [00:09<00:32, 125.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   4%|▎         | 156/4319 [00:09<00:49, 84.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   5%|▌         | 229/4319 [00:09<00:35, 116.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   5%|▌         | 227/4319 [00:09<00:31, 129.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   5%|▍         | 202/4319 [00:09<00:35, 116.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   6%|▌         | 240/4319 [00:09<00:32, 126.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   6%|▌         | 249/4319 [00:10<00:36, 111.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   5%|▍         | 214/4319 [00:09<00:37, 108.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   6%|▌         | 250/4319 [00:09<00:27, 148.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   4%|▍         | 182/4319 [00:09<00:38, 106.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   6%|▌         | 256/4319 [00:09<00:29, 137.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   6%|▌         | 254/4319 [00:09<00:27, 148.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   6%|▌         | 268/4319 [00:09<00:27, 148.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   5%|▌         | 227/4319 [00:09<00:30, 134.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   6%|▋         | 272/4319 [00:10<00:30, 131.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   6%|▌         | 244/4319 [00:09<00:29, 138.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   6%|▋         | 277/4319 [00:09<00:23, 168.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   5%|▍         | 205/4319 [00:09<00:32, 126.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   7%|▋         | 281/4319 [00:09<00:25, 157.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   6%|▌         | 251/4319 [00:09<00:26, 153.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   7%|▋         | 288/4319 [00:09<00:22, 177.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   7%|▋         | 299/4319 [00:09<00:23, 171.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   7%|▋         | 295/4319 [00:10<00:27, 148.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   6%|▌         | 268/4319 [00:09<00:26, 153.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   7%|▋         | 303/4319 [00:09<00:21, 183.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   5%|▌         | 232/4319 [00:09<00:27, 149.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   7%|▋         | 307/4319 [00:10<00:22, 179.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   6%|▋         | 276/4319 [00:10<00:24, 167.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   8%|▊         | 332/4319 [00:10<00:19, 203.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   7%|▋         | 323/4319 [00:10<00:19, 206.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   7%|▋         | 320/4319 [00:10<00:24, 162.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   7%|▋         | 291/4319 [00:10<00:24, 167.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   8%|▊         | 333/4319 [00:10<00:18, 210.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   6%|▌         | 255/4319 [00:10<00:25, 162.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   8%|▊         | 333/4319 [00:10<00:21, 182.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   8%|▊         | 352/4319 [00:10<00:17, 222.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   7%|▋         | 302/4319 [00:10<00:22, 180.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   8%|▊         | 361/4319 [00:10<00:19, 208.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   7%|▋         | 317/4319 [00:10<00:21, 187.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   8%|▊         | 343/4319 [00:10<00:23, 171.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   8%|▊         | 360/4319 [00:10<00:18, 217.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   6%|▋         | 280/4319 [00:10<00:22, 177.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   8%|▊         | 357/4319 [00:10<00:20, 195.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   8%|▊         | 327/4319 [00:10<00:20, 195.54 examples/s]#015Map (num_proc=8):   9%|▉         | 384/4319 [00:10<00:16, 241.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   9%|▊         | 368/4319 [00:10<00:20, 189.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   8%|▊         | 343/4319 [00:10<00:20, 192.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   9%|▉         | 387/4319 [00:10<00:19, 205.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   9%|▉         | 392/4319 [00:10<00:16, 232.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   7%|▋         | 303/4319 [00:10<00:21, 186.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   9%|▉         | 381/4319 [00:10<00:19, 198.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  10%|▉         | 419/4319 [00:10<00:14, 265.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   8%|▊         | 351/4319 [00:10<00:19, 203.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   9%|▉         | 394/4319 [00:10<00:19, 200.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   8%|▊         | 366/4319 [00:10<00:19, 201.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  10%|▉         | 411/4319 [00:10<00:18, 209.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  10%|▉         | 422/4319 [00:10<00:15, 246.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   8%|▊         | 331/4319 [00:10<00:19, 206.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   9%|▊         | 376/4319 [00:10<00:18, 214.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  10%|█         | 449/4319 [00:10<00:14, 269.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   9%|▉         | 405/4319 [00:10<00:19, 203.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   9%|▉         | 391/4319 [00:10<00:18, 213.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  10%|▉         | 418/4319 [00:10<00:19, 199.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  10%|█         | 435/4319 [00:10<00:18, 211.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   8%|▊         | 354/4319 [00:10<00:18, 209.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  11%|█         | 456/4319 [00:10<00:15, 254.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  11%|█         | 484/4319 [00:10<00:13, 283.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   9%|▉         | 407/4319 [00:10<00:17, 229.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  10%|▉         | 429/4319 [00:10<00:19, 197.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  10%|█         | 445/4319 [00:11<00:18, 214.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  11%|█         | 459/4319 [00:10<00:17, 215.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  10%|▉         | 415/4319 [00:10<00:19, 204.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   9%|▉         | 378/4319 [00:10<00:18, 210.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  11%|█▏        | 487/4319 [00:10<00:14, 262.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  12%|█▏        | 520/4319 [00:10<00:12, 303.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  10%|█         | 437/4319 [00:10<00:15, 244.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  11%|█         | 456/4319 [00:10<00:18, 209.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  11%|█         | 469/4319 [00:11<00:18, 211.02 examples/s]#015Map (num_proc=8):  10%|█         | 440/4319 [00:10<00:18, 211.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  11%|█         | 482/4319 [00:10<00:18, 203.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  12%|█▏        | 515/4319 [00:10<00:14, 260.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   9%|▉         | 403/4319 [00:10<00:19, 206.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  13%|█▎        | 554/4319 [00:10<00:12, 303.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  11%|█         | 478/4319 [00:10<00:18, 211.10 examples/s]#015Map (num_proc=8):  11%|█         | 464/4319 [00:10<00:16, 235.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  11%|█▏        | 493/4319 [00:11<00:17, 218.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  11%|█         | 464/4319 [00:10<00:18, 208.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  12%|█▏        | 504/4319 [00:10<00:18, 206.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  13%|█▎        | 543/4319 [00:10<00:14, 260.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  10%|▉         | 425/4319 [00:10<00:18, 207.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  14%|█▎        | 588/4319 [00:10<00:11, 311.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  11%|█▏        | 491/4319 [00:10<00:15, 240.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  12%|█▏        | 500/4319 [00:10<00:18, 202.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  12%|█▏        | 517/4319 [00:11<00:17, 216.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  12%|█▏        | 528/4319 [00:10<00:17, 215.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  11%|█▏        | 486/4319 [00:10<00:18, 207.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  13%|█▎        | 570/4319 [00:10<00:14, 251.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  10%|█         | 453/4319 [00:10<00:17, 218.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  14%|█▍        | 625/4319 [00:10<00:11, 315.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  12%|█▏        | 516/4319 [00:11<00:15, 238.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  12%|█▏        | 524/4319 [00:11<00:18, 209.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  13%|█▎        | 542/4319 [00:11<00:17, 221.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  13%|█▎        | 552/4319 [00:11<00:17, 213.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  12%|█▏        | 509/4319 [00:11<00:19, 198.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  14%|█▍        | 596/4319 [00:11<00:15, 244.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  11%|█         | 476/4319 [00:11<00:18, 207.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  15%|█▌        | 660/4319 [00:11<00:11, 317.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  13%|█▎        | 549/4319 [00:11<00:17, 213.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  13%|█▎        | 541/4319 [00:11<00:16, 223.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  13%|█▎        | 567/4319 [00:11<00:16, 222.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  13%|█▎        | 574/4319 [00:11<00:17, 214.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  12%|█▏        | 535/4319 [00:11<00:17, 212.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  14%|█▍        | 621/4319 [00:11<00:15, 241.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  12%|█▏        | 499/4319 [00:11<00:18, 211.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  16%|█▌        | 696/4319 [00:11<00:11, 324.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  13%|█▎        | 564/4319 [00:11<00:17, 218.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  13%|█▎        | 572/4319 [00:11<00:18, 206.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  14%|█▎        | 591/4319 [00:11<00:16, 222.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  14%|█▍        | 598/4319 [00:11<00:17, 217.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  13%|█▎        | 558/4319 [00:11<00:18, 204.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  17%|█▋        | 729/4319 [00:11<00:11, 319.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  15%|█▍        | 646/4319 [00:11<00:16, 223.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  12%|█▏        | 522/4319 [00:11<00:18, 205.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  14%|█▍        | 594/4319 [00:11<00:15, 237.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  14%|█▍        | 614/4319 [00:11<00:16, 222.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  14%|█▍        | 625/4319 [00:11<00:16, 221.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  14%|█▍        | 595/4319 [00:11<00:18, 196.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  13%|█▎        | 580/4319 [00:11<00:18, 205.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  18%|█▊        | 764/4319 [00:11<00:11, 321.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  13%|█▎        | 547/4319 [00:11<00:17, 210.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  15%|█▌        | 669/4319 [00:11<00:17, 210.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  14%|█▍        | 620/4319 [00:11<00:15, 240.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  15%|█▍        | 638/4319 [00:11<00:17, 211.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  14%|█▍        | 616/4319 [00:11<00:18, 198.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  15%|█▌        | 654/4319 [00:11<00:15, 232.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  19%|█▊        | 804/4319 [00:11<00:10, 329.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  14%|█▍        | 602/4319 [00:11<00:19, 191.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  13%|█▎        | 569/4319 [00:11<00:18, 207.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  16%|█▌        | 691/4319 [00:11<00:17, 202.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  15%|█▍        | 646/4319 [00:11<00:15, 240.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  15%|█▌        | 661/4319 [00:12<00:17, 214.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  15%|█▍        | 638/4319 [00:11<00:18, 195.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  16%|█▌        | 684/4319 [00:11<00:15, 238.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  19%|█▉        | 839/4319 [00:11<00:10, 333.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  14%|█▍        | 622/4319 [00:11<00:19, 189.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  14%|█▎        | 593/4319 [00:11<00:17, 212.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  16%|█▌        | 672/4319 [00:11<00:15, 241.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  16%|█▋        | 712/4319 [00:11<00:18, 193.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  16%|█▌        | 684/4319 [00:12<00:17, 210.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  16%|█▋        | 711/4319 [00:11<00:14, 246.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  15%|█▌        | 659/4319 [00:11<00:19, 185.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  20%|██        | 874/4319 [00:11<00:10, 332.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  15%|█▍        | 642/4319 [00:11<00:19, 187.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  14%|█▍        | 615/4319 [00:11<00:17, 208.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  16%|█▌        | 698/4319 [00:11<00:15, 237.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  17%|█▋        | 732/4319 [00:11<00:18, 188.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  17%|█▋        | 713/4319 [00:12<00:15, 227.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  17%|█▋        | 738/4319 [00:11<00:14, 243.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  16%|█▌        | 678/4319 [00:11<00:19, 182.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  21%|██        | 910/4319 [00:11<00:10, 336.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  15%|█▍        | 638/4319 [00:11<00:17, 213.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  15%|█▌        | 661/4319 [00:11<00:20, 180.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  17%|█▋        | 722/4319 [00:11<00:15, 230.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  18%|█▊        | 756/4319 [00:11<00:18, 192.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  17%|█▋        | 737/4319 [00:12<00:16, 218.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  18%|█▊        | 764/4319 [00:11<00:14, 242.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  16%|█▌        | 701/4319 [00:11<00:19, 184.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  22%|██▏       | 950/4319 [00:11<00:09, 337.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  15%|█▌        | 661/4319 [00:11<00:17, 215.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  16%|█▌        | 682/4319 [00:12<00:19, 186.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  17%|█▋        | 747/4319 [00:12<00:15, 232.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  18%|█▊        | 778/4319 [00:11<00:18, 188.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  18%|█▊        | 790/4319 [00:12<00:14, 238.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  18%|█▊        | 762/4319 [00:12<00:16, 212.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  23%|██▎       | 987/4319 [00:12<00:09, 343.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  16%|█▌        | 685/4319 [00:12<00:16, 220.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  16%|█▌        | 701/4319 [00:12<00:19, 184.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  17%|█▋        | 727/4319 [00:12<00:18, 189.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  18%|█▊        | 771/4319 [00:12<00:15, 232.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  18%|█▊        | 798/4319 [00:12<00:18, 187.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  19%|█▉        | 815/4319 [00:12<00:14, 234.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  18%|█▊        | 790/4319 [00:12<00:15, 225.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  24%|██▎       | 1025/4319 [00:12<00:09, 353.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  16%|█▋        | 709/4319 [00:12<00:16, 217.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  17%|█▋        | 746/4319 [00:12<00:19, 186.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  17%|█▋        | 720/4319 [00:12<00:21, 171.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  18%|█▊        | 797/4319 [00:12<00:15, 230.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  19%|█▉        | 819/4319 [00:12<00:18, 192.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  19%|█▉        | 840/4319 [00:12<00:14, 237.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  19%|█▉        | 816/4319 [00:12<00:14, 234.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  25%|██▍       | 1063/4319 [00:12<00:09, 346.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  17%|█▋        | 734/4319 [00:12<00:16, 223.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  17%|█▋        | 740/4319 [00:12<00:20, 178.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  19%|█▉        | 824/4319 [00:12<00:14, 236.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  18%|█▊        | 768/4319 [00:12<00:19, 179.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  19%|█▉        | 840/4319 [00:12<00:17, 194.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  20%|██        | 864/4319 [00:12<00:15, 228.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  19%|█▉        | 840/4319 [00:12<00:15, 225.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  18%|█▊        | 758/4319 [00:12<00:16, 220.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  26%|██▌       | 1102/4319 [00:12<00:09, 330.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  18%|█▊        | 759/4319 [00:12<00:20, 177.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  20%|█▉        | 853/4319 [00:12<00:13, 251.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  18%|█▊        | 788/4319 [00:12<00:19, 184.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  20%|█▉        | 862/4319 [00:12<00:17, 197.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  20%|██        | 868/4319 [00:12<00:14, 238.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  21%|██        | 887/4319 [00:12<00:15, 222.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  18%|█▊        | 781/4319 [00:12<00:16, 217.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  18%|█▊        | 782/4319 [00:12<00:18, 191.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  27%|██▋       | 1146/4319 [00:12<00:09, 343.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  19%|█▊        | 808/4319 [00:12<00:18, 185.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  20%|██        | 880/4319 [00:12<00:14, 244.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  20%|██        | 883/4319 [00:12<00:17, 193.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  21%|██        | 895/4319 [00:13<00:14, 242.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  21%|██        | 913/4319 [00:12<00:15, 225.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  19%|█▊        | 807/4319 [00:12<00:15, 228.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  27%|██▋       | 1185/4319 [00:12<00:08, 355.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  19%|█▊        | 802/4319 [00:12<00:19, 181.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  21%|██        | 905/4319 [00:12<00:14, 240.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  19%|█▉        | 830/4319 [00:12<00:19, 178.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  21%|██        | 907/4319 [00:12<00:16, 205.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  22%|██▏       | 939/4319 [00:12<00:14, 230.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  21%|██▏       | 920/4319 [00:13<00:15, 225.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  19%|█▉        | 831/4319 [00:12<00:15, 219.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  28%|██▊       | 1223/4319 [00:12<00:08, 355.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  22%|██▏       | 930/4319 [00:12<00:14, 239.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  19%|█▉        | 825/4319 [00:12<00:18, 186.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  22%|██▏       | 929/4319 [00:12<00:16, 207.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  20%|█▉        | 854/4319 [00:12<00:18, 183.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  22%|██▏       | 963/4319 [00:12<00:14, 227.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  22%|██▏       | 945/4319 [00:13<00:14, 230.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  20%|█▉        | 857/4319 [00:12<00:15, 229.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  29%|██▉       | 1260/4319 [00:12<00:08, 346.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  22%|██▏       | 956/4319 [00:12<00:14, 239.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  20%|█▉        | 846/4319 [00:12<00:18, 188.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  20%|██        | 874/4319 [00:12<00:18, 187.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  22%|██▏       | 950/4319 [00:12<00:17, 192.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  23%|██▎       | 988/4319 [00:12<00:14, 222.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  22%|██▏       | 969/4319 [00:13<00:14, 225.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  20%|██        | 882/4319 [00:12<00:15, 221.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  30%|███       | 1297/4319 [00:12<00:08, 346.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  20%|██        | 865/4319 [00:13<00:18, 182.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  23%|██▎       | 987/4319 [00:13<00:13, 246.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  21%|██        | 898/4319 [00:13<00:17, 199.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  23%|██▎       | 975/4319 [00:12<00:16, 208.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  23%|██▎       | 1011/4319 [00:13<00:14, 221.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  23%|██▎       | 992/4319 [00:13<00:15, 214.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  31%|███       | 1335/4319 [00:13<00:08, 355.70 examples/s]#015Map (num_proc=8):  21%|██        | 908/4319 [00:13<00:14, 230.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  21%|██        | 886/4319 [00:13<00:18, 189.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  23%|██▎       | 1013/4319 [00:13<00:13, 238.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  21%|██▏       | 922/4319 [00:13<00:17, 197.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  23%|██▎       | 997/4319 [00:13<00:16, 196.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  24%|██▍       | 1035/4319 [00:13<00:14, 219.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  32%|███▏      | 1371/4319 [00:13<00:08, 349.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  23%|██▎       | 1014/4319 [00:13<00:15, 208.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  22%|██▏       | 934/4319 [00:13<00:15, 217.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  24%|██▍       | 1038/4319 [00:13<00:13, 236.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  21%|██        | 907/4319 [00:13<00:18, 179.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  22%|██▏       | 944/4319 [00:13<00:17, 197.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  24%|██▎       | 1020/4319 [00:13<00:16, 199.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  24%|██▍       | 1058/4319 [00:13<00:15, 213.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  33%|███▎      | 1410/4319 [00:13<00:08, 351.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  24%|██▍       | 1035/4319 [00:13<00:16, 202.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  22%|██▏       | 961/4319 [00:13<00:14, 230.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  25%|██▍       | 1067/4319 [00:13<00:13, 249.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  22%|██▏       | 965/4319 [00:13<00:16, 199.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  21%|██▏       | 927/4319 [00:13<00:19, 174.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  24%|██▍       | 1042/4319 [00:13<00:16, 193.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  34%|███▎      | 1449/4319 [00:13<00:07, 359.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  25%|██▌       | 1081/4319 [00:13<00:15, 205.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  24%|██▍       | 1056/4319 [00:13<00:16, 198.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  23%|██▎       | 987/4319 [00:13<00:14, 231.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  25%|██▌       | 1093/4319 [00:13<00:13, 244.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  23%|██▎       | 987/4319 [00:13<00:16, 197.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  25%|██▍       | 1065/4319 [00:13<00:16, 199.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  22%|██▏       | 953/4319 [00:13<00:18, 177.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  34%|███▍      | 1485/4319 [00:13<00:08, 347.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  26%|██▌       | 1102/4319 [00:13<00:16, 193.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  23%|██▎       | 1012/4319 [00:13<00:14, 232.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  25%|██▍       | 1077/4319 [00:14<00:16, 190.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  26%|██▌       | 1125/4319 [00:13<00:12, 257.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  23%|██▎       | 1010/4319 [00:13<00:16, 198.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  25%|██▌       | 1090/4319 [00:13<00:15, 210.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  23%|██▎       | 976/4319 [00:13<00:17, 186.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  35%|███▌      | 1520/4319 [00:13<00:08, 322.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  24%|██▍       | 1036/4319 [00:13<00:14, 230.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  26%|██▌       | 1132/4319 [00:13<00:14, 215.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  25%|██▌       | 1098/4319 [00:14<00:17, 185.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  27%|██▋       | 1151/4319 [00:13<00:12, 252.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  24%|██▍       | 1033/4319 [00:13<00:16, 202.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  23%|██▎       | 998/4319 [00:13<00:17, 193.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  26%|██▌       | 1114/4319 [00:13<00:15, 207.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  25%|██▍       | 1062/4319 [00:13<00:13, 238.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  27%|██▋       | 1155/4319 [00:13<00:14, 214.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  36%|███▌      | 1559/4319 [00:13<00:08, 329.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  26%|██▌       | 1120/4319 [00:14<00:16, 194.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  27%|██▋       | 1180/4319 [00:13<00:11, 262.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  24%|██▍       | 1055/4319 [00:13<00:16, 192.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  26%|██▋       | 1137/4319 [00:13<00:15, 210.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  24%|██▎       | 1018/4319 [00:13<00:17, 185.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  37%|███▋      | 1597/4319 [00:13<00:07, 340.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  25%|██▌       | 1087/4319 [00:13<00:14, 228.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  27%|██▋       | 1178/4319 [00:13<00:14, 210.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  26%|██▋       | 1141/4319 [00:14<00:16, 190.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  28%|██▊       | 1208/4319 [00:13<00:11, 259.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  25%|██▍       | 1076/4319 [00:13<00:16, 196.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  27%|██▋       | 1161/4319 [00:13<00:14, 218.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  24%|██▍       | 1038/4319 [00:13<00:17, 186.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  26%|██▌       | 1111/4319 [00:13<00:13, 229.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  38%|███▊      | 1633/4319 [00:13<00:08, 333.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  28%|██▊       | 1200/4319 [00:13<00:14, 210.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  27%|██▋       | 1162/4319 [00:14<00:16, 191.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  29%|██▊       | 1236/4319 [00:14<00:11, 261.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  25%|██▌       | 1096/4319 [00:14<00:16, 194.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  27%|██▋       | 1183/4319 [00:13<00:14, 216.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  24%|██▍       | 1058/4319 [00:14<00:18, 175.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  28%|██▊       | 1230/4319 [00:14<00:13, 231.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  29%|██▉       | 1263/4319 [00:14<00:11, 263.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  26%|██▋       | 1135/4319 [00:14<00:14, 218.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  39%|███▊      | 1667/4319 [00:14<00:08, 316.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  27%|██▋       | 1182/4319 [00:14<00:17, 182.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  26%|██▌       | 1117/4319 [00:14<00:16, 197.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  28%|██▊       | 1209/4319 [00:14<00:13, 224.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  30%|██▉       | 1291/4319 [00:14<00:11, 265.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  39%|███▉      | 1706/4319 [00:14<00:07, 333.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  27%|██▋       | 1161/4319 [00:14<00:14, 225.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  25%|██▌       | 1086/4319 [00:14<00:17, 187.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  28%|██▊       | 1203/4319 [00:14<00:16, 189.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  29%|██▉       | 1255/4319 [00:14<00:14, 215.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  29%|██▊       | 1234/4319 [00:14<00:13, 221.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  26%|██▋       | 1139/4319 [00:14<00:16, 187.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  40%|████      | 1741/4319 [00:14<00:07, 337.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  31%|███       | 1319/4319 [00:14<00:11, 263.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  26%|██▌       | 1106/4319 [00:14<00:16, 189.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  30%|██▉       | 1278/4319 [00:14<00:13, 219.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  27%|██▋       | 1185/4319 [00:14<00:14, 218.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  28%|██▊       | 1223/4319 [00:14<00:16, 183.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  27%|██▋       | 1162/4319 [00:14<00:15, 198.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  29%|██▉       | 1258/4319 [00:14<00:14, 210.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  31%|███▏      | 1350/4319 [00:14<00:11, 266.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  41%|████      | 1775/4319 [00:14<00:07, 320.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  28%|██▊       | 1209/4319 [00:14<00:13, 222.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  26%|██▌       | 1130/4319 [00:14<00:16, 196.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  29%|██▉       | 1242/4319 [00:14<00:16, 182.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  30%|███       | 1302/4319 [00:14<00:14, 214.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  27%|██▋       | 1184/4319 [00:14<00:16, 195.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  30%|██▉       | 1281/4319 [00:14<00:14, 215.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  29%|██▊       | 1236/4319 [00:14<00:13, 232.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  32%|███▏      | 1378/4319 [00:14<00:11, 263.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  42%|████▏     | 1815/4319 [00:14<00:07, 327.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  29%|██▉       | 1261/4319 [00:15<00:16, 180.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  27%|██▋       | 1150/4319 [00:14<00:16, 186.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  31%|███       | 1324/4319 [00:14<00:14, 208.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  30%|███       | 1308/4319 [00:14<00:13, 225.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  28%|██▊       | 1207/4319 [00:14<00:15, 195.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  43%|████▎     | 1848/4319 [00:14<00:07, 326.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  33%|███▎      | 1405/4319 [00:14<00:11, 254.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  29%|██▉       | 1260/4319 [00:14<00:13, 223.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  27%|██▋       | 1169/4319 [00:14<00:16, 185.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  30%|██▉       | 1280/4319 [00:15<00:17, 176.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  31%|███       | 1348/4319 [00:14<00:14, 211.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  28%|██▊       | 1227/4319 [00:14<00:16, 188.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  31%|███       | 1331/4319 [00:14<00:14, 211.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  44%|████▎     | 1883/4319 [00:14<00:07, 331.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  30%|██▉       | 1286/4319 [00:14<00:13, 232.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  33%|███▎      | 1433/4319 [00:14<00:11, 250.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  28%|██▊       | 1190/4319 [00:14<00:16, 187.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  30%|███       | 1304/4319 [00:15<00:15, 190.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  32%|███▏      | 1374/4319 [00:14<00:14, 207.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  31%|███▏      | 1359/4319 [00:14<00:13, 225.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  29%|██▉       | 1252/4319 [00:14<00:15, 195.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  44%|████▍     | 1919/4319 [00:14<00:07, 330.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  30%|███       | 1311/4319 [00:14<00:12, 234.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  28%|██▊       | 1213/4319 [00:14<00:15, 197.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  34%|███▍      | 1461/4319 [00:14<00:11, 249.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  31%|███       | 1326/4319 [00:15<00:15, 193.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  32%|███▏      | 1401/4319 [00:14<00:13, 221.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  32%|███▏      | 1385/4319 [00:14<00:12, 234.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  29%|██▊       | 1233/4319 [00:14<00:15, 194.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  45%|████▌     | 1953/4319 [00:14<00:07, 314.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  35%|███▍      | 1494/4319 [00:14<00:10, 271.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  29%|██▉       | 1273/4319 [00:14<00:16, 183.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  31%|███       | 1339/4319 [00:14<00:12, 231.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  31%|███       | 1347/4319 [00:15<00:15, 193.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  33%|███▎      | 1425/4319 [00:14<00:13, 220.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  33%|███▎      | 1409/4319 [00:14<00:12, 229.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  29%|██▉       | 1257/4319 [00:15<00:14, 204.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  46%|████▌     | 1992/4319 [00:15<00:07, 329.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  32%|███▏      | 1363/4319 [00:15<00:12, 230.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  30%|██▉       | 1294/4319 [00:15<00:16, 185.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  35%|███▌      | 1523/4319 [00:15<00:10, 266.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  32%|███▏      | 1367/4319 [00:15<00:15, 188.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  34%|███▎      | 1448/4319 [00:15<00:13, 216.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  33%|███▎      | 1435/4319 [00:15<00:12, 237.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  30%|██▉       | 1279/4319 [00:15<00:14, 204.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  30%|███       | 1315/4319 [00:15<00:15, 189.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  47%|████▋     | 2027/4319 [00:15<00:07, 325.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  36%|███▌      | 1550/4319 [00:15<00:10, 261.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  32%|███▏      | 1387/4319 [00:15<00:13, 225.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  32%|███▏      | 1386/4319 [00:15<00:16, 182.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  34%|███▍      | 1478/4319 [00:15<00:12, 230.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  34%|███▍      | 1459/4319 [00:15<00:12, 231.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  48%|████▊     | 2061/4319 [00:15<00:06, 328.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  37%|███▋      | 1578/4319 [00:15<00:10, 266.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  30%|███       | 1300/4319 [00:15<00:15, 194.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  31%|███       | 1336/4319 [00:15<00:16, 185.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  33%|███▎      | 1410/4319 [00:15<00:13, 217.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  33%|███▎      | 1406/4319 [00:15<00:16, 180.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  35%|███▍      | 1503/4319 [00:15<00:12, 222.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  34%|███▍      | 1488/4319 [00:15<00:11, 246.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  49%|████▊     | 2096/4319 [00:15<00:06, 329.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  31%|███       | 1321/4319 [00:15<00:15, 191.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  32%|███▏      | 1361/4319 [00:15<00:14, 197.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  33%|███▎      | 1433/4319 [00:15<00:13, 214.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  33%|███▎      | 1433/4319 [00:15<00:14, 204.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  37%|███▋      | 1606/4319 [00:15<00:10, 247.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  35%|███▌      | 1530/4319 [00:15<00:12, 232.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  35%|███▌      | 1514/4319 [00:15<00:11, 240.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  49%|████▉     | 2130/4319 [00:15<00:06, 321.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  34%|███▎      | 1455/4319 [00:15<00:13, 215.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  34%|███▎      | 1455/4319 [00:15<00:13, 207.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  38%|███▊      | 1633/4319 [00:15<00:10, 248.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  32%|███▏      | 1381/4319 [00:15<00:15, 184.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  31%|███       | 1342/4319 [00:15<00:16, 175.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  36%|███▌      | 1554/4319 [00:15<00:12, 227.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  36%|███▌      | 1542/4319 [00:15<00:11, 246.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  50%|█████     | 2170/4319 [00:15<00:06, 317.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  38%|███▊      | 1659/4319 [00:15<00:10, 244.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  34%|███▍      | 1476/4319 [00:16<00:14, 193.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  32%|███▏      | 1401/4319 [00:15<00:15, 185.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  34%|███▍      | 1477/4319 [00:15<00:14, 197.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  37%|███▋      | 1579/4319 [00:15<00:11, 233.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  32%|███▏      | 1365/4319 [00:15<00:16, 183.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  36%|███▋      | 1568/4319 [00:15<00:11, 236.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  51%|█████     | 2211/4319 [00:15<00:06, 342.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  39%|███▉      | 1685/4319 [00:15<00:10, 242.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  35%|███▍      | 1498/4319 [00:16<00:14, 197.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  33%|███▎      | 1425/4319 [00:15<00:14, 196.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  35%|███▍      | 1498/4319 [00:15<00:14, 192.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  32%|███▏      | 1385/4319 [00:15<00:16, 176.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  37%|███▋      | 1593/4319 [00:15<00:11, 239.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  37%|███▋      | 1603/4319 [00:15<00:12, 210.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  52%|█████▏    | 2246/4319 [00:15<00:06, 329.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  40%|███▉      | 1714/4319 [00:15<00:10, 248.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  35%|███▌      | 1522/4319 [00:16<00:13, 202.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  33%|███▎      | 1446/4319 [00:15<00:15, 186.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  35%|███▌      | 1518/4319 [00:15<00:15, 185.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  33%|███▎      | 1407/4319 [00:15<00:15, 184.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  37%|███▋      | 1618/4319 [00:15<00:11, 238.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  38%|███▊      | 1627/4319 [00:15<00:12, 207.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  53%|█████▎    | 2282/4319 [00:15<00:06, 331.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  40%|████      | 1740/4319 [00:15<00:10, 239.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  36%|███▌      | 1547/4319 [00:16<00:13, 205.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  34%|███▍      | 1465/4319 [00:15<00:15, 181.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  33%|███▎      | 1426/4319 [00:16<00:15, 183.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  36%|███▌      | 1541/4319 [00:16<00:14, 186.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  38%|███▊      | 1642/4319 [00:15<00:11, 227.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  38%|███▊      | 1649/4319 [00:16<00:13, 200.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  54%|█████▎    | 2321/4319 [00:16<00:05, 341.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  41%|████      | 1766/4319 [00:16<00:10, 239.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  34%|███▍      | 1484/4319 [00:16<00:15, 182.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  36%|███▋      | 1574/4319 [00:16<00:12, 212.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  34%|███▎      | 1449/4319 [00:16<00:14, 194.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  36%|███▋      | 1568/4319 [00:16<00:13, 204.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  39%|███▊      | 1665/4319 [00:16<00:11, 221.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  39%|███▊      | 1673/4319 [00:16<00:13, 202.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  55%|█████▍    | 2357/4319 [00:16<00:05, 345.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  41%|████▏     | 1791/4319 [00:16<00:10, 231.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  35%|███▍      | 1504/4319 [00:16<00:15, 181.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  37%|███▋      | 1601/4319 [00:16<00:12, 223.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  34%|███▍      | 1470/4319 [00:16<00:14, 198.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  37%|███▋      | 1590/4319 [00:16<00:13, 203.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  39%|███▉      | 1689/4319 [00:16<00:11, 220.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  39%|███▉      | 1694/4319 [00:16<00:12, 203.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  55%|█████▌    | 2394/4319 [00:16<00:05, 343.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  35%|███▌      | 1523/4319 [00:16<00:15, 182.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  35%|███▍      | 1492/4319 [00:16<00:14, 200.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  38%|███▊      | 1627/4319 [00:16<00:11, 228.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  42%|████▏     | 1815/4319 [00:16<00:11, 222.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  37%|███▋      | 1617/4319 [00:16<00:13, 197.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  40%|███▉      | 1712/4319 [00:16<00:12, 207.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  40%|███▉      | 1718/4319 [00:16<00:12, 207.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  56%|█████▋    | 2430/4319 [00:16<00:05, 340.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  36%|███▌      | 1547/4319 [00:16<00:13, 198.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  43%|████▎     | 1839/4319 [00:16<00:10, 227.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  35%|███▌      | 1515/4319 [00:16<00:13, 204.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  38%|███▊      | 1650/4319 [00:16<00:12, 221.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  40%|████      | 1740/4319 [00:16<00:12, 210.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  40%|████      | 1738/4319 [00:16<00:11, 219.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  38%|███▊      | 1647/4319 [00:16<00:12, 218.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  57%|█████▋    | 2467/4319 [00:16<00:05, 329.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  36%|███▋      | 1568/4319 [00:16<00:14, 194.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  43%|████▎     | 1863/4319 [00:16<00:10, 227.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  36%|███▌      | 1539/4319 [00:16<00:13, 202.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  39%|███▊      | 1673/4319 [00:17<00:13, 201.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  41%|████      | 1766/4319 [00:16<00:11, 223.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  39%|███▉      | 1674/4319 [00:16<00:12, 219.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  41%|████      | 1762/4319 [00:16<00:12, 205.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  58%|█████▊    | 2504/4319 [00:16<00:05, 313.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  44%|████▎     | 1887/4319 [00:16<00:10, 225.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  37%|███▋      | 1588/4319 [00:16<00:14, 186.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  36%|███▌      | 1560/4319 [00:16<00:14, 195.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  39%|███▉      | 1697/4319 [00:17<00:12, 211.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  41%|████▏     | 1789/4319 [00:16<00:11, 214.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  39%|███▉      | 1698/4319 [00:16<00:11, 221.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  41%|████▏     | 1783/4319 [00:16<00:12, 195.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  59%|█████▉    | 2543/4319 [00:16<00:05, 329.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  44%|████▍     | 1912/4319 [00:16<00:10, 226.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  37%|███▋      | 1614/4319 [00:16<00:13, 198.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  37%|███▋      | 1585/4319 [00:16<00:13, 206.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  40%|███▉      | 1720/4319 [00:17<00:12, 200.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  42%|████▏     | 1816/4319 [00:16<00:11, 210.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  40%|███▉      | 1725/4319 [00:16<00:11, 221.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  42%|████▏     | 1803/4319 [00:16<00:13, 191.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  60%|█████▉    | 2580/4319 [00:16<00:05, 333.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  38%|███▊      | 1639/4319 [00:16<00:12, 212.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  45%|████▍     | 1938/4319 [00:16<00:10, 221.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  37%|███▋      | 1606/4319 [00:16<00:13, 202.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  40%|████      | 1742/4319 [00:17<00:12, 204.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  43%|████▎     | 1842/4319 [00:16<00:11, 221.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  41%|████      | 1751/4319 [00:16<00:11, 230.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  61%|██████    | 2614/4319 [00:16<00:05, 325.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  38%|███▊      | 1662/4319 [00:16<00:12, 215.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  42%|████▏     | 1823/4319 [00:16<00:13, 183.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  46%|████▌     | 1966/4319 [00:16<00:10, 233.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  38%|███▊      | 1630/4319 [00:16<00:12, 208.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  41%|████      | 1764/4319 [00:17<00:12, 199.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  41%|████      | 1780/4319 [00:17<00:10, 243.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  43%|████▎     | 1865/4319 [00:17<00:11, 217.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  39%|███▉      | 1684/4319 [00:17<00:12, 216.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  43%|████▎     | 1847/4319 [00:17<00:12, 193.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  61%|██████▏   | 2650/4319 [00:17<00:05, 317.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  38%|███▊      | 1651/4319 [00:17<00:12, 207.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  46%|████▌     | 1991/4319 [00:17<00:10, 214.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  41%|████▏     | 1786/4319 [00:17<00:12, 203.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  42%|████▏     | 1806/4319 [00:17<00:10, 237.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  44%|████▎     | 1889/4319 [00:17<00:11, 211.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  40%|███▉      | 1708/4319 [00:17<00:12, 215.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  43%|████▎     | 1870/4319 [00:17<00:12, 197.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  62%|██████▏   | 2686/4319 [00:17<00:05, 318.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  39%|███▉      | 1675/4319 [00:17<00:12, 213.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  47%|████▋     | 2013/4319 [00:17<00:10, 212.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  42%|████▏     | 1808/4319 [00:17<00:12, 197.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  42%|████▏     | 1830/4319 [00:17<00:10, 238.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  44%|████▍     | 1913/4319 [00:17<00:11, 212.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  40%|████      | 1731/4319 [00:17<00:12, 211.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  63%|██████▎   | 2720/4319 [00:17<00:04, 323.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  44%|████▍     | 1893/4319 [00:17<00:12, 199.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  39%|███▉      | 1698/4319 [00:17<00:12, 211.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  47%|████▋     | 2035/4319 [00:17<00:11, 206.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  43%|████▎     | 1854/4319 [00:17<00:10, 230.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  42%|████▏     | 1830/4319 [00:17<00:13, 190.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  45%|████▍     | 1936/4319 [00:17<00:11, 214.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  64%|██████▍   | 2759/4319 [00:17<00:04, 341.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  44%|████▍     | 1915/4319 [00:17<00:11, 204.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  41%|████      | 1754/4319 [00:17<00:12, 207.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  40%|███▉      | 1721/4319 [00:17<00:12, 203.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  48%|████▊     | 2057/4319 [00:17<00:11, 197.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  44%|████▎     | 1880/4319 [00:17<00:10, 237.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  43%|████▎     | 1852/4319 [00:17<00:12, 196.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  45%|████▌     | 1958/4319 [00:17<00:11, 203.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  65%|██████▍   | 2794/4319 [00:17<00:04, 332.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  41%|████      | 1775/4319 [00:17<00:12, 204.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  45%|████▍     | 1941/4319 [00:17<00:11, 209.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  40%|████      | 1745/4319 [00:17<00:12, 208.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  44%|████▍     | 1905/4319 [00:17<00:10, 238.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  43%|████▎     | 1876/4319 [00:18<00:11, 207.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  48%|████▊     | 2078/4319 [00:17<00:11, 187.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  66%|██████▌   | 2834/4319 [00:17<00:04, 349.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  42%|████▏     | 1798/4319 [00:17<00:12, 209.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  46%|████▌     | 1967/4319 [00:17<00:10, 219.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  46%|████▌     | 1979/4319 [00:17<00:12, 187.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  41%|████      | 1766/4319 [00:17<00:12, 197.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  45%|████▍     | 1930/4319 [00:17<00:09, 241.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  44%|████▍     | 1897/4319 [00:18<00:11, 206.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  49%|████▊     | 2102/4319 [00:17<00:11, 200.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  66%|██████▋   | 2872/4319 [00:17<00:04, 346.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  42%|████▏     | 1820/4319 [00:17<00:12, 205.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  46%|████▋     | 1999/4319 [00:17<00:12, 189.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  46%|████▌     | 1992/4319 [00:17<00:10, 216.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  41%|████▏     | 1786/4319 [00:17<00:12, 195.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  44%|████▍     | 1918/4319 [00:18<00:11, 207.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  45%|████▌     | 1956/4319 [00:17<00:09, 238.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  67%|██████▋   | 2908/4319 [00:17<00:04, 345.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  49%|████▉     | 2123/4319 [00:17<00:11, 183.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  43%|████▎     | 1841/4319 [00:17<00:12, 197.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  47%|████▋     | 2021/4319 [00:17<00:09, 233.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  47%|████▋     | 2022/4319 [00:17<00:11, 193.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  42%|████▏     | 1806/4319 [00:17<00:12, 196.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  45%|████▍     | 1940/4319 [00:18<00:11, 208.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  46%|████▌     | 1982/4319 [00:17<00:10, 232.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  68%|██████▊   | 2948/4319 [00:17<00:03, 354.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  50%|████▉     | 2143/4319 [00:17<00:11, 186.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  47%|████▋     | 2043/4319 [00:17<00:12, 189.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  43%|████▎     | 1861/4319 [00:17<00:13, 184.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  47%|████▋     | 2049/4319 [00:17<00:09, 227.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  42%|████▏     | 1828/4319 [00:17<00:12, 195.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  45%|████▌     | 1962/4319 [00:18<00:11, 196.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  47%|████▋     | 2014/4319 [00:18<00:09, 251.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  50%|█████     | 2162/4319 [00:18<00:11, 181.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  69%|██████▉   | 2985/4319 [00:18<00:03, 343.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  44%|████▎     | 1881/4319 [00:18<00:13, 187.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  48%|████▊     | 2078/4319 [00:18<00:09, 239.22 examples/s]#015Map (num_proc=8):  43%|████▎     | 1851/4319 [00:18<00:12, 202.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  48%|████▊     | 2068/4319 [00:18<00:11, 196.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  46%|████▌     | 1985/4319 [00:18<00:11, 205.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  47%|████▋     | 2040/4319 [00:18<00:09, 239.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  70%|██████▉   | 3021/4319 [00:18<00:03, 337.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  51%|█████     | 2184/4319 [00:18<00:11, 179.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  49%|████▊     | 2104/4319 [00:18<00:09, 241.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  43%|████▎     | 1872/4319 [00:18<00:12, 198.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  48%|████▊     | 2090/4319 [00:18<00:11, 193.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  44%|████▍     | 1900/4319 [00:18<00:14, 172.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  46%|████▋     | 2008/4319 [00:18<00:11, 204.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  48%|████▊     | 2068/4319 [00:18<00:09, 241.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  71%|███████   | 3056/4319 [00:18<00:03, 326.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  51%|█████     | 2206/4319 [00:18<00:11, 183.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  44%|████▍     | 1898/4319 [00:18<00:11, 212.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  49%|████▉     | 2115/4319 [00:18<00:10, 206.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  49%|████▉     | 2129/4319 [00:18<00:09, 227.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  45%|████▍     | 1924/4319 [00:18<00:13, 183.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  47%|████▋     | 2029/4319 [00:18<00:11, 201.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  49%|████▊     | 2096/4319 [00:18<00:09, 245.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  72%|███████▏  | 3097/4319 [00:18<00:03, 348.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  52%|█████▏    | 2227/4319 [00:18<00:11, 186.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  44%|████▍     | 1921/4319 [00:18<00:11, 213.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  50%|████▉     | 2152/4319 [00:18<00:09, 227.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  50%|████▉     | 2140/4319 [00:18<00:10, 207.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  48%|████▊     | 2054/4319 [00:18<00:10, 210.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  45%|████▌     | 1944/4319 [00:18<00:13, 178.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  49%|████▉     | 2121/4319 [00:18<00:08, 246.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  73%|███████▎  | 3134/4319 [00:18<00:03, 337.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  52%|█████▏    | 2250/4319 [00:18<00:10, 195.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  50%|█████     | 2179/4319 [00:18<00:09, 235.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  45%|████▌     | 1945/4319 [00:18<00:11, 206.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  50%|█████     | 2163/4319 [00:18<00:10, 209.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  48%|████▊     | 2078/4319 [00:19<00:10, 211.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  45%|████▌     | 1964/4319 [00:18<00:13, 174.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  50%|████▉     | 2147/4319 [00:18<00:08, 247.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  73%|███████▎  | 3169/4319 [00:18<00:03, 330.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  53%|█████▎    | 2270/4319 [00:18<00:10, 192.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  46%|████▌     | 1968/4319 [00:18<00:11, 209.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  51%|█████     | 2205/4319 [00:18<00:09, 228.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  51%|█████     | 2186/4319 [00:18<00:10, 207.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  49%|████▊     | 2100/4319 [00:19<00:10, 211.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  46%|████▌     | 1982/4319 [00:18<00:13, 175.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  50%|█████     | 2173/4319 [00:18<00:09, 236.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  74%|███████▍  | 3208/4319 [00:18<00:03, 345.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  53%|█████▎    | 2291/4319 [00:18<00:10, 189.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  46%|████▌     | 1991/4319 [00:18<00:10, 212.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  52%|█████▏    | 2230/4319 [00:18<00:08, 233.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  51%|█████     | 2212/4319 [00:18<00:09, 214.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  49%|████▉     | 2123/4319 [00:19<00:10, 206.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  46%|████▋     | 2004/4319 [00:18<00:12, 182.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  51%|█████     | 2197/4319 [00:18<00:09, 231.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  75%|███████▌  | 3244/4319 [00:18<00:03, 339.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  54%|█████▎    | 2314/4319 [00:18<00:10, 197.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  52%|█████▏    | 2255/4319 [00:18<00:08, 235.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  47%|████▋     | 2014/4319 [00:18<00:10, 211.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  50%|████▉     | 2145/4319 [00:19<00:10, 207.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  47%|████▋     | 2025/4319 [00:18<00:12, 187.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  52%|█████▏    | 2238/4319 [00:18<00:10, 207.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  51%|█████▏    | 2223/4319 [00:18<00:08, 233.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  76%|███████▌  | 3280/4319 [00:18<00:03, 327.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  54%|█████▍    | 2334/4319 [00:18<00:10, 191.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  47%|████▋     | 2038/4319 [00:18<00:10, 218.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  53%|█████▎    | 2279/4319 [00:18<00:08, 232.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  47%|████▋     | 2044/4319 [00:18<00:12, 184.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  50%|█████     | 2171/4319 [00:19<00:10, 210.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  52%|█████▏    | 2248/4319 [00:18<00:08, 237.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  52%|█████▏    | 2260/4319 [00:18<00:09, 206.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  77%|███████▋  | 3318/4319 [00:19<00:03, 326.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  48%|████▊     | 2061/4319 [00:19<00:10, 220.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  55%|█████▍    | 2355/4319 [00:19<00:10, 183.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  53%|█████▎    | 2304/4319 [00:19<00:08, 224.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  51%|█████     | 2195/4319 [00:19<00:09, 213.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  53%|█████▎    | 2286/4319 [00:19<00:09, 217.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  53%|█████▎    | 2276/4319 [00:19<00:08, 240.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  48%|████▊     | 2064/4319 [00:19<00:13, 173.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  78%|███████▊  | 3357/4319 [00:19<00:02, 331.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  48%|████▊     | 2085/4319 [00:19<00:10, 220.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  55%|█████▌    | 2376/4319 [00:19<00:10, 185.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  54%|█████▍    | 2328/4319 [00:19<00:08, 226.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  51%|█████▏    | 2217/4319 [00:19<00:09, 210.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  53%|█████▎    | 2309/4319 [00:19<00:09, 213.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  48%|████▊     | 2085/4319 [00:19<00:12, 172.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  53%|█████▎    | 2310/4319 [00:19<00:08, 246.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  79%|███████▊  | 3393/4319 [00:19<00:02, 339.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  55%|█████▌    | 2395/4319 [00:19<00:10, 184.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  49%|████▉     | 2109/4319 [00:19<00:10, 216.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  54%|█████▍    | 2353/4319 [00:19<00:08, 229.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  52%|█████▏    | 2240/4319 [00:19<00:09, 214.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  54%|█████▍    | 2333/4319 [00:19<00:09, 218.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  54%|█████▍    | 2336/4319 [00:19<00:08, 242.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  49%|████▉     | 2106/4319 [00:19<00:12, 172.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  79%|███████▉  | 3430/4319 [00:19<00:02, 330.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  56%|█████▌    | 2416/4319 [00:19<00:10, 184.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  55%|█████▌    | 2378/4319 [00:19<00:08, 224.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  49%|████▉     | 2134/4319 [00:19<00:10, 210.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  55%|█████▍    | 2357/4319 [00:19<00:09, 215.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  52%|█████▏    | 2264/4319 [00:19<00:10, 203.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  49%|████▉     | 2127/4319 [00:19<00:12, 180.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  55%|█████▍    | 2367/4319 [00:19<00:07, 244.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  80%|████████  | 3464/4319 [00:19<00:02, 329.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  56%|█████▋    | 2436/4319 [00:19<00:10, 185.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  56%|█████▌    | 2405/4319 [00:19<00:08, 233.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  50%|████▉     | 2158/4319 [00:19<00:09, 217.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  53%|█████▎    | 2287/4319 [00:20<00:09, 209.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  55%|█████▌    | 2383/4319 [00:19<00:08, 218.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  50%|████▉     | 2147/4319 [00:19<00:11, 181.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  55%|█████▌    | 2392/4319 [00:19<00:07, 242.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  81%|████████  | 3498/4319 [00:19<00:02, 332.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  57%|█████▋    | 2460/4319 [00:19<00:09, 198.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  56%|█████▌    | 2429/4319 [00:19<00:08, 234.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  51%|█████     | 2182/4319 [00:19<00:09, 219.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  56%|█████▌    | 2408/4319 [00:19<00:08, 222.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  53%|█████▎    | 2310/4319 [00:20<00:09, 203.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  50%|█████     | 2166/4319 [00:19<00:12, 176.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  56%|█████▌    | 2418/4319 [00:19<00:08, 232.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  82%|████████▏ | 3534/4319 [00:19<00:02, 318.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  51%|█████     | 2205/4319 [00:19<00:09, 219.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  57%|█████▋    | 2482/4319 [00:19<00:09, 190.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  57%|█████▋    | 2454/4319 [00:19<00:08, 220.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  54%|█████▍    | 2333/4319 [00:20<00:09, 206.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  56%|█████▋    | 2431/4319 [00:19<00:08, 211.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  51%|█████     | 2185/4319 [00:19<00:12, 177.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  83%|████████▎ | 3572/4319 [00:19<00:02, 335.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  57%|█████▋    | 2442/4319 [00:19<00:08, 232.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  52%|█████▏    | 2231/4319 [00:19<00:09, 227.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  58%|█████▊    | 2506/4319 [00:19<00:09, 196.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  57%|█████▋    | 2481/4319 [00:19<00:08, 224.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  55%|█████▍    | 2355/4319 [00:20<00:09, 209.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  57%|█████▋    | 2456/4319 [00:19<00:08, 221.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  51%|█████     | 2203/4319 [00:19<00:11, 177.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  84%|████████▎ | 3607/4319 [00:19<00:02, 337.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  52%|█████▏    | 2257/4319 [00:19<00:08, 234.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  57%|█████▋    | 2467/4319 [00:19<00:08, 219.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  58%|█████▊    | 2504/4319 [00:19<00:08, 224.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  59%|█████▊    | 2532/4319 [00:19<00:08, 203.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  55%|█████▌    | 2379/4319 [00:20<00:09, 214.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  57%|█████▋    | 2479/4319 [00:19<00:08, 220.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  51%|█████▏    | 2221/4319 [00:20<00:12, 172.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  84%|████████▍ | 3643/4319 [00:19<00:02, 327.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  53%|█████▎    | 2282/4319 [00:20<00:08, 234.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  58%|█████▊    | 2492/4319 [00:20<00:08, 219.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  59%|█████▊    | 2529/4319 [00:19<00:07, 227.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  59%|█████▉    | 2555/4319 [00:20<00:08, 209.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  56%|█████▌    | 2401/4319 [00:20<00:09, 210.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  58%|█████▊    | 2502/4319 [00:20<00:08, 220.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  52%|█████▏    | 2241/4319 [00:20<00:11, 178.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  85%|████████▌ | 3676/4319 [00:20<00:01, 325.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  53%|█████▎    | 2306/4319 [00:20<00:08, 231.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  58%|█████▊    | 2515/4319 [00:20<00:08, 217.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  59%|█████▉    | 2558/4319 [00:20<00:07, 236.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  60%|█████▉    | 2577/4319 [00:20<00:08, 198.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  56%|█████▌    | 2424/4319 [00:20<00:08, 213.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  58%|█████▊    | 2526/4319 [00:20<00:08, 221.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  52%|█████▏    | 2260/4319 [00:20<00:11, 181.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  86%|████████▌ | 3712/4319 [00:20<00:01, 333.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  54%|█████▍    | 2330/4319 [00:20<00:08, 221.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  59%|█████▉    | 2538/4319 [00:20<00:08, 209.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  60%|██████    | 2597/4319 [00:20<00:08, 196.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  60%|█████▉    | 2582/4319 [00:20<00:07, 224.01 examples/s]#015Map (num_proc=8):  57%|█████▋    | 2448/4319 [00:20<00:08, 221.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  59%|█████▉    | 2551/4319 [00:20<00:07, 225.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  53%|█████▎    | 2282/4319 [00:20<00:11, 182.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  87%|████████▋ | 3746/4319 [00:20<00:01, 326.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  55%|█████▍    | 2354/4319 [00:20<00:08, 219.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  59%|█████▉    | 2568/4319 [00:20<00:07, 233.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  57%|█████▋    | 2473/4319 [00:20<00:08, 228.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  61%|██████    | 2617/4319 [00:20<00:08, 194.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  60%|█████▉    | 2574/4319 [00:20<00:07, 222.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  60%|██████    | 2611/4319 [00:20<00:07, 227.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  53%|█████▎    | 2303/4319 [00:20<00:10, 183.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  88%|████████▊ | 3788/4319 [00:20<00:01, 347.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  55%|█████▌    | 2378/4319 [00:20<00:08, 222.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  60%|██████    | 2592/4319 [00:20<00:07, 232.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  61%|██████    | 2637/4319 [00:20<00:08, 194.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  58%|█████▊    | 2497/4319 [00:20<00:08, 218.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  61%|██████    | 2636/4319 [00:20<00:07, 231.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  60%|██████    | 2598/4319 [00:20<00:08, 210.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  54%|█████▍    | 2324/4319 [00:20<00:10, 188.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  89%|████████▊ | 3825/4319 [00:20<00:01, 345.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  56%|█████▌    | 2401/4319 [00:20<00:09, 212.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  61%|██████    | 2618/4319 [00:20<00:07, 233.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  62%|██████▏   | 2658/4319 [00:20<00:08, 189.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  58%|█████▊    | 2521/4319 [00:21<00:08, 218.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  62%|██████▏   | 2662/4319 [00:20<00:07, 229.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  61%|██████    | 2623/4319 [00:20<00:07, 219.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  54%|█████▍    | 2344/4319 [00:20<00:10, 184.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  89%|████████▉ | 3862/4319 [00:20<00:01, 340.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  56%|█████▌    | 2424/4319 [00:20<00:08, 216.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  61%|██████    | 2643/4319 [00:20<00:07, 235.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  62%|██████▏   | 2678/4319 [00:20<00:09, 181.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  59%|█████▉    | 2543/4319 [00:21<00:08, 209.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  62%|██████▏   | 2686/4319 [00:20<00:07, 228.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  61%|██████▏   | 2646/4319 [00:20<00:07, 214.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  55%|█████▍    | 2364/4319 [00:20<00:10, 187.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  90%|█████████ | 3904/4319 [00:20<00:01, 341.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  62%|██████▏   | 2672/4319 [00:20<00:06, 249.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  57%|█████▋    | 2449/4319 [00:20<00:08, 214.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  59%|█████▉    | 2566/4319 [00:21<00:08, 214.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  62%|██████▏   | 2699/4319 [00:20<00:08, 180.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  63%|██████▎   | 2710/4319 [00:20<00:07, 218.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  62%|██████▏   | 2669/4319 [00:20<00:07, 208.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  55%|█████▌    | 2385/4319 [00:20<00:10, 184.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  91%|█████████▏| 3947/4319 [00:20<00:01, 356.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  57%|█████▋    | 2473/4319 [00:20<00:08, 220.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  62%|██████▏   | 2699/4319 [00:20<00:06, 240.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  63%|██████▎   | 2720/4319 [00:20<00:08, 186.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  60%|█████▉    | 2588/4319 [00:21<00:08, 198.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  63%|██████▎   | 2739/4319 [00:20<00:06, 228.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  62%|██████▏   | 2690/4319 [00:20<00:08, 203.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  56%|█████▌    | 2405/4319 [00:21<00:10, 179.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  58%|█████▊    | 2497/4319 [00:21<00:08, 225.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  92%|█████████▏| 3984/4319 [00:20<00:00, 342.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  63%|██████▎   | 2725/4319 [00:21<00:06, 245.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  63%|██████▎   | 2742/4319 [00:21<00:08, 195.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  60%|██████    | 2611/4319 [00:21<00:08, 206.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  64%|██████▍   | 2765/4319 [00:21<00:06, 231.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  56%|█████▌    | 2426/4319 [00:21<00:10, 186.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  63%|██████▎   | 2718/4319 [00:21<00:07, 207.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  58%|█████▊    | 2521/4319 [00:21<00:08, 223.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  93%|█████████▎| 4020/4319 [00:21<00:00, 326.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  64%|██████▎   | 2751/4319 [00:21<00:06, 233.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  64%|██████▍   | 2762/4319 [00:21<00:08, 194.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  61%|██████    | 2632/4319 [00:21<00:08, 206.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  65%|██████▍   | 2789/4319 [00:21<00:06, 228.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  57%|█████▋    | 2446/4319 [00:21<00:10, 187.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  64%|██████▎   | 2743/4319 [00:21<00:07, 208.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  59%|█████▉    | 2546/4319 [00:21<00:08, 219.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  64%|██████▍   | 2777/4319 [00:21<00:06, 240.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  94%|█████████▍| 4054/4319 [00:21<00:00, 316.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  64%|██████▍   | 2783/4319 [00:21<00:07, 198.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  61%|██████▏   | 2653/4319 [00:21<00:08, 200.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  65%|██████▌   | 2818/4319 [00:21<00:06, 240.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  57%|█████▋    | 2467/4319 [00:21<00:09, 186.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  65%|██████▍   | 2803/4319 [00:21<00:06, 245.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  64%|██████▍   | 2771/4319 [00:21<00:07, 217.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  60%|█████▉    | 2575/4319 [00:21<00:07, 229.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  65%|██████▍   | 2804/4319 [00:21<00:07, 199.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  95%|█████████▍| 4086/4319 [00:21<00:00, 298.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  62%|██████▏   | 2676/4319 [00:21<00:08, 201.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  58%|█████▊    | 2486/4319 [00:21<00:09, 186.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  66%|██████▌   | 2845/4319 [00:21<00:06, 233.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  60%|██████    | 2603/4319 [00:21<00:07, 238.74 examples/s]#015Map (num_proc=8):  65%|██████▍   | 2793/4319 [00:21<00:07, 208.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  66%|██████▌   | 2830/4319 [00:21<00:06, 237.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  65%|██████▌   | 2826/4319 [00:21<00:07, 194.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  95%|█████████▌| 4117/4319 [00:21<00:00, 290.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  63%|██████▎   | 2700/4319 [00:21<00:07, 207.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  58%|█████▊    | 2506/4319 [00:21<00:09, 189.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  66%|██████▋   | 2870/4319 [00:21<00:06, 237.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  65%|██████▌   | 2815/4319 [00:21<00:07, 207.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  66%|██████▌   | 2855/4319 [00:21<00:06, 238.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  61%|██████    | 2629/4319 [00:21<00:07, 236.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  96%|█████████▌| 4147/4319 [00:21<00:00, 292.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  66%|██████▌   | 2847/4319 [00:21<00:07, 190.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  63%|██████▎   | 2722/4319 [00:22<00:07, 209.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  58%|█████▊    | 2525/4319 [00:21<00:09, 189.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  67%|██████▋   | 2900/4319 [00:21<00:05, 253.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  67%|██████▋   | 2881/4319 [00:21<00:05, 243.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  61%|██████▏   | 2653/4319 [00:21<00:07, 236.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  66%|██████▌   | 2837/4319 [00:21<00:07, 206.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  97%|█████████▋| 4178/4319 [00:21<00:00, 284.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  66%|██████▋   | 2867/4319 [00:21<00:07, 186.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  64%|██████▎   | 2745/4319 [00:22<00:07, 206.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  59%|█████▉    | 2544/4319 [00:21<00:09, 182.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  68%|██████▊   | 2926/4319 [00:21<00:05, 247.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  62%|██████▏   | 2677/4319 [00:21<00:07, 234.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  66%|██████▌   | 2860/4319 [00:21<00:07, 208.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  67%|██████▋   | 2907/4319 [00:21<00:05, 235.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  97%|█████████▋| 4211/4319 [00:21<00:00, 295.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  67%|██████▋   | 2892/4319 [00:21<00:07, 194.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  59%|█████▉    | 2564/4319 [00:21<00:09, 187.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  64%|██████▍   | 2770/4319 [00:22<00:07, 212.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  68%|██████▊   | 2952/4319 [00:21<00:05, 235.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  67%|██████▋   | 2885/4319 [00:21<00:06, 219.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  63%|██████▎   | 2701/4319 [00:21<00:07, 230.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  68%|██████▊   | 2939/4319 [00:21<00:05, 237.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  60%|█████▉    | 2583/4319 [00:21<00:09, 179.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  67%|██████▋   | 2914/4319 [00:21<00:07, 184.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  65%|██████▍   | 2797/4319 [00:22<00:07, 210.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  98%|█████████▊| 4241/4319 [00:21<00:00, 254.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  69%|██████▉   | 2979/4319 [00:21<00:05, 236.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  63%|██████▎   | 2727/4319 [00:22<00:06, 230.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  67%|██████▋   | 2909/4319 [00:22<00:06, 210.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  69%|██████▊   | 2967/4319 [00:22<00:05, 244.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  60%|██████    | 2605/4319 [00:22<00:09, 179.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  70%|██████▉   | 3005/4319 [00:22<00:05, 241.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  66%|██████▌   | 2829/4319 [00:22<00:06, 232.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  68%|██████▊   | 2941/4319 [00:22<00:07, 196.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  68%|██████▊   | 2931/4319 [00:22<00:06, 212.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  64%|██████▍   | 2759/4319 [00:22<00:06, 232.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  69%|██████▉   | 2996/4319 [00:22<00:05, 251.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  99%|█████████▉| 4270/4319 [00:22<00:00, 212.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  61%|██████    | 2623/4319 [00:22<00:09, 178.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  69%|██████▊   | 2962/4319 [00:22<00:06, 198.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  66%|██████▌   | 2854/4319 [00:22<00:06, 226.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  70%|███████   | 3030/4319 [00:22<00:05, 222.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  68%|██████▊   | 2953/4319 [00:22<00:06, 203.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  65%|██████▍   | 2788/4319 [00:22<00:06, 241.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  70%|██████▉   | 3023/4319 [00:22<00:05, 249.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  61%|██████    | 2641/4319 [00:22<00:09, 175.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  69%|██████▉   | 2983/4319 [00:22<00:06, 195.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  67%|██████▋   | 2878/4319 [00:22<00:06, 227.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  71%|███████   | 3058/4319 [00:22<00:05, 228.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  69%|██████▉   | 2979/4319 [00:22<00:06, 218.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  71%|███████   | 3050/4319 [00:22<00:05, 249.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  65%|██████▌   | 2813/4319 [00:22<00:06, 235.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  62%|██████▏   | 2662/4319 [00:22<00:09, 181.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  67%|██████▋   | 2901/4319 [00:22<00:06, 226.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  70%|██████▉   | 3006/4319 [00:22<00:06, 199.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  71%|███████▏  | 3082/4319 [00:22<00:05, 224.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  99%|█████████▉| 4293/4319 [00:22<00:00, 155.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  70%|██████▉   | 3004/4319 [00:22<00:06, 217.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  66%|██████▌   | 2841/4319 [00:22<00:06, 241.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  71%|███████   | 3076/4319 [00:22<00:05, 232.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  62%|██████▏   | 2681/4319 [00:22<00:08, 183.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  68%|██████▊   | 2929/4319 [00:22<00:05, 240.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  70%|███████   | 3027/4319 [00:22<00:06, 198.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  72%|███████▏  | 3106/4319 [00:22<00:05, 224.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  66%|██████▋   | 2866/4319 [00:22<00:05, 242.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  70%|███████   | 3028/4319 [00:22<00:06, 208.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  72%|███████▏  | 3107/4319 [00:22<00:04, 253.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  63%|██████▎   | 2700/4319 [00:22<00:08, 184.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  68%|██████▊   | 2955/4319 [00:23<00:05, 238.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  71%|███████   | 3047/4319 [00:22<00:06, 192.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  73%|███████▎  | 3133/4319 [00:22<00:05, 228.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  67%|██████▋   | 2892/4319 [00:22<00:05, 244.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  71%|███████   | 3052/4319 [00:22<00:05, 213.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  63%|██████▎   | 2719/4319 [00:22<00:08, 180.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  69%|██████▉   | 2980/4319 [00:23<00:05, 240.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  73%|███████▎  | 3133/4319 [00:22<00:05, 230.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  71%|███████   | 3069/4319 [00:22<00:06, 196.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  73%|███████▎  | 3157/4319 [00:22<00:05, 229.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  71%|███████   | 3074/4319 [00:22<00:05, 211.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  68%|██████▊   | 2918/4319 [00:22<00:05, 237.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  64%|██████▎   | 2745/4319 [00:22<00:07, 201.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  73%|███████▎  | 3161/4319 [00:22<00:04, 240.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  70%|██████▉   | 3006/4319 [00:23<00:05, 233.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  72%|███████▏  | 3089/4319 [00:22<00:06, 186.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  74%|███████▎  | 3183/4319 [00:22<00:04, 231.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  72%|███████▏  | 3096/4319 [00:22<00:05, 211.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  64%|██████▍   | 2767/4319 [00:22<00:07, 205.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  68%|██████▊   | 2946/4319 [00:22<00:05, 236.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  70%|███████   | 3031/4319 [00:23<00:05, 229.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  74%|███████▍  | 3186/4319 [00:22<00:04, 233.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  72%|███████▏  | 3108/4319 [00:22<00:06, 183.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  74%|███████▍  | 3211/4319 [00:22<00:04, 235.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  65%|██████▍   | 2789/4319 [00:23<00:07, 209.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  69%|██████▉   | 2971/4319 [00:23<00:05, 239.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  72%|███████▏  | 3120/4319 [00:23<00:05, 205.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  74%|███████▍  | 3211/4319 [00:23<00:04, 227.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  71%|███████   | 3061/4319 [00:23<00:05, 230.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  72%|███████▏  | 3127/4319 [00:23<00:06, 177.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  75%|███████▌  | 3243/4319 [00:23<00:04, 251.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  65%|██████▌   | 2813/4319 [00:23<00:06, 217.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  73%|███████▎  | 3144/4319 [00:23<00:05, 215.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  69%|██████▉   | 2997/4319 [00:23<00:05, 243.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  71%|███████▏  | 3087/4319 [00:23<00:05, 238.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  75%|███████▍  | 3235/4319 [00:23<00:04, 219.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  73%|███████▎  | 3150/4319 [00:23<00:06, 185.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  76%|███████▌  | 3272/4319 [00:23<00:04, 256.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  66%|██████▌   | 2835/4319 [00:23<00:06, 216.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  70%|███████   | 3027/4319 [00:23<00:05, 256.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  73%|███████▎  | 3167/4319 [00:23<00:05, 213.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  72%|███████▏  | 3111/4319 [00:23<00:05, 233.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  76%|███████▌  | 3264/4319 [00:23<00:04, 237.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  76%|███████▋  | 3300/4319 [00:23<00:03, 259.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  73%|███████▎  | 3169/4319 [00:23<00:06, 176.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  71%|███████   | 3053/4319 [00:23<00:05, 250.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  74%|███████▍  | 3189/4319 [00:23<00:05, 204.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  66%|██████▌   | 2858/4319 [00:23<00:07, 200.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  76%|███████▌  | 3289/4319 [00:23<00:04, 231.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  73%|███████▎  | 3135/4319 [00:23<00:05, 223.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  74%|███████▍  | 3193/4319 [00:23<00:05, 192.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  77%|███████▋  | 3327/4319 [00:23<00:03, 249.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  71%|███████▏  | 3079/4319 [00:23<00:04, 250.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  67%|██████▋   | 2882/4319 [00:23<00:06, 210.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  74%|███████▍  | 3210/4319 [00:23<00:05, 200.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  73%|███████▎  | 3160/4319 [00:23<00:05, 230.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  77%|███████▋  | 3316/4319 [00:23<00:04, 234.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  74%|███████▍  | 3214/4319 [00:23<00:05, 193.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  78%|███████▊  | 3357/4319 [00:23<00:03, 258.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  72%|███████▏  | 3108/4319 [00:23<00:04, 248.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  67%|██████▋   | 2906/4319 [00:23<00:06, 209.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  75%|███████▍  | 3232/4319 [00:23<00:05, 197.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  74%|███████▎  | 3184/4319 [00:24<00:04, 229.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  75%|███████▍  | 3235/4319 [00:23<00:05, 193.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  77%|███████▋  | 3346/4319 [00:23<00:04, 236.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  73%|███████▎  | 3134/4319 [00:23<00:04, 250.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  78%|███████▊  | 3383/4319 [00:23<00:03, 241.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  68%|██████▊   | 2928/4319 [00:23<00:06, 202.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  75%|███████▌  | 3253/4319 [00:23<00:05, 194.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  74%|███████▍  | 3212/4319 [00:24<00:04, 241.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  78%|███████▊  | 3373/4319 [00:23<00:03, 241.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  75%|███████▌  | 3256/4319 [00:23<00:05, 184.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  79%|███████▉  | 3408/4319 [00:23<00:03, 234.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  73%|███████▎  | 3161/4319 [00:23<00:04, 239.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  76%|███████▌  | 3273/4319 [00:23<00:05, 184.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  68%|██████▊   | 2950/4319 [00:23<00:07, 190.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  75%|███████▌  | 3242/4319 [00:24<00:04, 251.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  79%|███████▊  | 3399/4319 [00:23<00:03, 237.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  76%|███████▌  | 3275/4319 [00:23<00:05, 180.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  79%|███████▉  | 3432/4319 [00:23<00:03, 232.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  74%|███████▍  | 3188/4319 [00:23<00:04, 246.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  76%|███████▋  | 3295/4319 [00:23<00:05, 193.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  69%|██████▉   | 2974/4319 [00:23<00:06, 199.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  76%|███████▌  | 3268/4319 [00:24<00:04, 239.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  79%|███████▉  | 3423/4319 [00:23<00:03, 232.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  76%|███████▋  | 3294/4319 [00:23<00:05, 181.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  80%|████████  | 3457/4319 [00:23<00:03, 236.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  74%|███████▍  | 3213/4319 [00:24<00:04, 238.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  77%|███████▋  | 3315/4319 [00:24<00:05, 192.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  69%|██████▉   | 2999/4319 [00:24<00:06, 211.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  76%|███████▋  | 3294/4319 [00:24<00:04, 236.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  77%|███████▋  | 3313/4319 [00:24<00:05, 181.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  80%|███████▉  | 3447/4319 [00:24<00:03, 225.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  81%|████████  | 3482/4319 [00:24<00:03, 230.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  75%|███████▌  | 3241/4319 [00:24<00:04, 250.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  77%|███████▋  | 3335/4319 [00:24<00:05, 184.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  70%|███████   | 3024/4319 [00:24<00:06, 214.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  77%|███████▋  | 3321/4319 [00:24<00:04, 235.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  80%|████████  | 3472/4319 [00:24<00:03, 231.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  77%|███████▋  | 3333/4319 [00:24<00:05, 180.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  81%|████████▏ | 3511/4319 [00:24<00:03, 240.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  76%|███████▌  | 3268/4319 [00:24<00:04, 246.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  71%|███████   | 3046/4319 [00:24<00:06, 211.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  78%|███████▊  | 3358/4319 [00:24<00:05, 187.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  78%|███████▊  | 3352/4319 [00:24<00:05, 180.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  78%|███████▊  | 3348/4319 [00:24<00:04, 230.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  81%|████████  | 3497/4319 [00:24<00:03, 218.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  82%|████████▏ | 3537/4319 [00:24<00:03, 234.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  76%|███████▌  | 3293/4319 [00:24<00:04, 237.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  71%|███████   | 3069/4319 [00:24<00:05, 214.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  78%|███████▊  | 3378/4319 [00:24<00:04, 189.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  78%|███████▊  | 3371/4319 [00:24<00:05, 178.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  78%|███████▊  | 3378/4319 [00:24<00:03, 239.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  77%|███████▋  | 3319/4319 [00:24<00:04, 241.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  82%|████████▏ | 3520/4319 [00:24<00:03, 201.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  82%|████████▏ | 3563/4319 [00:24<00:03, 224.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  72%|███████▏  | 3093/4319 [00:24<00:05, 219.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  79%|███████▊  | 3398/4319 [00:24<00:04, 188.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  79%|███████▊  | 3391/4319 [00:24<00:05, 179.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  79%|███████▉  | 3408/4319 [00:25<00:03, 237.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  77%|███████▋  | 3345/4319 [00:24<00:04, 236.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  83%|████████▎ | 3587/4319 [00:24<00:03, 222.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  82%|████████▏ | 3544/4319 [00:24<00:03, 204.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  72%|███████▏  | 3117/4319 [00:24<00:05, 217.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  79%|███████▉  | 3418/4319 [00:24<00:05, 179.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  79%|███████▉  | 3414/4319 [00:24<00:04, 181.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  80%|███████▉  | 3436/4319 [00:25<00:03, 246.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  78%|███████▊  | 3370/4319 [00:24<00:04, 227.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  84%|████████▎ | 3611/4319 [00:24<00:03, 223.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  73%|███████▎  | 3139/4319 [00:24<00:05, 214.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  83%|████████▎ | 3565/4319 [00:24<00:03, 198.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  80%|███████▉  | 3440/4319 [00:24<00:04, 189.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  80%|███████▉  | 3436/4319 [00:24<00:04, 189.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  79%|███████▊  | 3396/4319 [00:24<00:03, 234.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  80%|████████  | 3462/4319 [00:25<00:03, 230.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  73%|███████▎  | 3162/4319 [00:24<00:05, 215.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  84%|████████▍ | 3638/4319 [00:24<00:02, 229.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  83%|████████▎ | 3588/4319 [00:24<00:03, 201.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  80%|████████  | 3460/4319 [00:24<00:04, 190.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  80%|████████  | 3457/4319 [00:24<00:04, 190.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  79%|███████▉  | 3421/4319 [00:24<00:03, 227.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  84%|████████▎ | 3612/4319 [00:24<00:03, 211.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  85%|████████▍ | 3665/4319 [00:24<00:02, 233.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  74%|███████▎  | 3184/4319 [00:24<00:05, 209.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  81%|████████  | 3483/4319 [00:24<00:04, 200.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  81%|████████  | 3487/4319 [00:25<00:03, 218.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  81%|████████  | 3478/4319 [00:24<00:04, 193.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  74%|███████▍  | 3209/4319 [00:25<00:05, 218.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  80%|███████▉  | 3448/4319 [00:24<00:03, 232.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  84%|████████▍ | 3635/4319 [00:25<00:03, 207.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  81%|████████  | 3504/4319 [00:24<00:04, 197.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  85%|████████▌ | 3691/4319 [00:24<00:02, 227.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  81%|████████▏ | 3511/4319 [00:25<00:03, 215.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  81%|████████  | 3500/4319 [00:25<00:04, 195.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  75%|███████▍  | 3239/4319 [00:25<00:04, 241.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  82%|████████▏ | 3526/4319 [00:25<00:03, 200.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  80%|████████  | 3473/4319 [00:25<00:03, 224.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  85%|████████▍ | 3658/4319 [00:25<00:03, 204.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  86%|████████▌ | 3714/4319 [00:25<00:02, 219.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  82%|████████▏ | 3534/4319 [00:25<00:03, 213.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  82%|████████▏ | 3520/4319 [00:25<00:04, 192.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  76%|███████▌  | 3265/4319 [00:25<00:04, 237.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  82%|████████▏ | 3549/4319 [00:25<00:03, 206.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  81%|████████  | 3501/4319 [00:25<00:03, 237.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  87%|████████▋ | 3745/4319 [00:25<00:02, 238.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  85%|████████▌ | 3684/4319 [00:25<00:03, 210.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  82%|████████▏ | 3556/4319 [00:25<00:03, 209.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  82%|████████▏ | 3542/4319 [00:25<00:04, 189.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  76%|███████▌  | 3291/4319 [00:25<00:04, 237.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  83%|████████▎ | 3573/4319 [00:25<00:03, 211.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  82%|████████▏ | 3525/4319 [00:25<00:03, 230.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  86%|████████▌ | 3707/4319 [00:25<00:02, 211.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  87%|████████▋ | 3769/4319 [00:25<00:02, 225.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  83%|████████▎ | 3580/4319 [00:25<00:03, 206.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  83%|████████▎ | 3564/4319 [00:25<00:03, 195.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  77%|███████▋  | 3316/4319 [00:25<00:04, 235.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  82%|████████▏ | 3550/4319 [00:25<00:03, 235.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  83%|████████▎ | 3596/4319 [00:25<00:03, 206.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  86%|████████▋ | 3731/4319 [00:25<00:02, 211.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  83%|████████▎ | 3601/4319 [00:25<00:03, 204.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  83%|████████▎ | 3586/4319 [00:25<00:03, 192.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  88%|████████▊ | 3793/4319 [00:25<00:02, 192.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  84%|████████▍ | 3619/4319 [00:25<00:03, 212.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  77%|███████▋  | 3347/4319 [00:25<00:04, 238.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  87%|████████▋ | 3753/4319 [00:25<00:02, 212.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  84%|████████▍ | 3623/4319 [00:26<00:03, 207.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  83%|████████▎ | 3575/4319 [00:25<00:03, 210.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  88%|████████▊ | 3815/4319 [00:25<00:02, 195.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  84%|████████▎ | 3608/4319 [00:25<00:03, 189.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  78%|███████▊  | 3376/4319 [00:25<00:03, 251.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  84%|████████▍ | 3647/4319 [00:25<00:03, 223.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  87%|████████▋ | 3776/4319 [00:25<00:02, 213.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  84%|████████▍ | 3644/4319 [00:26<00:03, 204.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  83%|████████▎ | 3597/4319 [00:25<00:03, 205.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  89%|████████▉ | 3836/4319 [00:25<00:02, 184.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  79%|███████▉  | 3402/4319 [00:25<00:03, 244.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  84%|████████▍ | 3628/4319 [00:25<00:03, 176.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  85%|████████▍ | 3670/4319 [00:25<00:03, 215.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  88%|████████▊ | 3799/4319 [00:25<00:02, 205.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  85%|████████▍ | 3666/4319 [00:26<00:03, 196.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  84%|████████▍ | 3618/4319 [00:25<00:03, 191.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  79%|███████▉  | 3431/4319 [00:25<00:03, 254.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  85%|████████▌ | 3692/4319 [00:25<00:02, 216.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  84%|████████▍ | 3649/4319 [00:25<00:03, 183.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  89%|████████▉ | 3860/4319 [00:25<00:02, 191.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  88%|████████▊ | 3822/4319 [00:25<00:02, 203.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  85%|████████▌ | 3687/4319 [00:26<00:03, 195.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  84%|████████▍ | 3640/4319 [00:25<00:03, 187.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  80%|████████  | 3457/4319 [00:25<00:03, 254.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  86%|████████▌ | 3715/4319 [00:25<00:02, 214.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  90%|████████▉ | 3882/4319 [00:25<00:02, 185.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  86%|████████▌ | 3709/4319 [00:26<00:03, 199.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  85%|████████▌ | 3672/4319 [00:26<00:03, 177.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  89%|████████▉ | 3847/4319 [00:26<00:02, 204.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  85%|████████▍ | 3660/4319 [00:26<00:03, 186.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  87%|████████▋ | 3741/4319 [00:26<00:02, 221.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  81%|████████  | 3485/4319 [00:26<00:03, 246.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  85%|████████▌ | 3690/4319 [00:26<00:03, 176.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  90%|█████████ | 3906/4319 [00:26<00:02, 191.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  90%|████████▉ | 3873/4319 [00:26<00:02, 216.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  86%|████████▋ | 3729/4319 [00:26<00:03, 188.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  85%|████████▌ | 3679/4319 [00:26<00:03, 179.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  87%|████████▋ | 3766/4319 [00:26<00:02, 229.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  81%|████████▏ | 3514/4319 [00:26<00:03, 257.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  91%|█████████ | 3929/4319 [00:26<00:01, 199.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  86%|████████▌ | 3709/4319 [00:26<00:03, 174.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  90%|█████████ | 3896/4319 [00:26<00:01, 216.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  87%|████████▋ | 3755/4319 [00:26<00:02, 198.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  86%|████████▌ | 3700/4319 [00:26<00:03, 174.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  82%|████████▏ | 3540/4319 [00:26<00:03, 251.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  88%|████████▊ | 3790/4319 [00:26<00:02, 216.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  91%|█████████▏| 3951/4319 [00:26<00:01, 194.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  91%|█████████ | 3918/4319 [00:26<00:01, 209.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  86%|████████▋ | 3728/4319 [00:26<00:03, 166.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  87%|████████▋ | 3777/4319 [00:26<00:02, 200.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  83%|████████▎ | 3569/4319 [00:26<00:02, 259.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  88%|████████▊ | 3812/4319 [00:26<00:02, 208.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  86%|████████▌ | 3718/4319 [00:26<00:03, 162.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  91%|█████████▏| 3943/4319 [00:26<00:01, 219.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  92%|█████████▏| 3973/4319 [00:26<00:01, 197.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  87%|████████▋ | 3746/4319 [00:26<00:03, 163.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  88%|████████▊ | 3799/4319 [00:26<00:02, 187.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  83%|████████▎ | 3602/4319 [00:26<00:02, 259.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  87%|████████▋ | 3742/4319 [00:26<00:03, 180.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  89%|████████▉ | 3836/4319 [00:26<00:02, 213.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  92%|█████████▏| 3966/4319 [00:26<00:01, 217.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  93%|█████████▎| 3996/4319 [00:26<00:01, 190.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  87%|████████▋ | 3768/4319 [00:26<00:03, 170.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  88%|████████▊ | 3819/4319 [00:27<00:02, 189.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  84%|████████▍ | 3639/4319 [00:26<00:02, 275.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  89%|████████▉ | 3858/4319 [00:26<00:02, 204.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  92%|█████████▏| 3988/4319 [00:26<00:01, 215.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  93%|█████████▎| 4017/4319 [00:26<00:01, 194.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  87%|████████▋ | 3761/4319 [00:26<00:03, 159.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  89%|████████▉ | 3839/4319 [00:27<00:02, 191.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  88%|████████▊ | 3786/4319 [00:26<00:03, 157.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  85%|████████▍ | 3669/4319 [00:26<00:02, 275.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  93%|█████████▎| 4012/4319 [00:26<00:01, 216.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  90%|████████▉ | 3880/4319 [00:26<00:02, 197.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  88%|████████▊ | 3783/4319 [00:26<00:03, 173.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  93%|█████████▎| 4038/4319 [00:26<00:01, 185.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  89%|████████▉ | 3859/4319 [00:27<00:02, 177.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  88%|████████▊ | 3807/4319 [00:26<00:03, 167.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  86%|████████▌ | 3703/4319 [00:26<00:02, 286.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  93%|█████████▎| 4038/4319 [00:26<00:01, 221.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  90%|█████████ | 3902/4319 [00:26<00:02, 197.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  94%|█████████▍| 4057/4319 [00:26<00:01, 184.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  90%|████████▉ | 3881/4319 [00:27<00:02, 185.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  88%|████████▊ | 3802/4319 [00:26<00:03, 159.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  89%|████████▊ | 3824/4319 [00:26<00:03, 156.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  87%|████████▋ | 3736/4319 [00:26<00:01, 295.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  91%|█████████ | 3925/4319 [00:26<00:01, 205.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  94%|█████████▍| 4061/4319 [00:26<00:01, 217.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  88%|████████▊ | 3820/4319 [00:27<00:03, 164.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  90%|█████████ | 3901/4319 [00:27<00:02, 186.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  87%|████████▋ | 3767/4319 [00:27<00:01, 299.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  89%|████████▉ | 3841/4319 [00:27<00:03, 151.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  91%|█████████▏| 3947/4319 [00:27<00:01, 204.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  91%|█████████ | 3920/4319 [00:27<00:02, 187.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  89%|████████▉ | 3838/4319 [00:27<00:02, 162.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  95%|█████████▍| 4084/4319 [00:27<00:01, 179.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  88%|████████▊ | 3797/4319 [00:27<00:01, 295.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  94%|█████████▍| 4076/4319 [00:27<00:01, 126.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  92%|█████████▏| 3969/4319 [00:27<00:01, 204.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  89%|████████▉ | 3857/4319 [00:27<00:03, 140.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  91%|█████████▏| 3942/4319 [00:27<00:01, 191.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  89%|████████▉ | 3856/4319 [00:27<00:02, 159.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  95%|█████████▌| 4104/4319 [00:27<00:01, 175.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  89%|████████▊ | 3829/4319 [00:27<00:01, 286.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  92%|█████████▏| 3992/4319 [00:27<00:01, 210.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  90%|████████▉ | 3872/4319 [00:27<00:03, 136.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  92%|█████████▏| 3963/4319 [00:27<00:01, 193.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  95%|█████████▍| 4092/4319 [00:27<00:02, 111.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  90%|████████▉ | 3873/4319 [00:27<00:02, 155.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  89%|████████▉ | 3858/4319 [00:27<00:01, 283.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  93%|█████████▎| 4018/4319 [00:27<00:01, 214.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  90%|████████▉ | 3886/4319 [00:27<00:03, 136.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  95%|█████████▌| 4124/4319 [00:27<00:01, 160.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  92%|█████████▏| 3987/4319 [00:27<00:01, 205.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  90%|█████████ | 3891/4319 [00:27<00:02, 159.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  90%|█████████ | 3889/4319 [00:27<00:01, 268.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  94%|█████████▎| 4045/4319 [00:27<00:01, 221.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  90%|█████████ | 3901/4319 [00:27<00:03, 132.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  93%|█████████▎| 4008/4319 [00:28<00:01, 202.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  95%|█████████▌| 4106/4319 [00:27<00:02, 98.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  91%|█████████ | 3909/4319 [00:27<00:02, 162.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  96%|█████████▌| 4142/4319 [00:27<00:01, 135.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  91%|█████████ | 3917/4319 [00:27<00:01, 257.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  94%|█████████▍| 4068/4319 [00:27<00:01, 211.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  93%|█████████▎| 4030/4319 [00:28<00:01, 206.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  91%|█████████ | 3915/4319 [00:27<00:03, 130.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  95%|█████████▌| 4118/4319 [00:27<00:02, 99.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  91%|█████████ | 3929/4319 [00:27<00:02, 161.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  91%|█████████▏| 3943/4319 [00:27<00:01, 249.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  94%|█████████▍| 4052/4319 [00:28<00:01, 206.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  95%|█████████▍| 4090/4319 [00:27<00:01, 198.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  91%|█████████ | 3933/4319 [00:27<00:02, 134.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  91%|█████████▏| 3950/4319 [00:27<00:02, 173.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  96%|█████████▌| 4130/4319 [00:27<00:01, 95.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  96%|█████████▋| 4158/4319 [00:27<00:01, 117.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  92%|█████████▏| 3971/4319 [00:27<00:01, 253.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  94%|█████████▍| 4074/4319 [00:28<00:01, 201.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  91%|█████████▏| 3950/4319 [00:27<00:02, 139.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  95%|█████████▌| 4111/4319 [00:27<00:01, 181.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  92%|█████████▏| 3968/4319 [00:27<00:02, 170.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  96%|█████████▌| 4142/4319 [00:27<00:01, 93.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  93%|█████████▎| 4002/4319 [00:28<00:01, 256.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  95%|█████████▍| 4096/4319 [00:28<00:01, 205.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  92%|█████████▏| 3965/4319 [00:28<00:02, 139.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  97%|█████████▋| 4172/4319 [00:28<00:01, 100.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  92%|█████████▏| 3987/4319 [00:28<00:01, 167.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  96%|█████████▌| 4131/4319 [00:28<00:01, 166.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  95%|█████████▌| 4117/4319 [00:28<00:00, 202.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  93%|█████████▎| 4028/4319 [00:28<00:01, 251.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  96%|█████████▌| 4153/4319 [00:28<00:01, 87.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  92%|█████████▏| 3985/4319 [00:28<00:02, 141.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  93%|█████████▎| 4005/4319 [00:28<00:01, 157.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  97%|█████████▋| 4184/4319 [00:28<00:01, 92.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  96%|█████████▌| 4149/4319 [00:28<00:01, 153.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  94%|█████████▍| 4056/4319 [00:28<00:01, 238.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  96%|█████████▌| 4139/4319 [00:28<00:00, 183.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  93%|█████████▎| 4006/4319 [00:28<00:02, 148.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  96%|█████████▋| 4163/4319 [00:28<00:01, 78.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  93%|█████████▎| 4022/4319 [00:28<00:01, 155.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  97%|█████████▋| 4196/4319 [00:28<00:01, 93.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  96%|█████████▋| 4165/4319 [00:28<00:01, 148.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  95%|█████████▍| 4083/4319 [00:28<00:01, 232.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  93%|█████████▎| 4023/4319 [00:28<00:01, 153.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  96%|█████████▋| 4159/4319 [00:28<00:00, 165.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  93%|█████████▎| 4038/4319 [00:28<00:01, 153.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  97%|█████████▋| 4209/4319 [00:28<00:01, 94.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  97%|█████████▋| 4173/4319 [00:28<00:02, 70.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  95%|█████████▌| 4110/4319 [00:28<00:00, 229.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  97%|█████████▋| 4182/4319 [00:28<00:00, 139.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  94%|█████████▎| 4040/4319 [00:28<00:01, 145.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  94%|█████████▍| 4054/4319 [00:28<00:01, 148.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  97%|█████████▋| 4177/4319 [00:29<00:00, 156.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  98%|█████████▊| 4221/4319 [00:28<00:00, 98.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  96%|█████████▌| 4137/4319 [00:28<00:00, 235.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  97%|█████████▋| 4181/4319 [00:28<00:02, 68.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  97%|█████████▋| 4197/4319 [00:28<00:00, 131.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  94%|█████████▍| 4071/4319 [00:28<00:01, 154.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  94%|█████████▍| 4061/4319 [00:28<00:01, 150.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  96%|█████████▋| 4161/4319 [00:28<00:00, 234.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  97%|█████████▋| 4196/4319 [00:29<00:00, 143.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  98%|█████████▊| 4234/4319 [00:28<00:00, 98.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  97%|█████████▋| 4189/4319 [00:28<00:01, 68.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  95%|█████████▍| 4091/4319 [00:28<00:01, 166.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  97%|█████████▋| 4211/4319 [00:28<00:00, 125.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  94%|█████████▍| 4081/4319 [00:28<00:01, 158.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  97%|█████████▋| 4189/4319 [00:28<00:00, 231.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  98%|█████████▊| 4213/4319 [00:29<00:00, 139.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  97%|█████████▋| 4198/4319 [00:28<00:01, 69.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  95%|█████████▌| 4108/4319 [00:28<00:01, 158.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  98%|█████████▊| 4225/4319 [00:28<00:00, 122.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  95%|█████████▍| 4099/4319 [00:28<00:01, 162.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  98%|█████████▊| 4247/4319 [00:28<00:00, 88.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  98%|█████████▊| 4214/4319 [00:28<00:00, 223.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  96%|█████████▌| 4125/4319 [00:28<00:01, 152.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  97%|█████████▋| 4207/4319 [00:28<00:01, 69.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  95%|█████████▌| 4117/4319 [00:28<00:01, 162.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  98%|█████████▊| 4239/4319 [00:28<00:00, 117.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  99%|█████████▊| 4258/4319 [00:29<00:00, 85.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  98%|█████████▊| 4230/4319 [00:29<00:00, 117.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  98%|█████████▊| 4237/4319 [00:29<00:00, 201.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  96%|█████████▌| 4135/4319 [00:29<00:01, 162.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  96%|█████████▌| 4146/4319 [00:29<00:01, 158.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  98%|█████████▊| 4217/4319 [00:29<00:01, 72.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  98%|█████████▊| 4251/4319 [00:29<00:00, 111.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  98%|█████████▊| 4244/4319 [00:29<00:00, 105.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  98%|█████████▊| 4227/4319 [00:29<00:01, 76.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  96%|█████████▋| 4167/4319 [00:29<00:00, 163.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  96%|█████████▌| 4155/4319 [00:29<00:01, 160.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  99%|█████████▉| 4268/4319 [00:29<00:00, 73.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  99%|█████████▊| 4258/4319 [00:29<00:00, 179.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  99%|█████████▊| 4263/4319 [00:29<00:00, 105.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  98%|█████████▊| 4235/4319 [00:29<00:01, 75.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  97%|█████████▋| 4174/4319 [00:29<00:00, 161.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  97%|█████████▋| 4187/4319 [00:29<00:00, 164.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  99%|█████████▊| 4257/4319 [00:29<00:00, 99.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  99%|█████████▉| 4274/4319 [00:29<00:00, 96.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  99%|█████████▉| 4278/4319 [00:29<00:00, 158.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  99%|█████████▉| 4276/4319 [00:29<00:00, 62.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  97%|█████████▋| 4204/4319 [00:29<00:00, 162.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  97%|█████████▋| 4191/4319 [00:29<00:00, 158.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  98%|█████████▊| 4245/4319 [00:29<00:00, 75.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  99%|█████████▉| 4268/4319 [00:29<00:00, 98.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  97%|█████████▋| 4207/4319 [00:29<00:00, 157.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  98%|█████████▊| 4222/4319 [00:29<00:00, 159.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  99%|█████████▊| 4255/4319 [00:29<00:00, 80.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  99%|█████████▉| 4284/4319 [00:29<00:00, 83.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  99%|█████████▉| 4283/4319 [00:29<00:00, 56.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  99%|█████████▉| 4279/4319 [00:30<00:00, 96.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  98%|█████████▊| 4224/4319 [00:29<00:00, 155.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  98%|█████████▊| 4239/4319 [00:29<00:00, 157.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  99%|█████████▉| 4296/4319 [00:29<00:00, 115.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  99%|█████████▊| 4264/4319 [00:29<00:00, 77.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  99%|█████████▉| 4294/4319 [00:29<00:00, 82.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  99%|█████████▉| 4289/4319 [00:30<00:00, 81.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  99%|█████████▉| 4291/4319 [00:29<00:00, 51.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  99%|█████████▊| 4257/4319 [00:29<00:00, 153.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  98%|█████████▊| 4240/4319 [00:29<00:00, 140.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  99%|█████████▉| 4273/4319 [00:29<00:00, 74.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|█████████▉| 4303/4319 [00:29<00:00, 76.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|█████████▉| 4312/4319 [00:29<00:00, 105.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  99%|█████████▊| 4255/4319 [00:29<00:00, 136.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  99%|█████████▉| 4275/4319 [00:29<00:00, 147.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  99%|█████████▉| 4297/4319 [00:29<00:00, 46.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  99%|█████████▉| 4282/4319 [00:29<00:00, 72.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|█████████▉| 4312/4319 [00:29<00:00, 73.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|█████████▉| 4298/4319 [00:30<00:00, 66.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  99%|█████████▉| 4270/4319 [00:30<00:00, 127.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  99%|█████████▉| 4292/4319 [00:30<00:00, 140.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  99%|█████████▉| 4291/4319 [00:30<00:00, 70.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|█████████▉| 4304/4319 [00:30<00:00, 44.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  99%|█████████▉| 4283/4319 [00:30<00:00, 121.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|█████████▉| 4301/4319 [00:30<00:00, 76.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|█████████▉| 4308/4319 [00:30<00:00, 58.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|█████████▉| 4309/4319 [00:30<00:00, 43.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|█████████▉| 4309/4319 [00:30<00:00, 76.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|█████████▉| 4309/4319 [00:30<00:00, 92.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  99%|█████████▉| 4297/4319 [00:30<00:00, 94.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|█████████▉| 4310/4319 [00:30<00:00, 74.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|█████████▉| 4311/4319 [00:38<00:00, 155.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|█████████▉| 4310/4319 [00:48<00:00, 58.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|█████████▉| 4312/4319 [00:48<00:00, 43.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|█████████▉| 4312/4319 [00:48<00:00, 76.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|█████████▉| 4314/4319 [00:48<00:00, 92.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|█████████▉| 4317/4319 [00:48<00:00, 73.89 examples/s]#015Map (num_proc=8): 100%|█████████▉| 4312/4319 [00:48<00:00, 105.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|█████████▉| 4315/4319 [00:48<00:00, 74.87 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|█████████▉| 4312/4319 [00:52<00:02,  2.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|█████████▉| 4314/4319 [00:54<00:01,  2.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|█████████▉| 4314/4319 [00:57<00:05,  1.06s/ examples]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|█████████▉| 4317/4319 [00:58<00:02,  1.01s/ examples]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|█████████▉| 4315/4319 [00:59<00:04,  1.10s/ examples]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|█████████▉| 4313/4319 [00:59<00:08,  1.47s/ examples]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|█████████▉| 4315/4319 [00:59<00:02,  1.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|█████████▉| 4315/4319 [01:00<00:03,  1.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|█████████▉| 4314/4319 [01:00<00:03,  1.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|█████████▉| 4315/4319 [01:00<00:05,  1.36s/ examples]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|█████████▉| 4316/4319 [01:01<00:02,  1.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|█████████▉| 4316/4319 [01:01<00:01,  1.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|█████████▉| 4317/4319 [01:02<00:01,  1.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|█████████▉| 4311/4319 [01:03<00:09,  1.16s/ examples]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|██████████| 4319/4319 [01:03<00:00, 68.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|█████████▉| 4313/4319 [01:04<00:06,  1.11s/ examples]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   0%|          | 0/507 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   0%|          | 1/507 [00:00<07:33,  1.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   7%|▋         | 35/507 [00:01<00:10, 47.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  16%|█▌        | 79/507 [00:01<00:03, 109.58 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  24%|██▍       | 121/507 [00:01<00:02, 166.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  33%|███▎      | 168/507 [00:01<00:01, 227.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  43%|████▎     | 219/507 [00:01<00:01, 281.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  53%|█████▎    | 267/507 [00:01<00:00, 328.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  61%|██████▏   | 311/507 [00:01<00:00, 352.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  70%|███████   | 355/507 [00:01<00:00, 370.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  79%|███████▉  | 400/507 [00:01<00:00, 387.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  88%|████████▊ | 447/507 [00:01<00:00, 402.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  97%|█████████▋| 493/507 [00:02<00:00, 373.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|█████████▉| 4318/4319 [01:09<00:01,  1.50s/ examples]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|██████████| 507/507 [00:06<00:00, 80.95 examples/s]\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8):   0%|          | 0/4319 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8):  13%|█▎        | 540/4319 [00:00<00:01, 3384.27 examples/s]\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8): 100%|██████████| 4319/4319 [00:00<00:00, 14577.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|██████████| 4319/4319 [01:12<00:00,  1.76s/ examples]\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8):   0%|          | 0/507 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8):  13%|█▎        | 64/507 [00:00<00:01, 417.72 examples/s]\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8): 100%|██████████| 507/507 [00:00<00:00, 1754.57 examples/s]\u001b[0m\n",
      "\u001b[34mDATASET PREPARATION COMPLETED\u001b[0m\n",
      "\u001b[34mDownloading builder script:   0%|          | 0.00/5.60k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading builder script: 100%|██████████| 5.60k/5.60k [00:00<00:00, 21.9MB/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|██████████| 4319/4319 [01:14<00:00,  1.67s/ examples]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|██████████| 4319/4319 [01:14<00:00, 57.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|██████████| 4319/4319 [01:15<00:00, 57.40 examples/s]\u001b[0m\n",
      "\u001b[34mTRAINING IN PROGRESS...\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|██████████| 4319/4319 [01:15<00:00, 56.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|██████████| 4319/4319 [01:16<00:00, 56.77 examples/s]\u001b[0m\n",
      "\u001b[34mDATASET PREPARATION COMPLETED\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|██████████| 4319/4319 [01:16<00:00,  1.36s/ examples]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|██████████| 4319/4319 [01:16<00:00, 56.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|██████████| 4319/4319 [01:16<00:00, 56.56 examples/s]\u001b[0m\n",
      "\u001b[34mDATASET PREPARATION COMPLETED\u001b[0m\n",
      "\u001b[34mDATASET PREPARATION COMPLETED\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|██████████| 4319/4319 [01:17<00:00, 55.90 examples/s]\u001b[0m\n",
      "\u001b[34mDATASET PREPARATION COMPLETED\u001b[0m\n",
      "\u001b[34mDATASET PREPARATION COMPLETED\u001b[0m\n",
      "\u001b[34mDATASET PREPARATION COMPLETED\u001b[0m\n",
      "\u001b[34mDATASET PREPARATION COMPLETED\u001b[0m\n",
      "\u001b[34mTRAINING IN PROGRESS...\u001b[0m\n",
      "\u001b[34mTRAINING IN PROGRESS...\u001b[0m\n",
      "\u001b[34mTRAINING IN PROGRESS...\u001b[0m\n",
      "\u001b[34mTRAINING IN PROGRESS...\u001b[0m\n",
      "\u001b[34mTRAINING IN PROGRESS...\u001b[0m\n",
      "\u001b[34mTRAINING IN PROGRESS...\u001b[0m\n",
      "\u001b[34mTRAINING IN PROGRESS...\u001b[0m\n",
      "\u001b[34m0%|          | 0/675 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m0%|          | 1/675 [00:02<30:45,  2.74s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 2/675 [00:03<20:23,  1.82s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 3/675 [00:05<17:01,  1.52s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 4/675 [00:06<16:21,  1.46s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 5/675 [00:07<15:34,  1.39s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 6/675 [00:09<15:06,  1.35s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 7/675 [00:10<14:51,  1.33s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 8/675 [00:11<14:39,  1.32s/it]\u001b[0m\n",
      "\u001b[34m1%|▏         | 9/675 [00:12<14:30,  1.31s/it]\u001b[0m\n",
      "\u001b[34m1%|▏         | 10/675 [00:14<14:22,  1.30s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 11/675 [00:15<14:21,  1.30s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 12/675 [00:16<14:14,  1.29s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 13/675 [00:17<14:12,  1.29s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 14/675 [00:19<14:09,  1.29s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 15/675 [00:20<14:07,  1.28s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 16/675 [00:21<14:04,  1.28s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 17/675 [00:23<14:03,  1.28s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 18/675 [00:24<14:02,  1.28s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 19/675 [00:25<14:00,  1.28s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 20/675 [00:26<13:59,  1.28s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 21/675 [00:28<13:59,  1.28s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 22/675 [00:29<13:57,  1.28s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 23/675 [00:30<13:55,  1.28s/it]\u001b[0m\n",
      "\u001b[34m4%|▎         | 24/675 [00:32<13:54,  1.28s/it]\u001b[0m\n",
      "\u001b[34m4%|▎         | 25/675 [00:33<13:52,  1.28s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 26/675 [00:34<13:51,  1.28s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 27/675 [00:35<13:52,  1.28s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 28/675 [00:37<13:50,  1.28s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 29/675 [00:38<13:50,  1.29s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 30/675 [00:39<13:53,  1.29s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 31/675 [00:41<13:57,  1.30s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 32/675 [00:42<13:58,  1.30s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 33/675 [00:43<14:01,  1.31s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 34/675 [00:45<14:00,  1.31s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 35/675 [00:46<14:01,  1.31s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 36/675 [00:47<14:01,  1.32s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 37/675 [00:49<14:01,  1.32s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 38/675 [00:50<13:59,  1.32s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 39/675 [00:51<13:59,  1.32s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 40/675 [00:53<13:59,  1.32s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 41/675 [00:54<13:57,  1.32s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 42/675 [00:55<13:55,  1.32s/it]\u001b[0m\n",
      "\u001b[34m6%|▋         | 43/675 [00:56<13:53,  1.32s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 44/675 [00:58<13:55,  1.32s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 45/675 [00:59<13:53,  1.32s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 46/675 [01:00<13:51,  1.32s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 47/675 [01:02<13:50,  1.32s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 48/675 [01:03<13:49,  1.32s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 49/675 [01:04<13:47,  1.32s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 50/675 [01:06<13:44,  1.32s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 51/675 [01:07<13:44,  1.32s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 52/675 [01:08<13:41,  1.32s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 53/675 [01:10<13:39,  1.32s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 54/675 [01:11<13:36,  1.32s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 55/675 [01:12<13:34,  1.31s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 56/675 [01:14<13:31,  1.31s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 57/675 [01:15<13:29,  1.31s/it]\u001b[0m\n",
      "\u001b[34m9%|▊         | 58/675 [01:16<13:27,  1.31s/it]\u001b[0m\n",
      "\u001b[34m9%|▊         | 59/675 [01:18<13:26,  1.31s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 60/675 [01:19<13:25,  1.31s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 61/675 [01:20<13:23,  1.31s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 62/675 [01:21<13:23,  1.31s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 63/675 [01:23<13:22,  1.31s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 64/675 [01:24<13:19,  1.31s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 65/675 [01:25<13:18,  1.31s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 66/675 [01:27<13:17,  1.31s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 67/675 [01:28<13:16,  1.31s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 68/675 [01:29<13:16,  1.31s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 69/675 [01:31<13:15,  1.31s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 70/675 [01:32<13:14,  1.31s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 71/675 [01:33<13:12,  1.31s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 72/675 [01:35<13:11,  1.31s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 73/675 [01:36<13:09,  1.31s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 74/675 [01:37<13:07,  1.31s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 75/675 [01:39<13:06,  1.31s/it]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 76/675 [01:40<13:03,  1.31s/it]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 77/675 [01:41<13:01,  1.31s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 78/675 [01:42<13:01,  1.31s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 79/675 [01:44<13:01,  1.31s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 80/675 [01:45<13:00,  1.31s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 81/675 [01:46<12:58,  1.31s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 82/675 [01:48<12:58,  1.31s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 83/675 [01:49<12:56,  1.31s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 84/675 [01:50<12:54,  1.31s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 85/675 [01:52<12:52,  1.31s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 86/675 [01:53<12:48,  1.30s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 87/675 [01:54<12:42,  1.30s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 88/675 [01:55<12:37,  1.29s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 89/675 [01:57<12:34,  1.29s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 90/675 [01:58<12:30,  1.28s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 91/675 [01:59<12:28,  1.28s/it]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 92/675 [02:01<12:26,  1.28s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 93/675 [02:02<12:25,  1.28s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 94/675 [02:03<12:24,  1.28s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 95/675 [02:04<12:22,  1.28s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 96/675 [02:06<12:20,  1.28s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 97/675 [02:07<12:18,  1.28s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 98/675 [02:08<12:17,  1.28s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 99/675 [02:10<12:17,  1.28s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 100/675 [02:11<12:16,  1.28s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 101/675 [02:12<12:15,  1.28s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 102/675 [02:13<12:14,  1.28s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 103/675 [02:15<12:12,  1.28s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 104/675 [02:16<12:10,  1.28s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 105/675 [02:17<12:09,  1.28s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 106/675 [02:18<12:08,  1.28s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 107/675 [02:20<12:07,  1.28s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 108/675 [02:21<12:06,  1.28s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 109/675 [02:22<12:05,  1.28s/it]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 110/675 [02:24<12:03,  1.28s/it]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 111/675 [02:25<12:01,  1.28s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 112/675 [02:26<12:01,  1.28s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 113/675 [02:27<11:59,  1.28s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 114/675 [02:29<11:57,  1.28s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 115/675 [02:30<11:56,  1.28s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 116/675 [02:31<11:54,  1.28s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 117/675 [02:33<11:54,  1.28s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 118/675 [02:34<11:52,  1.28s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 119/675 [02:35<11:50,  1.28s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 120/675 [02:36<11:48,  1.28s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 121/675 [02:38<11:47,  1.28s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 122/675 [02:39<11:49,  1.28s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 123/675 [02:40<11:48,  1.28s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 124/675 [02:42<11:45,  1.28s/it]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 125/675 [02:43<11:43,  1.28s/it]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 126/675 [02:44<11:41,  1.28s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 127/675 [02:45<11:40,  1.28s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 128/675 [02:47<11:39,  1.28s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 129/675 [02:48<11:38,  1.28s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 130/675 [02:49<11:37,  1.28s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 131/675 [02:50<11:36,  1.28s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 132/675 [02:52<11:34,  1.28s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 133/675 [02:53<11:32,  1.28s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 134/675 [02:54<11:31,  1.28s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 135/675 [02:55<09:48,  1.09s/it]\u001b[0m\n",
      "\u001b[34mDue to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\u001b[0m\n",
      "\u001b[34mDue to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\u001b[0m\n",
      "\u001b[34mDue to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\u001b[0m\n",
      "\u001b[34mDue to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\u001b[0m\n",
      "\u001b[34mDue to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\u001b[0m\n",
      "\u001b[34mDue to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\u001b[0m\n",
      "\u001b[34mDue to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\u001b[0m\n",
      "\u001b[34mDue to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\u001b[0m\n",
      "\u001b[34mDue to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\u001b[0m\n",
      "\u001b[34mDue to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\u001b[0m\n",
      "\u001b[34mDue to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\u001b[0m\n",
      "\u001b[34mDue to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\u001b[0m\n",
      "\u001b[34mDue to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\u001b[0m\n",
      "\u001b[34mDue to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\u001b[0m\n",
      "\u001b[34mDue to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\u001b[0m\n",
      "\u001b[34mDue to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\u001b[0m\n",
      "\u001b[34mThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\u001b[0m\n",
      "\u001b[34mThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\u001b[0m\n",
      "\u001b[34mThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\u001b[0m\n",
      "\u001b[34mThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\u001b[0m\n",
      "\u001b[34mThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\u001b[0m\n",
      "\u001b[34mThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\u001b[0m\n",
      "\u001b[34mThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\u001b[0m\n",
      "\u001b[34mThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\u001b[0m\n",
      "\u001b[34mThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\u001b[0m\n",
      "\u001b[34mThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\u001b[0m\n",
      "\u001b[34mThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\u001b[0m\n",
      "\u001b[34mThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\u001b[0m\n",
      "\u001b[34mThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\u001b[0m\n",
      "\u001b[34mThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\u001b[0m\n",
      "\u001b[34mThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\u001b[0m\n",
      "\u001b[34mThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\u001b[0m\n",
      "\u001b[34m0%|          | 0/16 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m12%|█▎        | 2/16 [00:02<00:14,  1.04s/it]#033[A\u001b[0m\n",
      "\u001b[34m19%|█▉        | 3/16 [00:07<00:35,  2.70s/it]#033[A\u001b[0m\n",
      "\u001b[34m25%|██▌       | 4/16 [00:13<00:47,  3.98s/it]#033[A\u001b[0m\n",
      "\u001b[34m31%|███▏      | 5/16 [00:15<00:38,  3.47s/it]#033[A\u001b[0m\n",
      "\u001b[34m38%|███▊      | 6/16 [00:24<00:50,  5.07s/it]#033[A\u001b[0m\n",
      "\u001b[34m44%|████▍     | 7/16 [00:32<00:55,  6.18s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 8/16 [00:34<00:39,  4.93s/it]#033[A\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 9/16 [00:42<00:41,  5.90s/it]#033[A\u001b[0m\n",
      "\u001b[34m62%|██████▎   | 10/16 [00:50<00:39,  6.55s/it]#033[A\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 11/16 [00:52<00:25,  5.15s/it]#033[A\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 12/16 [01:01<00:24,  6.12s/it]#033[A\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 13/16 [01:09<00:20,  6.69s/it]#033[A\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 14/16 [01:11<00:10,  5.34s/it]#033[A\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 15/16 [01:19<00:06,  6.29s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 16/16 [01:21<00:00,  4.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 1.7407866716384888, 'eval_cer': 89.82962447844228, 'eval_runtime': 293.7057, 'eval_samples_per_second': 1.726, 'eval_steps_per_second': 0.054, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m20%|██        | 135/675 [07:49<09:48,  1.09s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 16/16 [04:44<00:00,  4.88s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m20%|██        | 136/675 [08:04<13:58:29, 93.34s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 137/675 [08:05<9:49:17, 65.72s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 138/675 [08:06<6:55:14, 46.39s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 139/675 [08:07<4:53:33, 32.86s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 140/675 [08:09<3:28:32, 23.39s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 141/675 [08:10<2:29:08, 16.76s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 142/675 [08:11<1:47:36, 12.11s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 143/675 [08:13<1:18:36,  8.87s/it]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 144/675 [08:14<58:19,  6.59s/it]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 145/675 [08:15<44:09,  5.00s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 146/675 [08:16<34:15,  3.89s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 147/675 [08:18<27:18,  3.10s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 148/675 [08:19<22:27,  2.56s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 149/675 [08:20<19:04,  2.18s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 150/675 [08:22<16:41,  1.91s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 151/675 [08:23<15:02,  1.72s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 152/675 [08:24<13:52,  1.59s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 153/675 [08:25<13:03,  1.50s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 154/675 [08:27<12:27,  1.43s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 155/675 [08:28<12:01,  1.39s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 156/675 [08:29<11:42,  1.35s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 157/675 [08:31<11:30,  1.33s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 158/675 [08:32<11:21,  1.32s/it]\u001b[0m\n",
      "\u001b[34m24%|██▎       | 159/675 [08:33<11:14,  1.31s/it]\u001b[0m\n",
      "\u001b[34m24%|██▎       | 160/675 [08:34<11:09,  1.30s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 161/675 [08:36<11:04,  1.29s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 162/675 [08:37<10:59,  1.29s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 163/675 [08:38<10:58,  1.29s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 164/675 [08:39<10:58,  1.29s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 165/675 [08:41<10:55,  1.29s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 166/675 [08:42<10:53,  1.28s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 167/675 [08:43<10:51,  1.28s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 168/675 [08:45<10:49,  1.28s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 169/675 [08:46<10:48,  1.28s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 170/675 [08:47<10:45,  1.28s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 171/675 [08:48<10:45,  1.28s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 172/675 [08:50<10:43,  1.28s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 173/675 [08:51<10:42,  1.28s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 174/675 [08:52<10:40,  1.28s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 175/675 [08:54<10:39,  1.28s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 176/675 [08:55<10:37,  1.28s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 177/675 [08:56<10:36,  1.28s/it]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 178/675 [08:57<10:34,  1.28s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 179/675 [08:59<10:33,  1.28s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 180/675 [09:00<10:32,  1.28s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 181/675 [09:01<10:31,  1.28s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 182/675 [09:02<10:29,  1.28s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 183/675 [09:04<10:27,  1.28s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 184/675 [09:05<10:26,  1.28s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 185/675 [09:06<10:25,  1.28s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 186/675 [09:08<10:24,  1.28s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 187/675 [09:09<10:23,  1.28s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 188/675 [09:10<10:21,  1.28s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 189/675 [09:11<10:20,  1.28s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 190/675 [09:13<10:19,  1.28s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 191/675 [09:14<10:20,  1.28s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 192/675 [09:15<10:20,  1.29s/it]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 193/675 [09:17<10:17,  1.28s/it]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 194/675 [09:18<10:16,  1.28s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 195/675 [09:19<10:13,  1.28s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 196/675 [09:20<10:12,  1.28s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 197/675 [09:22<10:10,  1.28s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 198/675 [09:23<10:09,  1.28s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 199/675 [09:24<10:07,  1.28s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 200/675 [09:26<10:07,  1.28s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 201/675 [09:27<10:06,  1.28s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 202/675 [09:28<10:05,  1.28s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 203/675 [09:29<09:49,  1.25s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 204/675 [09:31<09:52,  1.26s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 205/675 [09:32<09:54,  1.26s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 206/675 [09:33<09:54,  1.27s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 207/675 [09:34<09:54,  1.27s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 208/675 [09:36<09:53,  1.27s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 209/675 [09:37<09:51,  1.27s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 210/675 [09:38<09:53,  1.28s/it]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 211/675 [09:39<09:53,  1.28s/it]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 212/675 [09:41<09:50,  1.28s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 213/675 [09:42<09:48,  1.27s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 214/675 [09:43<09:46,  1.27s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 215/675 [09:45<09:44,  1.27s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 216/675 [09:46<09:43,  1.27s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 217/675 [09:47<09:41,  1.27s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 218/675 [09:48<09:40,  1.27s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 219/675 [09:50<09:39,  1.27s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 220/675 [09:51<09:37,  1.27s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 221/675 [09:52<09:36,  1.27s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 222/675 [09:53<09:34,  1.27s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 223/675 [09:55<09:33,  1.27s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 224/675 [09:56<09:32,  1.27s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 225/675 [09:57<09:30,  1.27s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 226/675 [09:58<09:30,  1.27s/it]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 227/675 [10:00<09:29,  1.27s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 228/675 [10:01<09:27,  1.27s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 229/675 [10:02<09:26,  1.27s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 230/675 [10:04<09:25,  1.27s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 231/675 [10:05<09:25,  1.27s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 232/675 [10:06<09:23,  1.27s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 233/675 [10:08<09:38,  1.31s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 234/675 [10:09<09:34,  1.30s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 235/675 [10:10<09:49,  1.34s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 236/675 [10:12<09:42,  1.33s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 237/675 [10:13<09:33,  1.31s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 238/675 [10:14<09:27,  1.30s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 239/675 [10:15<09:21,  1.29s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 240/675 [10:17<09:18,  1.28s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 241/675 [10:18<09:15,  1.28s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 242/675 [10:19<09:13,  1.28s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 243/675 [10:20<09:10,  1.27s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 244/675 [10:22<09:08,  1.27s/it]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 245/675 [10:23<09:07,  1.27s/it]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 246/675 [10:24<09:06,  1.27s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 247/675 [10:26<09:04,  1.27s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 248/675 [10:27<09:03,  1.27s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 249/675 [10:28<09:01,  1.27s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 250/675 [10:29<09:02,  1.28s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 251/675 [10:31<08:59,  1.27s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 252/675 [10:32<08:58,  1.27s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 253/675 [10:33<08:57,  1.27s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 254/675 [10:34<08:56,  1.27s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 255/675 [10:36<08:54,  1.27s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 256/675 [10:37<08:53,  1.27s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 257/675 [10:38<08:52,  1.27s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 258/675 [10:40<08:51,  1.27s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 259/675 [10:41<08:49,  1.27s/it]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 260/675 [10:42<08:48,  1.27s/it]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 261/675 [10:43<08:46,  1.27s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 262/675 [10:45<08:45,  1.27s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 263/675 [10:46<08:44,  1.27s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 264/675 [10:47<08:43,  1.27s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 265/675 [10:48<08:43,  1.28s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 266/675 [10:50<08:42,  1.28s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 267/675 [10:51<08:40,  1.28s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 268/675 [10:52<08:38,  1.27s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 269/675 [10:54<08:37,  1.27s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 270/675 [10:54<07:20,  1.09s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/16 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m12%|█▎        | 2/16 [00:08<00:58,  4.17s/it]#033[A\u001b[0m\n",
      "\u001b[34m19%|█▉        | 3/16 [00:16<01:16,  5.91s/it]#033[A\u001b[0m\n",
      "\u001b[34m25%|██▌       | 4/16 [00:25<01:21,  6.82s/it]#033[A\u001b[0m\n",
      "\u001b[34m31%|███▏      | 5/16 [00:33<01:21,  7.37s/it]#033[A\u001b[0m\n",
      "\u001b[34m38%|███▊      | 6/16 [00:41<01:16,  7.70s/it]#033[A\u001b[0m\n",
      "\u001b[34m44%|████▍     | 7/16 [00:50<01:11,  7.91s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 8/16 [00:58<01:04,  8.05s/it]#033[A\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 9/16 [01:06<00:57,  8.15s/it]#033[A\u001b[0m\n",
      "\u001b[34m62%|██████▎   | 10/16 [01:15<00:49,  8.22s/it]#033[A\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 11/16 [01:23<00:41,  8.27s/it]#033[A\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 12/16 [01:32<00:33,  8.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 13/16 [01:40<00:24,  8.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 14/16 [01:48<00:16,  8.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 15/16 [01:57<00:08,  8.34s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 16/16 [02:04<00:00,  8.16s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 7.328771591186523, 'eval_cer': 100.0, 'eval_runtime': 295.1256, 'eval_samples_per_second': 1.718, 'eval_steps_per_second': 0.054, 'epoch': 2.0}\u001b[0m\n",
      "\u001b[34m40%|████      | 270/675 [15:49<07:20,  1.09s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 16/16 [04:46<00:00,  8.16s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m40%|████      | 271/675 [16:04<10:31:10, 93.74s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 272/675 [16:05<7:23:17, 66.00s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 273/675 [16:07<5:12:06, 46.58s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 274/675 [16:08<3:40:29, 32.99s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 275/675 [16:09<2:36:30, 23.48s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 276/675 [16:10<1:51:49, 16.82s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 277/675 [16:12<1:20:42, 12.17s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 278/675 [16:13<59:00,  8.92s/it]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 279/675 [16:15<43:51,  6.65s/it]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 280/675 [16:16<33:17,  5.06s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 281/675 [16:17<25:50,  3.94s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 282/675 [16:18<20:38,  3.15s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 283/675 [16:20<17:00,  2.60s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 284/675 [16:21<14:27,  2.22s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 285/675 [16:22<12:43,  1.96s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 286/675 [16:24<11:27,  1.77s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 287/675 [16:25<10:33,  1.63s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 288/675 [16:26<09:56,  1.54s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 289/675 [16:28<09:29,  1.47s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 290/675 [16:29<09:17,  1.45s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 291/675 [16:30<09:01,  1.41s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 292/675 [16:32<08:50,  1.39s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 293/675 [16:33<08:42,  1.37s/it]\u001b[0m\n",
      "\u001b[34m44%|████▎     | 294/675 [16:34<08:35,  1.35s/it]\u001b[0m\n",
      "\u001b[34m44%|████▎     | 295/675 [16:36<08:30,  1.34s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 296/675 [16:37<08:26,  1.34s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 297/675 [16:38<08:23,  1.33s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 298/675 [16:40<08:23,  1.33s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 299/675 [16:41<08:20,  1.33s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 300/675 [16:42<08:18,  1.33s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 301/675 [16:44<08:16,  1.33s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 302/675 [16:45<08:14,  1.33s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 303/675 [16:46<08:12,  1.32s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 304/675 [16:48<08:11,  1.32s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 305/675 [16:49<08:09,  1.32s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 306/675 [16:50<08:07,  1.32s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 307/675 [16:52<08:06,  1.32s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 308/675 [16:53<08:04,  1.32s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 309/675 [16:54<08:03,  1.32s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 310/675 [16:56<08:01,  1.32s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 311/675 [16:57<08:00,  1.32s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 312/675 [16:58<07:59,  1.32s/it]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 313/675 [17:00<07:58,  1.32s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 314/675 [17:01<07:57,  1.32s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 315/675 [17:02<07:56,  1.32s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 316/675 [17:04<07:55,  1.32s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 317/675 [17:05<07:53,  1.32s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 318/675 [17:06<07:52,  1.32s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 319/675 [17:08<07:51,  1.32s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 320/675 [17:09<07:49,  1.32s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 321/675 [17:10<07:49,  1.32s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 322/675 [17:11<07:47,  1.32s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 323/675 [17:13<07:45,  1.32s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 324/675 [17:14<07:43,  1.32s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 325/675 [17:15<07:42,  1.32s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 326/675 [17:17<07:40,  1.32s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 327/675 [17:18<07:39,  1.32s/it]\u001b[0m\n",
      "\u001b[34m49%|████▊     | 328/675 [17:19<07:37,  1.32s/it]\u001b[0m\n",
      "\u001b[34m49%|████▊     | 329/675 [17:21<07:36,  1.32s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 330/675 [17:22<07:35,  1.32s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 331/675 [17:23<07:34,  1.32s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 332/675 [17:25<07:32,  1.32s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 333/675 [17:26<07:31,  1.32s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 334/675 [17:27<07:29,  1.32s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 335/675 [17:29<07:28,  1.32s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 336/675 [17:30<07:26,  1.32s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 337/675 [17:31<07:26,  1.32s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 338/675 [17:33<07:25,  1.32s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 339/675 [17:34<07:22,  1.32s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 340/675 [17:35<07:21,  1.32s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 341/675 [17:37<07:20,  1.32s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 342/675 [17:38<07:15,  1.31s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 343/675 [17:39<07:10,  1.30s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 344/675 [17:40<07:06,  1.29s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 345/675 [17:42<07:03,  1.28s/it]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 346/675 [17:43<07:01,  1.28s/it]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 347/675 [17:44<06:58,  1.28s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 348/675 [17:45<06:59,  1.28s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 349/675 [17:47<06:58,  1.28s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 350/675 [17:48<06:56,  1.28s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 351/675 [17:49<06:53,  1.28s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 352/675 [17:51<06:52,  1.28s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 353/675 [17:52<06:49,  1.27s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 354/675 [17:53<06:48,  1.27s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 355/675 [17:54<06:46,  1.27s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 356/675 [17:56<06:46,  1.27s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 357/675 [17:57<06:45,  1.27s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 358/675 [17:58<06:44,  1.28s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 359/675 [18:00<06:43,  1.28s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 360/675 [18:01<06:41,  1.28s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 361/675 [18:02<06:40,  1.27s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 362/675 [18:03<06:38,  1.27s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 363/675 [18:05<06:36,  1.27s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 364/675 [18:06<06:34,  1.27s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 365/675 [18:07<06:33,  1.27s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 366/675 [18:08<06:32,  1.27s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 367/675 [18:10<06:30,  1.27s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 368/675 [18:11<06:28,  1.27s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 369/675 [18:12<06:27,  1.27s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 370/675 [18:13<06:27,  1.27s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 371/675 [18:15<06:26,  1.27s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 372/675 [18:16<06:24,  1.27s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 373/675 [18:17<06:24,  1.27s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 374/675 [18:19<06:23,  1.27s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 375/675 [18:20<06:21,  1.27s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 376/675 [18:21<06:20,  1.27s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 377/675 [18:22<06:19,  1.27s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 378/675 [18:24<06:17,  1.27s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 379/675 [18:25<06:15,  1.27s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 380/675 [18:26<06:13,  1.27s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 381/675 [18:27<06:12,  1.27s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 382/675 [18:29<06:11,  1.27s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 383/675 [18:30<06:09,  1.27s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 384/675 [18:31<06:08,  1.27s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 385/675 [18:33<06:08,  1.27s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 386/675 [18:34<06:07,  1.27s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 387/675 [18:35<06:06,  1.27s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 388/675 [18:36<06:04,  1.27s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 389/675 [18:38<06:02,  1.27s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 390/675 [18:39<06:02,  1.27s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 391/675 [18:40<06:00,  1.27s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 392/675 [18:41<06:00,  1.27s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 393/675 [18:43<05:58,  1.27s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 394/675 [18:44<05:56,  1.27s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 395/675 [18:45<05:55,  1.27s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 396/675 [18:46<05:54,  1.27s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 397/675 [18:48<05:52,  1.27s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 398/675 [18:49<05:51,  1.27s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 399/675 [18:50<05:49,  1.27s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 400/675 [18:52<05:49,  1.27s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 401/675 [18:53<05:48,  1.27s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 402/675 [18:54<05:46,  1.27s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 403/675 [18:55<05:45,  1.27s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 404/675 [18:57<05:43,  1.27s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 405/675 [18:57<04:52,  1.08s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/16 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m12%|█▎        | 2/16 [00:08<00:58,  4.19s/it]#033[A\u001b[0m\n",
      "\u001b[34m19%|█▉        | 3/16 [00:16<01:17,  5.93s/it]#033[A\u001b[0m\n",
      "\u001b[34m25%|██▌       | 4/16 [00:25<01:22,  6.85s/it]#033[A\u001b[0m\n",
      "\u001b[34m31%|███▏      | 5/16 [00:33<01:21,  7.38s/it]#033[A\u001b[0m\n",
      "\u001b[34m38%|███▊      | 6/16 [00:41<01:16,  7.70s/it]#033[A\u001b[0m\n",
      "\u001b[34m44%|████▍     | 7/16 [00:50<01:11,  7.91s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 8/16 [00:58<01:04,  8.05s/it]#033[A\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 9/16 [01:06<00:57,  8.15s/it]#033[A\u001b[0m\n",
      "\u001b[34m62%|██████▎   | 10/16 [01:15<00:49,  8.21s/it]#033[A\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 11/16 [01:23<00:41,  8.26s/it]#033[A\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 12/16 [01:32<00:33,  8.29s/it]#033[A\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 13/16 [01:40<00:24,  8.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 14/16 [01:48<00:16,  8.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 15/16 [01:57<00:08,  8.34s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 16/16 [02:04<00:00,  8.17s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 5990.7861328125, 'eval_cer': 100.0, 'eval_runtime': 294.2239, 'eval_samples_per_second': 1.723, 'eval_steps_per_second': 0.054, 'epoch': 3.0}\u001b[0m\n",
      "\u001b[34m60%|██████    | 405/675 [23:52<04:52,  1.08s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 16/16 [04:45<00:00,  8.17s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34mSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\u001b[0m\n",
      "\u001b[34mNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m60%|██████    | 406/675 [24:07<6:59:49, 93.64s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 407/675 [24:08<4:54:28, 65.93s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 408/675 [24:09<3:27:04, 46.53s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 409/675 [24:11<2:26:06, 32.95s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 410/675 [24:12<1:43:34, 23.45s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 411/675 [24:13<1:13:54, 16.80s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 412/675 [24:15<53:13, 12.14s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 413/675 [24:16<38:47,  8.88s/it]\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 414/675 [24:17<28:35,  6.57s/it]\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 415/675 [24:18<21:43,  5.01s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 416/675 [24:20<16:49,  3.90s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 417/675 [24:21<13:15,  3.08s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 418/675 [24:22<10:45,  2.51s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 419/675 [24:23<09:08,  2.14s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 420/675 [24:25<08:00,  1.89s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 421/675 [24:26<07:12,  1.70s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 422/675 [24:27<06:38,  1.57s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 423/675 [24:28<06:13,  1.48s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 424/675 [24:30<05:56,  1.42s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 425/675 [24:31<05:44,  1.38s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 426/675 [24:32<05:34,  1.35s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 427/675 [24:34<05:28,  1.32s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 428/675 [24:35<05:37,  1.37s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 429/675 [24:36<05:29,  1.34s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 430/675 [24:38<05:22,  1.32s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 431/675 [24:39<05:17,  1.30s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 432/675 [24:40<05:13,  1.29s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 433/675 [24:41<05:11,  1.29s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 434/675 [24:43<05:09,  1.28s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 435/675 [24:44<05:07,  1.28s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 436/675 [24:45<05:05,  1.28s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 437/675 [24:46<05:03,  1.28s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 438/675 [24:48<05:02,  1.27s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 439/675 [24:49<05:00,  1.27s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 440/675 [24:50<04:59,  1.27s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 441/675 [24:52<04:58,  1.27s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 442/675 [24:53<04:56,  1.27s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 443/675 [24:54<04:55,  1.28s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 444/675 [24:55<04:54,  1.27s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 445/675 [24:57<04:53,  1.27s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 446/675 [24:58<04:51,  1.27s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 447/675 [24:59<04:50,  1.27s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 448/675 [25:00<04:48,  1.27s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 449/675 [25:02<04:47,  1.27s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 450/675 [25:03<04:46,  1.27s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 451/675 [25:04<04:44,  1.27s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 452/675 [25:06<04:43,  1.27s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 453/675 [25:07<04:41,  1.27s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 454/675 [25:08<04:40,  1.27s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 455/675 [25:09<04:39,  1.27s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 456/675 [25:11<04:38,  1.27s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 457/675 [25:12<04:37,  1.27s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 458/675 [25:13<04:35,  1.27s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 459/675 [25:14<04:34,  1.27s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 460/675 [25:16<04:33,  1.27s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 461/675 [25:17<04:32,  1.27s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 462/675 [25:18<04:31,  1.27s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▊   | 463/675 [25:20<04:29,  1.27s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▊   | 464/675 [25:21<04:27,  1.27s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 465/675 [25:22<04:26,  1.27s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 466/675 [25:23<04:25,  1.27s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 467/675 [25:25<04:24,  1.27s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 468/675 [25:26<04:22,  1.27s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 469/675 [25:27<04:21,  1.27s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 470/675 [25:28<04:20,  1.27s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 471/675 [25:30<04:19,  1.27s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 472/675 [25:31<04:18,  1.27s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 473/675 [25:32<04:17,  1.27s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 474/675 [25:33<04:15,  1.27s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 475/675 [25:35<04:14,  1.27s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 476/675 [25:36<04:12,  1.27s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 477/675 [25:37<04:11,  1.27s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 478/675 [25:39<04:10,  1.27s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 479/675 [25:40<04:08,  1.27s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 480/675 [25:41<04:07,  1.27s/it]\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 481/675 [25:42<04:06,  1.27s/it]\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 482/675 [25:44<04:05,  1.27s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 483/675 [25:45<04:04,  1.27s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 484/675 [25:46<04:02,  1.27s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 485/675 [25:47<04:01,  1.27s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 486/675 [25:49<04:00,  1.27s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 487/675 [25:50<03:59,  1.27s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 488/675 [25:51<03:57,  1.27s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 489/675 [25:53<03:56,  1.27s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 490/675 [25:54<03:55,  1.27s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 491/675 [25:55<03:53,  1.27s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 492/675 [25:56<03:52,  1.27s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 493/675 [25:58<03:51,  1.27s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 494/675 [25:59<03:50,  1.27s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 495/675 [26:00<03:48,  1.27s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 496/675 [26:01<03:47,  1.27s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▎  | 497/675 [26:03<03:46,  1.27s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 498/675 [26:04<03:44,  1.27s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 499/675 [26:05<03:43,  1.27s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 500/675 [26:07<03:42,  1.27s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 162.8648, 'grad_norm': 3.1653881072998047, 'learning_rate': 0.001473, 'epoch': 3.7}\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 500/675 [26:07<03:42,  1.27s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 501/675 [26:08<03:40,  1.27s/it]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "region = sagemaker_session.boto_session.region_name\n",
    "\n",
    "# image_uri = f'763104351884.dkr.ecr.{region}.amazonaws.com/pytorch-training:2.2.0-gpu-py310-cu121-ubuntu20.04-sagemaker'\n",
    "image_uri = f'763104351884.dkr.ecr.{region}.amazonaws.com/pytorch-training:2.3.0-gpu-py311-cu121-ubuntu20.04-sagemaker'\n",
    "\n",
    "instance_count = 1\n",
    "# instance_type = 'ml.g5.48xlarge'\n",
    "instance_type = 'ml.p4d.24xlarge' # 8xA100 40G\n",
    "\n",
    "checkpoint_s3_uri = f's3://{bucket}/checkpoints/whisper_checkpoint'\n",
    "checkpoint_local_path = \"/opt/ml/checkpoints\"\n",
    "\n",
    "environment = {\n",
    "    'NODE_NUMBER': str(instance_count),\n",
    "    'TRAIN_DATA_PATH': f's3://{bucket}/{prefix_data}/train/',\n",
    "    'VALID_DATA_PATH': f's3://{bucket}/{prefix_data}/valid/',\n",
    "    'PRETRAINED_MODEL_S3_PATH': f\"{input_model}/\",\n",
    "    'OUTPUT_MODEL_S3_PATH': f's3://{bucket}/checkpoints/whisper_checkpoint', # destination\n",
    "}\n",
    "\n",
    "estimator = Estimator(role=role,\n",
    "                      entry_point='entry.py',\n",
    "                      source_dir='./sm_scripts',\n",
    "                      base_job_name='whisper-launch',\n",
    "                      instance_count=instance_count,\n",
    "                      instance_type=instance_type,\n",
    "                      volume_size=1024, # in GB\n",
    "                      image_uri=image_uri,\n",
    "                      environment=environment,\n",
    "                      max_run=3*24*3600, #任务最大存续时间，默认2day，需要提交ticket提升quota最大28天\n",
    "                      disable_profiler=True,\n",
    "                      debugger_hook_config=False,\n",
    "                      checkpoint_s3_uri=checkpoint_s3_uri,\n",
    "                      checkpoint_local_path=checkpoint_local_path)\n",
    "\n",
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4124e1c3-9f2f-4c6f-8f49-43311180565a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba8b48e-fa8b-45f1-8b33-4b597d36420e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_dgmr_py310",
   "language": "python",
   "name": "conda_dgmr_py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
