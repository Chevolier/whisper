{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f40caf1-4209-48c6-961e-2e097aacae5a",
   "metadata": {},
   "source": [
    "# prepare text and audio_paths files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1797e649-f631-4908-bde2-957e7dbe32b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a8f51c60-5a4a-4765-aa79-638f76d2f9b2.amr', 'c40afd4e-dafb-40a5-8c6e-ce9283a33278.amr', '94a7e398-202d-4bcc-b991-81eced1c892f.amr', '19a69c77-0be3-49d5-8d0d-90fea3c7a1c4.amr', '7997ef05-06ce-4389-a915-c291782ae901.amr']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_dir = \"data/test\"\n",
    "\n",
    "filenames = [filename for filename in os.listdir(os.path.join(data_dir, \"clips\")) if filename.endswith('.amr')]\n",
    "print(filenames[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abeac1f-2e07-4944-af33-b6ab8fef9d00",
   "metadata": {},
   "source": [
    "## convert amr to mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d21eea4c-bb0d-4bfc-bf10-308dca490041",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "465ca1a8-f847-4d34-95e6-2f6dfb4a1b31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from pydub import AudioSegment\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# for filename in tqdm(filenames, total=len(filenames)):\n",
    "    \n",
    "#     amr_audio = AudioSegment.from_file(data_dir+f'/clips/{filename}', format=\"amr\")\n",
    "#     amr_audio.export(data_dir+f'/clips/{filename[:-3]}mp3', format=\"mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f36f369a-2736-41d0-b0f1-5a6bfa4f3231",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_name</th>\n",
       "      <th>content</th>\n",
       "      <th>user_id</th>\n",
       "      <th>record_file_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model</td>\n",
       "      <td>CMSN 20 si</td>\n",
       "      <td>wuzy37</td>\n",
       "      <td>8deb96cd-1939-46d0-8f87-5bd798ade923.amr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model</td>\n",
       "      <td>CMSRO 20di cr</td>\n",
       "      <td>wuzy37</td>\n",
       "      <td>09b311d8-c557-4bfb-bac5-f0d18a5da8e9.amr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model</td>\n",
       "      <td>CMSN 20 si</td>\n",
       "      <td>ex_xietian2</td>\n",
       "      <td>6ae92f35-3139-417c-b0f4-d30ac25b3937.amr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Model</td>\n",
       "      <td>CMSRO 20di cr</td>\n",
       "      <td>ex_xietian2</td>\n",
       "      <td>3b65f69e-5aea-4211-acaf-b7bb2f651755.amr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Model</td>\n",
       "      <td>CMSRO 20di rd</td>\n",
       "      <td>ex_xietian2</td>\n",
       "      <td>c40afd4e-dafb-40a5-8c6e-ce9283a33278.amr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category_name        content      user_id  \\\n",
       "0         Model     CMSN 20 si       wuzy37   \n",
       "1         Model  CMSRO 20di cr       wuzy37   \n",
       "2         Model     CMSN 20 si  ex_xietian2   \n",
       "3         Model  CMSRO 20di cr  ex_xietian2   \n",
       "4         Model  CMSRO 20di rd  ex_xietian2   \n",
       "\n",
       "                             record_file_id  \n",
       "0  8deb96cd-1939-46d0-8f87-5bd798ade923.amr  \n",
       "1  09b311d8-c557-4bfb-bac5-f0d18a5da8e9.amr  \n",
       "2  6ae92f35-3139-417c-b0f4-d30ac25b3937.amr  \n",
       "3  3b65f69e-5aea-4211-acaf-b7bb2f651755.amr  \n",
       "4  c40afd4e-dafb-40a5-8c6e-ce9283a33278.amr  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_data = pd.read_csv(os.path.join(data_dir, \"语料.csv\"))\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eebb10b2-8c43-4084-b245-45e7e004523c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_path = os.path.join(data_dir, 'text')\n",
    "audio_paths_path = os.path.join(data_dir, 'audio_paths')\n",
    "\n",
    "with open(text_path, 'w') as fo1, open(audio_paths_path, 'w') as fo2:\n",
    "    for filename in filenames:\n",
    "        part_name, part_format = filename.split('.')\n",
    "        content = df_data[df_data['record_file_id']==filename].reset_index(drop=True).loc[0, 'content']\n",
    "        \n",
    "        fo1.write(part_name+' '+content+'\\n')\n",
    "        abs_path = os.path.abspath(os.path.join(data_dir+'/clips', filename[:-3]+'mp3'))\n",
    "        fo2.write(part_name+' '+abs_path+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510d87d6-4994-48fe-8bd7-a7e60db9c3ec",
   "metadata": {},
   "source": [
    "# process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3ca7a5d-2f26-4e88-95c1-9cf37cfa7e22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python3 finetune/custom_data/data_prep.py \\\n",
    "# --source_data_dir data/test \\\n",
    "# --output_data_dir data/custom_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c9810a-1f59-4282-805b-5dec6181fcd1",
   "metadata": {},
   "source": [
    "# finetuning on custom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63339b50-73ec-44b8-a971-d4a7739172a2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install evaluate\n",
    "# !pip install tensorboardX\n",
    "# !pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "490a454a-47d3-4ec1-971a-6c01a5708855",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.sh\n",
    "# train \n",
    "\n",
    "ngpu=1  # number of GPUs to perform distributed training on.\n",
    "train_data_dir=data/custom_test_data\n",
    "eval_data_dir=data/custom_test_data\n",
    "\n",
    "torchrun --nproc_per_node=${ngpu} finetune/train/fine-tune_on_custom_dataset.py \\\n",
    "--model_name /home/ec2-user/SageMaker/efs/Models/whisper-large-v3 \\\n",
    "--language Cantonese \\\n",
    "--sampling_rate 16000 \\\n",
    "--num_proc ${ngpu} \\\n",
    "--train_strategy epoch \\\n",
    "--learning_rate 3e-3 \\\n",
    "--warmup 1000 \\\n",
    "--train_batchsize 1 \\\n",
    "--eval_batchsize 1 \\\n",
    "--num_epochs 5 \\\n",
    "--resume_from_ckpt None \\\n",
    "--output_dir checkpoint \\\n",
    "--train_datasets ${train_data_dir} \\\n",
    "--eval_datasets ${eval_data_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a73c79c-c8da-4f95-b5b0-46d96b698f6f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "ARGUMENTS OF INTEREST:\n",
      "{'model_name': '/home/ec2-user/SageMaker/efs/Models/whisper-large-v3', 'language': 'Cantonese', 'sampling_rate': 16000, 'num_proc': 1, 'train_strategy': 'epoch', 'learning_rate': 0.003, 'warmup': 1000, 'train_batchsize': 1, 'eval_batchsize': 1, 'num_epochs': 5, 'num_steps': 100000, 'resume_from_ckpt': 'None', 'output_dir': 'checkpoint', 'train_datasets': ['data/custom_test_data'], 'eval_datasets': ['data/custom_test_data']}\n",
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "DATASET PREPARATION IN PROGRESS...\n",
      "DATASET PREPARATION COMPLETED\n",
      "TRAINING IN PROGRESS...\n",
      "  0%|                                                   | 0/185 [00:00<?, ?it/s]/home/ec2-user/SageMaker/efs/conda_envs/whisper_py310/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      " 20%|████████▍                                 | 37/185 [00:31<01:57,  1.26it/s]Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "\n",
      "  0%|                                                    | 0/37 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|██▍                                         | 2/37 [00:00<00:13,  2.60it/s]\u001b[A\n",
      "  8%|███▌                                        | 3/37 [00:01<00:20,  1.64it/s]\u001b[A\n",
      " 11%|████▊                                       | 4/37 [00:02<00:22,  1.50it/s]\u001b[A\n",
      " 14%|█████▉                                      | 5/37 [00:03<00:25,  1.26it/s]\u001b[A\n",
      " 16%|███████▏                                    | 6/37 [00:04<00:23,  1.34it/s]\u001b[A\n",
      " 19%|████████▎                                   | 7/37 [00:04<00:22,  1.32it/s]\u001b[A\n",
      " 22%|█████████▌                                  | 8/37 [00:05<00:21,  1.37it/s]\u001b[A\n",
      " 24%|██████████▋                                 | 9/37 [00:06<00:20,  1.35it/s]\u001b[A\n",
      " 27%|███████████▌                               | 10/37 [00:07<00:20,  1.34it/s]\u001b[A\n",
      " 30%|████████████▊                              | 11/37 [00:07<00:18,  1.39it/s]\u001b[A\n",
      " 32%|█████████████▉                             | 12/37 [00:08<00:18,  1.32it/s]\u001b[A\n",
      " 35%|███████████████                            | 13/37 [00:09<00:17,  1.35it/s]\u001b[A\n",
      " 38%|████████████████▎                          | 14/37 [00:09<00:16,  1.39it/s]\u001b[A\n",
      " 41%|█████████████████▍                         | 15/37 [00:10<00:15,  1.44it/s]\u001b[A\n",
      " 43%|██████████████████▌                        | 16/37 [00:11<00:14,  1.48it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 17/37 [00:12<00:14,  1.36it/s]\u001b[A\n",
      " 49%|████████████████████▉                      | 18/37 [00:12<00:13,  1.38it/s]\u001b[A\n",
      " 51%|██████████████████████                     | 19/37 [00:13<00:12,  1.41it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 20/37 [00:14<00:11,  1.46it/s]\u001b[A\n",
      " 57%|████████████████████████▍                  | 21/37 [00:14<00:11,  1.39it/s]\u001b[A\n",
      " 59%|█████████████████████████▌                 | 22/37 [00:15<00:10,  1.46it/s]\u001b[A\n",
      " 62%|██████████████████████████▋                | 23/37 [00:16<00:09,  1.41it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 24/37 [00:17<00:10,  1.29it/s]\u001b[A\n",
      " 68%|█████████████████████████████              | 25/37 [00:17<00:08,  1.34it/s]\u001b[A\n",
      " 70%|██████████████████████████████▏            | 26/37 [00:18<00:08,  1.31it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 27/37 [00:19<00:08,  1.20it/s]\u001b[A\n",
      " 76%|████████████████████████████████▌          | 28/37 [00:20<00:06,  1.29it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▋         | 29/37 [00:21<00:06,  1.21it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 30/37 [00:22<00:05,  1.25it/s]\u001b[A\n",
      " 84%|████████████████████████████████████       | 31/37 [00:22<00:04,  1.25it/s]\u001b[A\n",
      " 86%|█████████████████████████████████████▏     | 32/37 [00:23<00:03,  1.30it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▎    | 33/37 [00:24<00:02,  1.34it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 34/37 [00:24<00:02,  1.40it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▋  | 35/37 [00:25<00:01,  1.26it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▊ | 36/37 [00:26<00:00,  1.34it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 1.6802617311477661, 'eval_cer': 83.24873096446701, 'eval_runtime': 46.2193, 'eval_samples_per_second': 0.801, 'eval_steps_per_second': 0.801, 'epoch': 1.0}\n",
      " 20%|████████▍                                 | 37/185 [01:18<01:57,  1.26it/s]\n",
      "100%|███████████████████████████████████████████| 37/37 [00:45<00:00,  1.46it/s]\u001b[A\n",
      "                                                                                \u001b[ASome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n",
      "/home/ec2-user/SageMaker/efs/conda_envs/whisper_py310/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      " 40%|████████████████▊                         | 74/185 [02:33<01:29,  1.24it/s]\n",
      "  0%|                                                    | 0/37 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|██▍                                         | 2/37 [00:01<00:23,  1.52it/s]\u001b[A\n",
      "  8%|███▌                                        | 3/37 [00:02<00:27,  1.22it/s]\u001b[A\n",
      " 11%|████▊                                       | 4/37 [00:03<00:27,  1.21it/s]\u001b[A\n",
      " 14%|█████▉                                      | 5/37 [00:04<00:26,  1.20it/s]\u001b[A\n",
      " 16%|███████▏                                    | 6/37 [00:05<00:27,  1.11it/s]\u001b[A\n",
      " 19%|████████▎                                   | 7/37 [00:13<01:38,  3.29s/it]\u001b[A\n",
      " 22%|█████████▌                                  | 8/37 [00:14<01:15,  2.61s/it]\u001b[A\n",
      " 24%|██████████▋                                 | 9/37 [00:22<02:00,  4.30s/it]\u001b[A\n",
      " 27%|███████████▌                               | 10/37 [00:27<01:58,  4.37s/it]\u001b[A\n",
      " 30%|████████████▊                              | 11/37 [00:35<02:23,  5.51s/it]\u001b[A\n",
      " 32%|█████████████▉                             | 12/37 [00:43<02:37,  6.31s/it]\u001b[A\n",
      " 35%|███████████████                            | 13/37 [00:44<01:52,  4.69s/it]\u001b[A\n",
      " 38%|████████████████▎                          | 14/37 [00:45<01:20,  3.49s/it]\u001b[A\n",
      " 41%|█████████████████▍                         | 15/37 [00:45<00:58,  2.66s/it]\u001b[A\n",
      " 43%|██████████████████▌                        | 16/37 [00:46<00:43,  2.07s/it]\u001b[A\n",
      " 46%|███████████████████▊                       | 17/37 [00:47<00:36,  1.83s/it]\u001b[A\n",
      " 49%|████████████████████▉                      | 18/37 [00:56<01:13,  3.86s/it]\u001b[A\n",
      " 51%|██████████████████████                     | 19/37 [00:57<00:52,  2.91s/it]\u001b[A\n",
      " 54%|███████████████████████▏                   | 20/37 [00:57<00:38,  2.24s/it]\u001b[A\n",
      " 57%|████████████████████████▍                  | 21/37 [00:58<00:29,  1.82s/it]\u001b[A\n",
      " 59%|█████████████████████████▌                 | 22/37 [00:59<00:22,  1.48s/it]\u001b[A\n",
      " 62%|██████████████████████████▋                | 23/37 [01:00<00:18,  1.29s/it]\u001b[A\n",
      " 65%|███████████████████████████▉               | 24/37 [01:00<00:15,  1.16s/it]\u001b[A\n",
      " 68%|█████████████████████████████              | 25/37 [01:09<00:39,  3.28s/it]\u001b[A\n",
      " 70%|██████████████████████████████▏            | 26/37 [01:10<00:28,  2.58s/it]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 27/37 [01:11<00:22,  2.21s/it]\u001b[A\n",
      " 76%|████████████████████████████████▌          | 28/37 [01:12<00:15,  1.75s/it]\u001b[A\n",
      " 78%|█████████████████████████████████▋         | 29/37 [01:20<00:29,  3.70s/it]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 30/37 [01:21<00:20,  2.92s/it]\u001b[A\n",
      " 84%|████████████████████████████████████       | 31/37 [01:22<00:14,  2.35s/it]\u001b[A\n",
      " 86%|█████████████████████████████████████▏     | 32/37 [01:23<00:09,  1.95s/it]\u001b[A\n",
      " 89%|██████████████████████████████████████▎    | 33/37 [01:24<00:06,  1.57s/it]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 34/37 [01:24<00:03,  1.31s/it]\u001b[A\n",
      " 95%|████████████████████████████████████████▋  | 35/37 [01:25<00:02,  1.17s/it]\u001b[A\n",
      " 97%|█████████████████████████████████████████▊ | 36/37 [01:26<00:01,  1.01s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 1.0017151832580566, 'eval_cer': 1028.4263959390862, 'eval_runtime': 114.3786, 'eval_samples_per_second': 0.323, 'eval_steps_per_second': 0.323, 'epoch': 2.0}\n",
      " 40%|████████████████▊                         | 74/185 [04:28<01:29,  1.24it/s]\n",
      "100%|███████████████████████████████████████████| 37/37 [01:53<00:00,  3.11s/it]\u001b[A\n",
      "                                                                                \u001b[ASome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n",
      "/home/ec2-user/SageMaker/efs/conda_envs/whisper_py310/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      " 60%|████████████████████████▌                | 111/185 [05:35<00:58,  1.26it/s]\n",
      "  0%|                                                    | 0/37 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|██▍                                         | 2/37 [00:00<00:14,  2.47it/s]\u001b[A\n",
      "  8%|███▌                                        | 3/37 [00:01<00:19,  1.75it/s]\u001b[A\n",
      " 11%|████▊                                       | 4/37 [00:02<00:21,  1.52it/s]\u001b[A\n",
      " 14%|█████▉                                      | 5/37 [00:03<00:22,  1.42it/s]\u001b[A\n",
      " 16%|███████▏                                    | 6/37 [00:04<00:22,  1.36it/s]\u001b[A\n",
      " 19%|████████▎                                   | 7/37 [00:04<00:22,  1.32it/s]\u001b[A\n",
      " 22%|█████████▌                                  | 8/37 [00:05<00:22,  1.30it/s]\u001b[A\n",
      " 24%|██████████▋                                 | 9/37 [00:06<00:21,  1.28it/s]\u001b[A\n",
      " 27%|███████████▌                               | 10/37 [00:07<00:21,  1.27it/s]\u001b[A\n",
      " 30%|████████████▊                              | 11/37 [00:08<00:20,  1.26it/s]\u001b[A\n",
      " 32%|█████████████▉                             | 12/37 [00:08<00:19,  1.26it/s]\u001b[A\n",
      " 35%|███████████████                            | 13/37 [00:09<00:19,  1.26it/s]\u001b[A\n",
      " 38%|████████████████▎                          | 14/37 [00:10<00:18,  1.26it/s]\u001b[A\n",
      " 41%|█████████████████▍                         | 15/37 [00:11<00:17,  1.26it/s]\u001b[A\n",
      " 43%|██████████████████▌                        | 16/37 [00:12<00:16,  1.26it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 17/37 [00:12<00:15,  1.26it/s]\u001b[A\n",
      " 49%|████████████████████▉                      | 18/37 [00:13<00:15,  1.26it/s]\u001b[A\n",
      " 51%|██████████████████████                     | 19/37 [00:14<00:14,  1.25it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 20/37 [00:15<00:13,  1.25it/s]\u001b[A\n",
      " 57%|████████████████████████▍                  | 21/37 [00:16<00:12,  1.25it/s]\u001b[A\n",
      " 59%|█████████████████████████▌                 | 22/37 [00:16<00:12,  1.25it/s]\u001b[A\n",
      " 62%|██████████████████████████▋                | 23/37 [00:17<00:11,  1.25it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 24/37 [00:18<00:10,  1.25it/s]\u001b[A\n",
      " 68%|█████████████████████████████              | 25/37 [00:19<00:09,  1.25it/s]\u001b[A\n",
      " 70%|██████████████████████████████▏            | 26/37 [00:19<00:08,  1.25it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 27/37 [00:20<00:07,  1.26it/s]\u001b[A\n",
      " 76%|████████████████████████████████▌          | 28/37 [00:21<00:07,  1.25it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▋         | 29/37 [00:22<00:06,  1.25it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 30/37 [00:23<00:05,  1.25it/s]\u001b[A\n",
      " 84%|████████████████████████████████████       | 31/37 [00:23<00:04,  1.25it/s]\u001b[A\n",
      " 86%|█████████████████████████████████████▏     | 32/37 [00:24<00:03,  1.25it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▎    | 33/37 [00:25<00:03,  1.25it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 34/37 [00:26<00:02,  1.25it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▋  | 35/37 [00:27<00:01,  1.25it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▊ | 36/37 [00:27<00:00,  1.25it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.782383382320404, 'eval_cer': 81.7258883248731, 'eval_runtime': 48.4212, 'eval_samples_per_second': 0.764, 'eval_steps_per_second': 0.764, 'epoch': 3.0}\n",
      " 60%|████████████████████████▌                | 111/185 [06:23<00:58,  1.26it/s]\n",
      "100%|███████████████████████████████████████████| 37/37 [00:47<00:00,  1.32it/s]\u001b[A\n",
      "                                                                                \u001b[ASome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n",
      "/home/ec2-user/SageMaker/efs/conda_envs/whisper_py310/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      " 80%|████████████████████████████████▊        | 148/185 [07:30<00:29,  1.23it/s]\n",
      "  0%|                                                    | 0/37 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|██▍                                         | 2/37 [00:00<00:14,  2.48it/s]\u001b[A\n",
      "  8%|███▌                                        | 3/37 [00:01<00:19,  1.76it/s]\u001b[A\n",
      " 11%|████▊                                       | 4/37 [00:02<00:21,  1.54it/s]\u001b[A\n",
      " 14%|█████▉                                      | 5/37 [00:03<00:22,  1.43it/s]\u001b[A\n",
      " 16%|███████▏                                    | 6/37 [00:03<00:22,  1.37it/s]\u001b[A\n",
      " 19%|████████▎                                   | 7/37 [00:04<00:22,  1.32it/s]\u001b[A\n",
      " 22%|█████████▌                                  | 8/37 [00:05<00:22,  1.30it/s]\u001b[A\n",
      " 24%|██████████▋                                 | 9/37 [00:06<00:21,  1.28it/s]\u001b[A\n",
      " 27%|███████████▌                               | 10/37 [00:07<00:21,  1.27it/s]\u001b[A\n",
      " 30%|████████████▊                              | 11/37 [00:07<00:20,  1.27it/s]\u001b[A\n",
      " 32%|█████████████▉                             | 12/37 [00:08<00:19,  1.27it/s]\u001b[A\n",
      " 35%|███████████████                            | 13/37 [00:09<00:18,  1.26it/s]\u001b[A\n",
      " 38%|████████████████▎                          | 14/37 [00:10<00:18,  1.26it/s]\u001b[A\n",
      " 41%|█████████████████▍                         | 15/37 [00:11<00:17,  1.26it/s]\u001b[A\n",
      " 43%|██████████████████▌                        | 16/37 [00:11<00:16,  1.26it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 17/37 [00:12<00:15,  1.26it/s]\u001b[A\n",
      " 49%|████████████████████▉                      | 18/37 [00:13<00:15,  1.26it/s]\u001b[A\n",
      " 51%|██████████████████████                     | 19/37 [00:14<00:14,  1.26it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 20/37 [00:15<00:13,  1.26it/s]\u001b[A\n",
      " 57%|████████████████████████▍                  | 21/37 [00:15<00:12,  1.26it/s]\u001b[A\n",
      " 59%|█████████████████████████▌                 | 22/37 [00:16<00:11,  1.26it/s]\u001b[A\n",
      " 62%|██████████████████████████▋                | 23/37 [00:17<00:11,  1.25it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 24/37 [00:18<00:10,  1.25it/s]\u001b[A\n",
      " 68%|█████████████████████████████              | 25/37 [00:19<00:09,  1.25it/s]\u001b[A\n",
      " 70%|██████████████████████████████▏            | 26/37 [00:19<00:08,  1.25it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 27/37 [00:20<00:07,  1.26it/s]\u001b[A\n",
      " 76%|████████████████████████████████▌          | 28/37 [00:21<00:07,  1.25it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▋         | 29/37 [00:22<00:06,  1.25it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 30/37 [00:23<00:05,  1.25it/s]\u001b[A\n",
      " 84%|████████████████████████████████████       | 31/37 [00:23<00:04,  1.25it/s]\u001b[A\n",
      " 86%|█████████████████████████████████████▏     | 32/37 [00:24<00:03,  1.25it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▎    | 33/37 [00:25<00:03,  1.26it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 34/37 [00:26<00:02,  1.25it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▋  | 35/37 [00:27<00:01,  1.25it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▊ | 36/37 [00:27<00:00,  1.25it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 1.2435855865478516, 'eval_cer': 80.20304568527918, 'eval_runtime': 48.0828, 'eval_samples_per_second': 0.77, 'eval_steps_per_second': 0.77, 'epoch': 4.0}\n",
      " 80%|████████████████████████████████▊        | 148/185 [08:18<00:29,  1.23it/s]\n",
      "100%|███████████████████████████████████████████| 37/37 [00:47<00:00,  1.32it/s]\u001b[A\n",
      "                                                                                \u001b[ASome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n",
      "/home/ec2-user/SageMaker/efs/conda_envs/whisper_py310/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████| 185/185 [09:24<00:00,  1.25it/s]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n",
      "\n",
      "  0%|                                                    | 0/37 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|██▍                                         | 2/37 [00:00<00:13,  2.53it/s]\u001b[A\n",
      "  8%|███▌                                        | 3/37 [00:01<00:19,  1.78it/s]\u001b[A\n",
      " 11%|████▊                                       | 4/37 [00:02<00:21,  1.54it/s]\u001b[A\n",
      " 14%|█████▉                                      | 5/37 [00:03<00:22,  1.42it/s]\u001b[A\n",
      " 16%|███████▏                                    | 6/37 [00:03<00:22,  1.36it/s]\u001b[A\n",
      " 19%|████████▎                                   | 7/37 [00:04<00:22,  1.33it/s]\u001b[A\n",
      " 22%|█████████▌                                  | 8/37 [00:05<00:22,  1.30it/s]\u001b[A\n",
      " 24%|██████████▋                                 | 9/37 [00:06<00:21,  1.28it/s]\u001b[A\n",
      " 27%|███████████▌                               | 10/37 [00:07<00:21,  1.27it/s]\u001b[A\n",
      " 30%|████████████▊                              | 11/37 [00:07<00:20,  1.26it/s]\u001b[A\n",
      " 32%|█████████████▉                             | 12/37 [00:08<00:19,  1.26it/s]\u001b[A\n",
      " 35%|███████████████                            | 13/37 [00:09<00:19,  1.25it/s]\u001b[A\n",
      " 38%|████████████████▎                          | 14/37 [00:10<00:18,  1.25it/s]\u001b[A\n",
      " 41%|█████████████████▍                         | 15/37 [00:11<00:17,  1.25it/s]\u001b[A\n",
      " 43%|██████████████████▌                        | 16/37 [00:12<00:16,  1.25it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 17/37 [00:12<00:16,  1.25it/s]\u001b[A\n",
      " 49%|████████████████████▉                      | 18/37 [00:13<00:15,  1.24it/s]\u001b[A\n",
      " 51%|██████████████████████                     | 19/37 [00:14<00:14,  1.25it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 20/37 [00:15<00:13,  1.25it/s]\u001b[A\n",
      " 57%|████████████████████████▍                  | 21/37 [00:16<00:12,  1.25it/s]\u001b[A\n",
      " 59%|█████████████████████████▌                 | 22/37 [00:16<00:12,  1.24it/s]\u001b[A\n",
      " 62%|██████████████████████████▋                | 23/37 [00:17<00:11,  1.25it/s]\u001b[A\n",
      " 65%|███████████████████████████▉               | 24/37 [00:18<00:10,  1.25it/s]\u001b[A\n",
      " 68%|█████████████████████████████              | 25/37 [00:19<00:09,  1.25it/s]\u001b[A\n",
      " 70%|██████████████████████████████▏            | 26/37 [00:20<00:08,  1.25it/s]\u001b[A\n",
      " 73%|███████████████████████████████▍           | 27/37 [00:20<00:08,  1.25it/s]\u001b[A\n",
      " 76%|████████████████████████████████▌          | 28/37 [00:21<00:07,  1.25it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▋         | 29/37 [00:22<00:06,  1.25it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▊        | 30/37 [00:23<00:05,  1.25it/s]\u001b[A\n",
      " 84%|████████████████████████████████████       | 31/37 [00:24<00:04,  1.25it/s]\u001b[A\n",
      " 86%|█████████████████████████████████████▏     | 32/37 [00:24<00:03,  1.25it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▎    | 33/37 [00:25<00:03,  1.25it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 34/37 [00:26<00:02,  1.25it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████▋  | 35/37 [00:27<00:01,  1.25it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▊ | 36/37 [00:28<00:00,  1.25it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 1.1661362648010254, 'eval_cer': 80.20304568527918, 'eval_runtime': 48.2137, 'eval_samples_per_second': 0.767, 'eval_steps_per_second': 0.767, 'epoch': 5.0}\n",
      "100%|█████████████████████████████████████████| 185/185 [10:48<00:00,  1.25it/s]\n",
      "100%|███████████████████████████████████████████| 37/37 [00:47<00:00,  1.33it/s]\u001b[A\n",
      "                                                                                \u001b[ASome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n",
      "There were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n",
      "{'train_runtime': 709.0906, 'train_samples_per_second': 0.261, 'train_steps_per_second': 0.261, 'train_loss': 1.5108362146326013, 'epoch': 5.0}\n",
      "100%|█████████████████████████████████████████| 185/185 [11:49<00:00,  3.83s/it]\n",
      "DONE TRAINING\n"
     ]
    }
   ],
   "source": [
    "!bash train.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34705651-b72b-4457-8bea-798e34251fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_whisper_py310",
   "language": "python",
   "name": "conda_whisper_py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
