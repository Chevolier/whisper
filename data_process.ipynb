{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f40caf1-4209-48c6-961e-2e097aacae5a",
   "metadata": {},
   "source": [
    "# prepare text and audio_paths files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1797e649-f631-4908-bde2-957e7dbe32b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a8f51c60-5a4a-4765-aa79-638f76d2f9b2.amr', 'c40afd4e-dafb-40a5-8c6e-ce9283a33278.amr', '94a7e398-202d-4bcc-b991-81eced1c892f.amr', '19a69c77-0be3-49d5-8d0d-90fea3c7a1c4.amr', '7997ef05-06ce-4389-a915-c291782ae901.amr']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_dir = \"data/test\"\n",
    "\n",
    "filenames = [filename for filename in os.listdir(os.path.join(data_dir, \"clips\")) if filename.endswith('.amr')]\n",
    "print(filenames[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abeac1f-2e07-4944-af33-b6ab8fef9d00",
   "metadata": {},
   "source": [
    "## convert amr to mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d21eea4c-bb0d-4bfc-bf10-308dca490041",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "465ca1a8-f847-4d34-95e6-2f6dfb4a1b31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from pydub import AudioSegment\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# for filename in tqdm(filenames, total=len(filenames)):\n",
    "    \n",
    "#     amr_audio = AudioSegment.from_file(data_dir+f'/clips/{filename}', format=\"amr\")\n",
    "#     amr_audio.export(data_dir+f'/clips/{filename[:-3]}mp3', format=\"mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f36f369a-2736-41d0-b0f1-5a6bfa4f3231",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_name</th>\n",
       "      <th>content</th>\n",
       "      <th>user_id</th>\n",
       "      <th>record_file_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model</td>\n",
       "      <td>CMSN 20 si</td>\n",
       "      <td>wuzy37</td>\n",
       "      <td>8deb96cd-1939-46d0-8f87-5bd798ade923.amr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model</td>\n",
       "      <td>CMSRO 20di cr</td>\n",
       "      <td>wuzy37</td>\n",
       "      <td>09b311d8-c557-4bfb-bac5-f0d18a5da8e9.amr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model</td>\n",
       "      <td>CMSN 20 si</td>\n",
       "      <td>ex_xietian2</td>\n",
       "      <td>6ae92f35-3139-417c-b0f4-d30ac25b3937.amr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Model</td>\n",
       "      <td>CMSRO 20di cr</td>\n",
       "      <td>ex_xietian2</td>\n",
       "      <td>3b65f69e-5aea-4211-acaf-b7bb2f651755.amr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Model</td>\n",
       "      <td>CMSRO 20di rd</td>\n",
       "      <td>ex_xietian2</td>\n",
       "      <td>c40afd4e-dafb-40a5-8c6e-ce9283a33278.amr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category_name        content      user_id  \\\n",
       "0         Model     CMSN 20 si       wuzy37   \n",
       "1         Model  CMSRO 20di cr       wuzy37   \n",
       "2         Model     CMSN 20 si  ex_xietian2   \n",
       "3         Model  CMSRO 20di cr  ex_xietian2   \n",
       "4         Model  CMSRO 20di rd  ex_xietian2   \n",
       "\n",
       "                             record_file_id  \n",
       "0  8deb96cd-1939-46d0-8f87-5bd798ade923.amr  \n",
       "1  09b311d8-c557-4bfb-bac5-f0d18a5da8e9.amr  \n",
       "2  6ae92f35-3139-417c-b0f4-d30ac25b3937.amr  \n",
       "3  3b65f69e-5aea-4211-acaf-b7bb2f651755.amr  \n",
       "4  c40afd4e-dafb-40a5-8c6e-ce9283a33278.amr  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_data = pd.read_csv(os.path.join(data_dir, \"è¯­æ–™.csv\"))\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eebb10b2-8c43-4084-b245-45e7e004523c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_path = os.path.join(data_dir, 'text')\n",
    "audio_paths_path = os.path.join(data_dir, 'audio_paths')\n",
    "\n",
    "with open(text_path, 'w') as fo1, open(audio_paths_path, 'w') as fo2:\n",
    "    for filename in filenames:\n",
    "        part_name, part_format = filename.split('.')\n",
    "        content = df_data[df_data['record_file_id']==filename].reset_index(drop=True).loc[0, 'content']\n",
    "        \n",
    "        fo1.write(part_name+' '+content+'\\n')\n",
    "        abs_path = os.path.abspath(os.path.join(data_dir+'/clips', filename[:-3]+'mp3'))\n",
    "        fo2.write(part_name+' '+abs_path+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510d87d6-4994-48fe-8bd7-a7e60db9c3ec",
   "metadata": {},
   "source": [
    "# process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3ca7a5d-2f26-4e88-95c1-9cf37cfa7e22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python3 finetune/custom_data/data_prep.py \\\n",
    "# --source_data_dir data/test \\\n",
    "# --output_data_dir data/custom_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffe5026-0f87-4d10-952e-f1e44dea6c82",
   "metadata": {},
   "source": [
    "# finetuning on huggingface dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73c4d188-216c-460d-afc8-1ee0443e2044",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /home/ec2-user/SageMaker/efs/conda_envs/whisper_py310/lib/python3.10/site-packages (0.23.2)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/SageMaker/efs/conda_envs/whisper_py310/lib/python3.10/site-packages (from huggingface_hub) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/SageMaker/efs/conda_envs/whisper_py310/lib/python3.10/site-packages (from huggingface_hub) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ec2-user/SageMaker/efs/conda_envs/whisper_py310/lib/python3.10/site-packages (from huggingface_hub) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/SageMaker/efs/conda_envs/whisper_py310/lib/python3.10/site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: requests in /home/ec2-user/SageMaker/efs/conda_envs/whisper_py310/lib/python3.10/site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ec2-user/SageMaker/efs/conda_envs/whisper_py310/lib/python3.10/site-packages (from huggingface_hub) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/SageMaker/efs/conda_envs/whisper_py310/lib/python3.10/site-packages (from huggingface_hub) (4.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/SageMaker/efs/conda_envs/whisper_py310/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/SageMaker/efs/conda_envs/whisper_py310/lib/python3.10/site-packages (from requests->huggingface_hub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/SageMaker/efs/conda_envs/whisper_py310/lib/python3.10/site-packages (from requests->huggingface_hub) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/SageMaker/efs/conda_envs/whisper_py310/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8d43b3c-291d-4cbb-b6f8-926fbb9c06c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: huggingface-cli <command> [<args>]\n",
      "huggingface-cli: error: unrecognized arguments: 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\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2ed6160-5a9b-4e1a-b48d-bd499b5abc90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train_hf.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile train_hf.sh\n",
    "\n",
    "ngpu=1  # number of GPUs to perform distributed training on.\n",
    "\n",
    "torchrun --nproc_per_node=${ngpu} finetune/train/fine-tune_on_hf_dataset.py \\\n",
    "--model_name /home/ec2-user/SageMaker/efs/Models/whisper-large-v3 \\\n",
    "--language Cantonese \\\n",
    "--sampling_rate 16000 \\\n",
    "--num_proc ${ngpu} \\\n",
    "--train_strategy steps \\\n",
    "--learning_rate 3e-3 \\\n",
    "--warmup 1000 \\\n",
    "--train_batchsize 1 \\\n",
    "--eval_batchsize 1 \\\n",
    "--num_steps 10000 \\\n",
    "--resume_from_ckpt None \\\n",
    "--output_dir op_dir_steps \\\n",
    "--train_datasets mozilla-foundation/common_voice_17_0  \\\n",
    "--train_dataset_configs yue \\\n",
    "--train_dataset_splits validation \\\n",
    "--train_dataset_text_columns sentence \\\n",
    "--eval_datasets mozilla-foundation/common_voice_17_0 \\\n",
    "--eval_dataset_configs yue \\\n",
    "--eval_dataset_splits test \\\n",
    "--eval_dataset_text_columns sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901e3519-b6a9-430c-bcc3-6dec2a25f919",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "ARGUMENTS OF INTEREST:\n",
      "{'model_name': '/home/ec2-user/SageMaker/efs/Models/whisper-large-v3', 'language': 'Cantonese', 'sampling_rate': 16000, 'num_proc': 1, 'train_strategy': 'steps', 'learning_rate': 0.003, 'warmup': 1000, 'train_batchsize': 1, 'eval_batchsize': 1, 'num_epochs': 20, 'num_steps': 10000, 'resume_from_ckpt': 'None', 'output_dir': 'op_dir_steps', 'train_datasets': ['mozilla-foundation/common_voice_17_0'], 'train_dataset_configs': ['yue'], 'train_dataset_splits': ['validation'], 'train_dataset_text_columns': ['sentence'], 'eval_datasets': ['mozilla-foundation/common_voice_17_0'], 'eval_dataset_configs': ['yue'], 'eval_dataset_splits': ['test'], 'eval_dataset_text_columns': ['sentence']}\n",
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "DATASET PREPARATION IN PROGRESS...\n",
      "/home/ec2-user/SageMaker/efs/conda_envs/whisper_py310/lib/python3.10/site-packages/datasets/load.py:1491: FutureWarning: The repository for mozilla-foundation/common_voice_17_0 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mozilla-foundation/common_voice_17_0\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Downloading builder script: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8.19k/8.19k [00:00<00:00, 45.3MB/s]\n",
      "Downloading readme: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12.6k/12.6k [00:00<00:00, 50.1MB/s]\n",
      "Downloading extra modules: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.92k/3.92k [00:00<00:00, 35.3MB/s]\n",
      "Downloading extra modules: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132k/132k [00:00<00:00, 11.0MB/s]\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17.5k/17.5k [00:00<00:00, 60.2MB/s]\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79.6M/79.6M [00:01<00:00, 62.1MB/s]\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67.8M/67.8M [00:01<00:00, 42.3MB/s]\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73.1M/73.1M [00:00<00:00, 111MB/s]\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.00G/1.00G [00:13<00:00, 74.5MB/s]\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 967M/967M [00:11<00:00, 82.2MB/s]\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 942M/942M [00:20<00:00, 46.2MB/s]\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 462M/462M [00:16<00:00, 28.6MB/s]\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50.3M/50.3M [00:00<00:00, 77.6MB/s]\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 554M/554M [00:07<00:00, 70.3MB/s]\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 973k/973k [00:00<00:00, 14.0MB/s]\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 745k/745k [00:00<00:00, 22.6MB/s]\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 724k/724k [00:00<00:00, 23.7MB/s]\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41.5M/41.5M [00:00<00:00, 79.4MB/s]\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 591k/591k [00:00<00:00, 20.7MB/s]\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.49M/6.49M [00:00<00:00, 10.9MB/s]\n",
      "Generating train split: 0 examples [00:00, ? examples/s]\n",
      "Reading metadata...: 3150it [00:00, 176179.56it/s]\n",
      "Generating train split: 3150 examples [00:02, 1371.39 examples/s]\n",
      "Generating validation split: 0 examples [00:00, ? examples/s]\n",
      "Reading metadata...: 2602it [00:00, 179712.47it/s]\n",
      "Generating validation split: 2602 examples [00:01, 1418.67 examples/s]\n",
      "Generating test split: 0 examples [00:00, ? examples/s]\n",
      "Reading metadata...: 2626it [00:00, 171756.71it/s]\n",
      "Generating test split: 2626 examples [00:01, 1380.79 examples/s]\n",
      "Generating other split: 0 examples [00:00, ? examples/s]\n",
      "Reading metadata...: 0it [00:00, ?it/s]\u001b[A\n",
      "Reading metadata...: 17313it [00:00, 173111.18it/s]\u001b[A\n",
      "Reading metadata...: 34625it [00:00, 165857.75it/s]\u001b[A\n",
      "Reading metadata...: 51232it [00:00, 163038.01it/s]\u001b[A\n",
      "Reading metadata...: 67547it [00:00, 161281.24it/s]\u001b[A\n",
      "Reading metadata...: 83681it [00:00, 159844.37it/s]\u001b[A\n",
      "Reading metadata...: 99668it [00:00, 158652.02it/s]\u001b[A\n",
      "Reading metadata...: 115534it [00:00, 158525.59it/s]\u001b[A\n",
      "Reading metadata...: 141697it [00:00, 160697.94it/s]\u001b[A\n",
      "Generating other split: 141697 examples [00:25, 5505.65 examples/s]\n",
      "Generating invalidated split: 0 examples [00:00, ? examples/s]\n",
      "Reading metadata...: 1760it [00:00, 169571.93it/s]\n",
      "Generating invalidated split: 1760 examples [00:00, 5611.11 examples/s]\n",
      "Generating validated split: 0 examples [00:00, ? examples/s]\n",
      "Reading metadata...: 0it [00:00, ?it/s]\u001b[A\n",
      "Reading metadata...: 21758it [00:00, 177748.22it/s]\u001b[A\n",
      "Generating validated split: 21758 examples [00:03, 5783.45 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2602/2602 [03:06<00:00, 13.96 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2626/2626 [03:14<00:00, 13.53 examples/s]\n",
      "Filter: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2602/2602 [00:00<00:00, 94632.42 examples/s]\n",
      "Filter: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2626/2626 [00:00<00:00, 99751.33 examples/s]\n",
      "DATASET PREPARATION COMPLETED\n",
      "/home/ec2-user/SageMaker/efs/conda_envs/whisper_py310/lib/python3.10/site-packages/transformers/training_args.py:1493: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "TRAINING IN PROGRESS...\n",
      "  0%|                                                 | 0/10000 [00:00<?, ?it/s]/home/ec2-user/SageMaker/efs/conda_envs/whisper_py310/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 31.9513, 'grad_norm': 37.168418884277344, 'learning_rate': 0.001479, 'epoch': 0.19}\n",
      "  6%|â–ˆâ–ˆâ–Ž                                  | 619/10000 [08:36<2:09:06,  1.21it/s]"
     ]
    }
   ],
   "source": [
    "!bash train_hf.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c9810a-1f59-4282-805b-5dec6181fcd1",
   "metadata": {},
   "source": [
    "# finetuning on custom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "490a454a-47d3-4ec1-971a-6c01a5708855",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.sh\n",
    "\n",
    "ngpu=1  # number of GPUs to perform distributed training on.\n",
    "\n",
    "torchrun --nproc_per_node=${ngpu} finetune/train/fine-tune_on_custom_dataset.py \\\n",
    "--model_name /home/ec2-user/SageMaker/efs/Models/whisper-large-v3 \\\n",
    "--language Cantonese \\\n",
    "--sampling_rate 16000 \\\n",
    "--num_proc ${ngpu} \\\n",
    "--train_strategy epoch \\\n",
    "--learning_rate 3e-3 \\\n",
    "--warmup 1000 \\\n",
    "--train_batchsize ${train_batch_size} \\\n",
    "--eval_batchsize ${eval_batch_size} \\\n",
    "--num_epochs 2 \\\n",
    "--resume_from_ckpt None \\\n",
    "--output_dir checkpoint \\\n",
    "--train_datasets data/custom_test_data \\\n",
    "--eval_datasets data/custom_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a73c79c-c8da-4f95-b5b0-46d96b698f6f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "ARGUMENTS OF INTEREST:\n",
      "{'model_name': '/home/ec2-user/SageMaker/efs/Models/whisper-large-v3', 'language': 'Cantonese', 'sampling_rate': 16000, 'num_proc': 1, 'train_strategy': 'epoch', 'learning_rate': 0.003, 'warmup': 1000, 'train_batchsize': 1, 'eval_batchsize': 1, 'num_epochs': 2, 'num_steps': 100000, 'resume_from_ckpt': 'None', 'output_dir': 'checkpoint', 'train_datasets': ['data/custom_test_data'], 'eval_datasets': ['data/custom_test_data']}\n",
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "DATASET PREPARATION IN PROGRESS...\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:05<00:00,  7.22 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:03<00:00, 11.15 examples/s]\n",
      "Filter: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:00<00:00, 1899.80 examples/s]\n",
      "Filter: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:00<00:00, 1856.09 examples/s]\n",
      "DATASET PREPARATION COMPLETED\n",
      "TRAINING IN PROGRESS...\n",
      "  0%|                                                    | 0/74 [00:00<?, ?it/s]/home/ec2-user/SageMaker/efs/conda_envs/whisper_py310/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 37/74 [00:31<00:28,  1.28it/s]Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "\n",
      "  0%|                                                    | 0/37 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|â–ˆâ–ˆâ–                                         | 2/37 [00:00<00:15,  2.23it/s]\u001b[A\n",
      "  8%|â–ˆâ–ˆâ–ˆâ–Œ                                        | 3/37 [00:01<00:21,  1.60it/s]\u001b[A\n",
      " 11%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š                                       | 4/37 [00:02<00:24,  1.35it/s]\u001b[A\n",
      " 14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                      | 5/37 [00:03<00:25,  1.24it/s]\u001b[A\n",
      " 16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                    | 6/37 [00:04<00:26,  1.19it/s]\u001b[A\n",
      " 19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                   | 7/37 [00:05<00:25,  1.18it/s]\u001b[A\n",
      " 22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                  | 8/37 [00:06<00:24,  1.16it/s]\u001b[A\n",
      " 24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                 | 9/37 [00:07<00:23,  1.17it/s]\u001b[A\n",
      " 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                               | 10/37 [00:07<00:22,  1.18it/s]\u001b[A\n",
      " 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                              | 11/37 [00:08<00:21,  1.18it/s]\u001b[A\n",
      " 32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                             | 12/37 [00:09<00:21,  1.19it/s]\u001b[A\n",
      " 35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                            | 13/37 [00:10<00:20,  1.18it/s]\u001b[A\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                          | 14/37 [00:11<00:23,  1.01s/it]\u001b[A\n",
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 15/37 [00:12<00:20,  1.08it/s]\u001b[A\n",
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                        | 16/37 [00:13<00:18,  1.13it/s]\u001b[A\n",
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                       | 17/37 [00:14<00:17,  1.16it/s]\u001b[A\n",
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                      | 18/37 [00:15<00:15,  1.19it/s]\u001b[A\n",
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     | 19/37 [00:15<00:14,  1.21it/s]\u001b[A\n",
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 20/37 [00:16<00:13,  1.23it/s]\u001b[A\n",
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 21/37 [00:17<00:13,  1.19it/s]\u001b[A\n",
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                 | 22/37 [00:18<00:12,  1.23it/s]\u001b[A\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                | 23/37 [00:19<00:11,  1.21it/s]\u001b[A\n",
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰               | 24/37 [00:20<00:11,  1.17it/s]\u001b[A\n",
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              | 25/37 [00:20<00:10,  1.17it/s]\u001b[A\n",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–            | 26/37 [00:21<00:09,  1.17it/s]\u001b[A\n",
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 27/37 [00:22<00:08,  1.16it/s]\u001b[A\n",
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ          | 28/37 [00:23<00:07,  1.23it/s]\u001b[A\n",
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹         | 29/37 [00:24<00:06,  1.16it/s]\u001b[A\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š        | 30/37 [00:25<00:05,  1.21it/s]\u001b[A\n",
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       | 31/37 [00:25<00:04,  1.24it/s]\u001b[A\n",
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 32/37 [00:26<00:03,  1.28it/s]\u001b[A\n",
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 33/37 [00:27<00:03,  1.28it/s]\u001b[A\n",
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 34/37 [00:28<00:02,  1.27it/s]\u001b[A\n",
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 35/37 [00:28<00:01,  1.23it/s]\u001b[A\n",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 36/37 [00:29<00:00,  1.25it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8018691539764404, 'eval_cer': 37.6940133037694, 'eval_runtime': 49.8487, 'eval_samples_per_second': 0.742, 'eval_steps_per_second': 0.742, 'epoch': 1.0}\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 37/74 [01:21<00:28,  1.28it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:48<00:00,  1.31it/s]\u001b[A\n",
      "                                                                                \u001b[ASome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n",
      "/home/ec2-user/SageMaker/efs/conda_envs/whisper_py310/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [02:39<00:00,  1.28it/s]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n",
      "\n",
      "  0%|                                                    | 0/37 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|â–ˆâ–ˆâ–                                         | 2/37 [00:08<02:29,  4.26s/it]\u001b[A\n",
      "  8%|â–ˆâ–ˆâ–ˆâ–Œ                                        | 3/37 [00:16<03:18,  5.83s/it]\u001b[A\n",
      " 11%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š                                       | 4/37 [00:24<03:39,  6.64s/it]\u001b[A\n",
      " 14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                      | 5/37 [00:32<03:45,  7.05s/it]\u001b[A\n",
      " 16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                    | 6/37 [00:40<03:46,  7.30s/it]\u001b[A\n",
      " 19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                   | 7/37 [00:48<03:44,  7.47s/it]\u001b[A\n",
      " 22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                  | 8/37 [00:55<03:41,  7.63s/it]\u001b[A\n",
      " 24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                 | 9/37 [01:03<03:36,  7.72s/it]\u001b[A\n",
      " 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                               | 10/37 [01:11<03:29,  7.77s/it]\u001b[A\n",
      " 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                              | 11/37 [01:19<03:23,  7.82s/it]\u001b[A\n",
      " 32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                             | 12/37 [01:27<03:15,  7.80s/it]\u001b[A\n",
      " 35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                            | 13/37 [01:35<03:07,  7.80s/it]\u001b[A\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                          | 14/37 [01:43<02:59,  7.82s/it]\u001b[A\n",
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 15/37 [01:50<02:51,  7.81s/it]\u001b[A\n",
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                        | 16/37 [01:58<02:43,  7.81s/it]\u001b[A\n",
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                       | 17/37 [01:59<01:55,  5.78s/it]\u001b[A\n",
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                      | 18/37 [02:07<02:01,  6.40s/it]\u001b[A\n",
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     | 19/37 [02:15<02:02,  6.83s/it]\u001b[A\n",
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 20/37 [02:23<02:00,  7.11s/it]\u001b[A\n",
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 21/37 [02:31<01:57,  7.33s/it]\u001b[A\n",
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                 | 22/37 [02:38<01:51,  7.47s/it]\u001b[A\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                | 23/37 [02:46<01:46,  7.62s/it]\u001b[A\n",
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰               | 24/37 [02:54<01:40,  7.74s/it]\u001b[A\n",
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              | 25/37 [03:02<01:33,  7.78s/it]\u001b[A\n",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–            | 26/37 [03:10<01:26,  7.90s/it]\u001b[A\n",
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 27/37 [03:18<01:18,  7.86s/it]\u001b[A\n",
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ          | 28/37 [03:26<01:10,  7.83s/it]\u001b[A\n",
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹         | 29/37 [03:34<01:02,  7.83s/it]\u001b[A\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š        | 30/37 [03:42<00:54,  7.80s/it]\u001b[A\n",
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       | 31/37 [03:43<00:34,  5.77s/it]\u001b[A\n",
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 32/37 [03:50<00:31,  6.36s/it]\u001b[A\n",
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 33/37 [03:58<00:27,  6.79s/it]\u001b[A\n",
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 34/37 [04:06<00:21,  7.07s/it]\u001b[A\n",
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 35/37 [04:14<00:14,  7.30s/it]\u001b[A\n",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 36/37 [04:22<00:07,  7.48s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 1.2237664461135864, 'eval_cer': 2663.6363636363635, 'eval_runtime': 296.0501, 'eval_samples_per_second': 0.125, 'eval_steps_per_second': 0.125, 'epoch': 2.0}\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [08:22<00:00,  1.28it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [04:47<00:00,  7.59s/it]\u001b[A\n",
      "                                                                                \u001b[ASome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n",
      "There were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n",
      "{'train_runtime': 563.9377, 'train_samples_per_second': 0.131, 'train_steps_per_second': 0.131, 'train_loss': 2.1076977704022384, 'epoch': 2.0}\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [09:23<00:00,  7.62s/it]\n",
      "DONE TRAINING\n"
     ]
    }
   ],
   "source": [
    "!bash train.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34705651-b72b-4457-8bea-798e34251fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_whisper_py310",
   "language": "python",
   "name": "conda_whisper_py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
