{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db53f808-9fbd-408d-a6a0-d18200733876",
   "metadata": {},
   "source": [
    "## Using Huggingface DLC to Host the Whisper Model for Automatic Speech Recognition Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a75f20-21ff-4d05-a0e8-50a6ceaa49c2",
   "metadata": {},
   "source": [
    "## Common set up \n",
    "**❗If you run this notebook in SageMaker Studio, please select the Data Science 2.0 image and choose the ml.m5.large instance.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12501f18-d807-4337-b4e9-7e1c2d7590df",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Install required packages\n",
    "# %pip install openai-whisper # ==20230918 # -q\n",
    "# %pip install torchaudio # ==2.1.0 # -q\n",
    "# %pip install datasets # ==2.16.1 # -q\n",
    "# %pip install sagemaker # ==2.184.0 # -q\n",
    "# %pip install librosa  # -q\n",
    "# %pip install soundfile # -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6e6e597-e406-4851-bdcc-25c118e006f9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install transformers # >=4.28.1 -q\n",
    "# !pip install accelerate # >=0.20.3 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42d2eb07-63a4-4feb-80ec-2a7508c0927d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !conda install -y ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fc3f1126-d487-4f60-ab8b-8e5897d94735",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da52b2e1-dc62-41fd-a8e7-00dd6e31285c",
   "metadata": {},
   "source": [
    "**❗Please restart the kernel before executing the cells below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5fec1136-d7b0-402f-b959-d0302680c508",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import required packages \n",
    "import torch\n",
    "import whisper\n",
    "import torchaudio\n",
    "import sagemaker\n",
    "import time\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "443ea851-3d8c-42d6-bcbe-334d7cde01ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# basic configurations \n",
    "sess = sagemaker.session.Session()\n",
    "bucket = sess.default_bucket()\n",
    "prefix = 'models/whisper_ckpts'\n",
    "prefix = 'whisper_blog_post'\n",
    "role = sagemaker.get_execution_role()\n",
    "region = sess._region_name \n",
    "\n",
    "# below boto3 clients are for invoking asynchronous endpoint \n",
    "sm_runtime = boto3.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7530e5bc-8c1d-47e1-9554-b22635b2de18",
   "metadata": {},
   "source": [
    "### Create Whisper Hugging Face model artifacts and upload to S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "098bce2b-7151-43c3-8b8b-3c5000a9b60b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "85bce568-21b0-4d48-9849-1ac8cf18388b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:15<00:00,  7.83s/it]\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import WhisperProcessor, AutoModelForSpeechSeq2Seq\n",
    "\n",
    "# Load the pre-trained model\n",
    "model_name = \"/home/ec2-user/SageMaker/efs/Projects/whisper/checkpoint/checkpoint-v6/checkpoint-40\" # \"openai/whisper-base\"\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(model_name)\n",
    "\n",
    "# Define a directory where you want to save the model\n",
    "save_directory = \"./model\"\n",
    "\n",
    "# Save the model to the specified directory\n",
    "model.save_pretrained(save_directory)\n",
    "\n",
    "from transformers import WhisperTokenizer\n",
    "\n",
    "tokenizer = WhisperTokenizer.from_pretrained(model_name)\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "processor = WhisperProcessor.from_pretrained(model_name)\n",
    "processor.save_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "02164e7e-7244-4f22-a435-b383caf61b96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./\n",
      "./tokenizer_config.json\n",
      "./preprocessor_config.json\n",
      "./model-00002-of-00002.safetensors\n",
      "./model.safetensors.index.json\n",
      "./config.json\n",
      "./merges.txt\n",
      "./generation_config.json\n",
      "./special_tokens_map.json\n",
      "./added_tokens.json\n",
      "./vocab.json\n",
      "./model-00001-of-00002.safetensors\n",
      "./normalizer.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-west-2-452145973879/whisper_blog_post/huggingface/model/model.tar.gz'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!tar cvzf model.tar.gz -C model/ .\n",
    "\n",
    "model_uri = sess.upload_data('model.tar.gz', bucket = bucket, key_prefix=f\"{prefix}/huggingface/model\")\n",
    "!rm model.tar.gz\n",
    "!rm -rf model\n",
    "model_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "70fe78a4-f976-4096-adfc-c7beb4e2b2cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate a unique model name and provide image uri\n",
    "\n",
    "id = int(time.time())\n",
    "model_name = f'whisper-hf-model-{id}'\n",
    "\n",
    "# !Please change the image URI for the region that you are using:e.g. us-east-1\n",
    "# image = f\"763104351884.dkr.ecr.{region}.amazonaws.com/huggingface-pytorch-inference:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04\"\n",
    "# image = f\"763104351884.dkr.ecr.{region}.amazonaws.com/pytorch-inference:2.3.0-gpu-py311-cu121-ubuntu20.04-sagemaker\"\n",
    "image = \"452145973879.dkr.ecr.us-west-2.amazonaws.com/whisper-inference:v0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4821404d-d25a-4503-a26f-04980e93575b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a HuggingFaceModel for deployment\n",
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "\n",
    "whisper_hf_model = HuggingFaceModel(\n",
    "    model_data=model_uri,\n",
    "    role=role,\n",
    "    image_uri = image,\n",
    "    entry_point=\"inference.py\",\n",
    "    source_dir='code',\n",
    "    name=model_name,\n",
    "    env = {\n",
    "        \"chunk_length_s\":\"30\",\n",
    "        'MMS_MAX_REQUEST_SIZE': '2000000000',\n",
    "        'MMS_MAX_RESPONSE_SIZE': '2000000000',\n",
    "        'MMS_DEFAULT_RESPONSE_TIMEOUT': '900'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4305c4f-67af-4f2d-b545-9e112f9722c0",
   "metadata": {},
   "source": [
    "### Real-time inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2c1075c2-8146-468c-bd6e-54496e4ee6eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.serializers import DataSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "# Define serializers and deserializer\n",
    "audio_serializer = DataSerializer(content_type=\"audio/x-audio\")  # \"audio/x-audio\"\n",
    "deserializer = JSONDeserializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9b6375d7-8116-49a1-a50d-28c1b30133b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------!"
     ]
    }
   ],
   "source": [
    "# Deploy the model for real-time inference\n",
    "endpoint_name = f'whisper-hf-real-time-endpoint-{id}'\n",
    "\n",
    "real_time_predictor = whisper_hf_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g4dn.xlarge\",   # \"ml.g4dn.xlarge\",  \"ml.g5.xlarge\"\n",
    "    endpoint_name = endpoint_name,\n",
    "    serializer=audio_serializer,\n",
    "    deserializer = deserializer\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be85b0e4-7d00-4bb7-bc21-edcd23c9cd32",
   "metadata": {},
   "source": [
    "# if already deployed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b61286b4-21aa-4abe-b71f-16cd1c3beee6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.base_predictor.Predictor at 0x7fc7ad18d180>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker import Model, image_uris, serializers, deserializers\n",
    "\n",
    "# endpoint_name = 'whisper-hf-real-time-endpoint-1718259402'  # g4dn\n",
    "endpoint_name = 'whisper-hf-real-time-endpoint-1718257905'  # g5\n",
    "\n",
    "real_time_predictor = sagemaker.Predictor(\n",
    "    endpoint_name=endpoint_name, \n",
    "    sagemaker_session=sess,\n",
    "    serializer=audio_serializer, # serializers.JSONSerializer()\n",
    "    deserializer = deserializer\n",
    ")\n",
    "\n",
    "real_time_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "88f4e679-e83e-436f-ad00-8d02b038f582",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Download a test data sample from huggingface dataset\n",
    "# import soundfile as sf\n",
    "# from datasets import load_dataset\n",
    "# dataset = load_dataset('MLCommons/peoples_speech', split='train', streaming = True)\n",
    "# sample = next(iter(dataset))\n",
    "# audio_data = sample['audio']['array']\n",
    "# output_path = 'sample_audio.wav'\n",
    "# sf.write(output_path, audio_data, sample['audio']['sampling_rate'])\n",
    "\n",
    "# print(f\"Audio sample saved to '{output_path}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3381911f-3f81-4cb1-a9e0-eedbaa41161d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time cost: 3.873155355453491s\n",
      "response: 放落嚟星期五鬼星小姐你本人電話號碼幾多羅小姐你本人電話號碼係嗨你嗰部大眼雞嚟㗎嘛係咪?羅士在新聞問但係如果係話譬如我哋師傅上門安裝嗰個時間你都係與佢都係當日鐘五十二點至下集五點鐘呢段時間都係大約呢段時間上門嘅係呀好啊冇問題你府上係住喺鑽石山啟鑽院嗰邊嚟㗎嘛劉少正係咪好咁我呢邊就照落單我哋安排師傅今個星期五上門即係四月二十六號嘅好咁師�\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "# Perform real-time inference\n",
    "audio_path = \"/home/ec2-user/SageMaker/efs/Projects/whisper/data/midea_data_500/wavs/bdaca8e0-4eab-44d0-b632-91dbb78e02eb.wav\"\n",
    "audio_path = \"/home/ec2-user/SageMaker/efs/Projects/whisper/data/midea_data_500/wavs/89c871c5-516c-4bc0-90a5-0d7e60fbc374.wav\"\n",
    "audio_path = \"/home/ec2-user/SageMaker/efs/Projects/whisper/data/midea_0612/wavs/d5f2afaa-53af-4dcb-ac24-3827a99c748e.wav\"\n",
    "# audio_path = \"/home/ec2-user/SageMaker/efs/Projects/whisper/data/midea_0612/fb0b8693-208a-408c-9f56-1979aa9b5421.wav\"\n",
    "audio_path = \"/home/ec2-user/SageMaker/efs/Projects/whisper/data/midea_0612/wavs_1channel/d5f2afaa-53af-4dcb-ac24-3827a99c748e_c1.wav\"\n",
    "\n",
    "# audio_path = \"sample_audio.wav\" \n",
    "start_time = time.time()\n",
    "response = real_time_predictor.predict(data=audio_path)\n",
    "time_cost = time.time() - start_time\n",
    "\n",
    "print(f\"time cost: {time_cost}s\")\n",
    "print(f\"response: {response}\")\n",
    "# print(response[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cc0a7c98-c5f2-4ec0-91a3-c0851870e969",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# optional: Delete real-time inference endpoint, this is not required for below steps\n",
    "# real_time_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37d757e-b3da-469e-8f31-79b4e284009b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf6f6800-fcc3-425b-8d83-2c94e08cd34d",
   "metadata": {},
   "source": [
    "### Batch Transform Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "02fcbeae-bb46-44c5-8028-b58fdf2cfb61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using already existing model: whisper-hf-model-1718259402\n"
     ]
    }
   ],
   "source": [
    "# Create a transformer\n",
    "whisper_transformer = whisper_hf_model.transformer(\n",
    "    instance_count = 1,\n",
    "    instance_type = \"ml.g4dn.xlarge\",\n",
    "    output_path=\"s3://{}/{}/batch-transform/\".format(bucket, prefix),\n",
    "    max_payload = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d8746208-69b6-40fd-8b76-147f8a59469c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Please provide the S3 path where you have one or more audio files that you want to process \n",
    "data = \"s3://sagemaker-us-west-2-452145973879/data/midea_data_500/wavs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "897627a2-00d9-4860-a0e4-381688e06ffe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: whisper-hf-batch-transform-1718259402\n"
     ]
    }
   ],
   "source": [
    "# Define request data and job name\n",
    "job_name = f\"whisper-hf-batch-transform-{id}\"\n",
    "\n",
    "# Start batch transform job\n",
    "whisper_transformer.transform(data = data, job_name= job_name, wait = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82561d70-22d4-45d4-9b4d-740fb077e511",
   "metadata": {},
   "source": [
    "### Asynchronous Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f2625d15-bbff-420e-ac9c-0ffeebb3023f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-us-west-2-452145973879/whisper_blog_post/huggingface/model/model.tar.gz), script artifact (code), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-west-2-452145973879/whisper-hf-model-1718259402/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: whisper-hf-model-1718259402\n",
      "WARNING:sagemaker:Using already existing model: whisper-hf-model-1718259402\n",
      "INFO:sagemaker:Creating endpoint-config with name whisper-hf-async-endpoint-1718259402\n",
      "INFO:sagemaker:Creating endpoint with name whisper-hf-async-endpoint-1718259402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------!CPU times: user 5min 44s, sys: 1min 2s, total: 6min 46s\n",
      "Wall time: 12min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sagemaker.async_inference import AsyncInferenceConfig\n",
    "\n",
    "# Create an AsyncInferenceConfig object\n",
    "async_config = AsyncInferenceConfig(\n",
    "    output_path=f\"s3://{bucket}/{prefix}/output\", \n",
    "    max_concurrent_invocations_per_instance = 4,\n",
    "    # notification_config = {\n",
    "            #   \"SuccessTopic\": \"arn:aws:sns:us-east-2:123456789012:MyTopic\",\n",
    "            #   \"ErrorTopic\": \"arn:aws:sns:us-east-2:123456789012:MyTopic\",\n",
    "    # }, #  Notification configuration \n",
    ")\n",
    "\n",
    "# Deploy the model for async inference\n",
    "endpoint_name = f'whisper-hf-async-endpoint-{id}'\n",
    "async_predictor = whisper_hf_model.deploy(\n",
    "    async_inference_config=async_config,\n",
    "    initial_instance_count=1, # number of instances\n",
    "    instance_type ='ml.g4dn.xlarge', # instance type\n",
    "    endpoint_name = endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d03d4add-f11d-4fcf-a33c-47a4eb99e4ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Provide the S3 path for the audio file you want to processs\n",
    "input_path = \"s3://xxx/audio-files/xxx.mp3\"\n",
    "input_path = \"s3://sagemaker-us-west-2-452145973879/data/midea_data_500/wavs/005888b3-897d-4112-8232-0cefda76aa3f.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "db4b6114-6439-4a0c-9431-0fb74e58f617",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-west-2-452145973879/whisper_blog_post/output/ad9ec9de-b144-4a96-af09-cfdfc6b910e7.out'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform async inference\n",
    "initial_args = {'ContentType':\"audio/x-audio\"}\n",
    "response = async_predictor.predict_async(initial_args = initial_args, input_path=input_path)\n",
    "response.output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91944dd9-1055-4cc1-b01f-1570cd222fa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "109a8a77-3036-456c-8fea-f5316648cdc1",
   "metadata": {},
   "source": [
    "### Optional: Test autoscaling configurations for Async inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b3b4139b-51e2-4eaf-8d0b-9f23327a4545",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PolicyARN': 'arn:aws:autoscaling:us-west-2:452145973879:scalingPolicy:2a239217-1727-49eb-b629-8ea1870a3308:resource/sagemaker/endpoint/whisper-hf-async-endpoint-1718259402/variant/AllTraffic:policyName/Invocations-ScalingPolicy',\n",
       " 'Alarms': [{'AlarmName': 'TargetTracking-endpoint/whisper-hf-async-endpoint-1718259402/variant/AllTraffic-AlarmHigh-0c02d78f-d7fa-4525-97df-ed99a5a4b874',\n",
       "   'AlarmARN': 'arn:aws:cloudwatch:us-west-2:452145973879:alarm:TargetTracking-endpoint/whisper-hf-async-endpoint-1718259402/variant/AllTraffic-AlarmHigh-0c02d78f-d7fa-4525-97df-ed99a5a4b874'},\n",
       "  {'AlarmName': 'TargetTracking-endpoint/whisper-hf-async-endpoint-1718259402/variant/AllTraffic-AlarmLow-19a89b75-bdab-42be-9e10-f1e2f3251de5',\n",
       "   'AlarmARN': 'arn:aws:cloudwatch:us-west-2:452145973879:alarm:TargetTracking-endpoint/whisper-hf-async-endpoint-1718259402/variant/AllTraffic-AlarmLow-19a89b75-bdab-42be-9e10-f1e2f3251de5'}],\n",
       " 'ResponseMetadata': {'RequestId': '90633e50-91b9-4aa5-a66e-2c724e38ba40',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '90633e50-91b9-4aa5-a66e-2c724e38ba40',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '901',\n",
       "   'date': 'Thu, 13 Jun 2024 09:55:39 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoscale = boto3.client('application-autoscaling') \n",
    "resource_id='endpoint/' + endpoint_name + '/variant/' + 'AllTraffic'\n",
    "\n",
    "# Register scalable target\n",
    "register_response = autoscale.register_scalable_target(\n",
    "    ServiceNamespace='sagemaker', \n",
    "    ResourceId=resource_id,\n",
    "    ScalableDimension='sagemaker:variant:DesiredInstanceCount',\n",
    "    MinCapacity=0,  \n",
    "    MaxCapacity=3 # * check how many instances available in your account\n",
    ")\n",
    "\n",
    "# Define scaling policy\n",
    "scalingPolicy_response = autoscale.put_scaling_policy(\n",
    "    PolicyName='Invocations-ScalingPolicy',\n",
    "    ServiceNamespace='sagemaker', # The namespace of the AWS service that provides the resource. \n",
    "    ResourceId=resource_id,  \n",
    "    ScalableDimension='sagemaker:variant:DesiredInstanceCount', # SageMaker supports only Instance Count\n",
    "    PolicyType='TargetTrackingScaling', # 'StepScaling'|'TargetTrackingScaling'\n",
    "    TargetTrackingScalingPolicyConfiguration={\n",
    "        'TargetValue': 3.0, # The target value for the metric. \n",
    "        'CustomizedMetricSpecification': {\n",
    "            'MetricName': 'ApproximateBacklogSizePerInstance',\n",
    "            'Namespace': 'AWS/SageMaker',\n",
    "            'Dimensions': [\n",
    "                {'Name': 'EndpointName', 'Value': endpoint_name }\n",
    "            ],\n",
    "            'Statistic': 'Average',\n",
    "        },\n",
    "        'ScaleInCooldown': 60, # The cooldown period helps you prevent your Auto Scaling group from launching or terminating \n",
    "                                # additional instances before the effects of previous activities are visible. \n",
    "                                # You can configure the length of time based on your instance startup time or other application needs.\n",
    "                                # ScaleInCooldown - The amount of time, in seconds, after a scale in activity completes before another scale in activity can start. \n",
    "        'ScaleOutCooldown': 60 # ScaleOutCooldown - The amount of time, in seconds, after a scale out activity completes before another scale out activity can start.\n",
    "        \n",
    "        # 'DisableScaleIn': True|False - indicates whether scale in by the target tracking policy is disabled. \n",
    "                            # If the value is true , scale in is disabled and the target tracking policy won't remove capacity from the scalable resource.\n",
    "    }\n",
    ")\n",
    "\n",
    "scalingPolicy_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "633991e3-9d1d-4537-a84e-3e464d5e1720",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whisper-hf-async-endpoint-1718259402\n",
      "\n",
      "Async invocations for Hugging Face model serving with autoscaling\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Trigger 1000 asynchronous invocations with autoscaling from 1 to 3\n",
    "# then scale down to 0 on completion\n",
    "\n",
    "print(endpoint_name)\n",
    "for i in range(1,1000):\n",
    "    response = sm_runtime.invoke_endpoint_async(\n",
    "    EndpointName=endpoint_name, \n",
    "    InputLocation=input_path)\n",
    "    \n",
    "print(\"\\nAsync invocations for Hugging Face model serving with autoscaling\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae0feb3-e8e8-438f-95bb-99e422823262",
   "metadata": {},
   "source": [
    "### Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37456ce7-2513-4b0e-9361-6aa18817fa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete Asynchronous inference endpoint\n",
    "async_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bc0813-a319-4a50-9520-c497937860df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "conda_whisper",
   "language": "python",
   "name": "conda_whisper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
